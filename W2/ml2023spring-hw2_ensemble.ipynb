{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc2727f6",
   "metadata": {
    "id": "OYlaRwNu7ojq",
    "papermill": {
     "duration": 0.006285,
     "end_time": "2023-03-17T04:29:30.107355",
     "exception": false,
     "start_time": "2023-03-17T04:29:30.101070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Homework 2: Phoneme Classification**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8965d500",
   "metadata": {
    "id": "A7DRC5V7_8A5",
    "papermill": {
     "duration": 0.00485,
     "end_time": "2023-03-17T04:29:30.117286",
     "exception": false,
     "start_time": "2023-03-17T04:29:30.112436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Objectives:\n",
    "* Solve a classification problem with deep neural networks (DNNs).\n",
    "* Understand recursive neural networks (RNNs).\n",
    "\n",
    "If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91b65ed",
   "metadata": {
    "id": "pADUiYODJE1O",
    "papermill": {
     "duration": 0.00476,
     "end_time": "2023-03-17T04:29:30.126789",
     "exception": false,
     "start_time": "2023-03-17T04:29:30.122029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Some Utility Functions\n",
    "**Fixes random number generator seeds for reproducibility.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deaf2427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:29:30.139153Z",
     "iopub.status.busy": "2023-03-17T04:29:30.138284Z",
     "iopub.status.idle": "2023-03-17T04:29:41.067396Z",
     "shell.execute_reply": "2023-03-17T04:29:41.066122Z"
    },
    "papermill": {
     "duration": 10.938443,
     "end_time": "2023-03-17T04:29:41.070135",
     "exception": false,
     "start_time": "2023-03-17T04:29:30.131692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "Collecting torchensemble\r\n",
      "  Downloading torchensemble-0.1.9-py3-none-any.whl (42 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from torchensemble) (1.12.0)\r\n",
      "Requirement already satisfied: torchvision>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from torchensemble) (0.13.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from torchensemble) (1.0.2)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.23.0->torchensemble) (1.7.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.23.0->torchensemble) (3.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.23.0->torchensemble) (1.21.6)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.23.0->torchensemble) (1.0.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4.0->torchensemble) (4.1.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.2.2->torchensemble) (2.28.1)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision>=0.2.2->torchensemble) (9.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.2.2->torchensemble) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.2.2->torchensemble) (2.1.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.2.2->torchensemble) (2022.12.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision>=0.2.2->torchensemble) (1.26.11)\r\n",
      "Installing collected packages: torchensemble\r\n",
      "Successfully installed torchensemble-0.1.9\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb655ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:29:41.083100Z",
     "iopub.status.busy": "2023-03-17T04:29:41.082748Z",
     "iopub.status.idle": "2023-03-17T04:29:42.903189Z",
     "shell.execute_reply": "2023-03-17T04:29:42.902190Z"
    },
    "id": "BsZKgBZQJjaE",
    "papermill": {
     "duration": 1.829532,
     "end_time": "2023-03-17T04:29:42.905617",
     "exception": false,
     "start_time": "2023-03-17T04:29:41.076085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "def same_seeds(seed):\n",
    "    random.seed(seed) \n",
    "    np.random.seed(seed)  \n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed) \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff1df93",
   "metadata": {
    "id": "_L_4anls8Drv",
    "papermill": {
     "duration": 0.005181,
     "end_time": "2023-03-17T04:29:42.916459",
     "exception": false,
     "start_time": "2023-03-17T04:29:42.911278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
    "\n",
    "A phoneme may span several frames and is dependent to past and future frames. \\\n",
    "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
    "\n",
    "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f53694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:29:42.928827Z",
     "iopub.status.busy": "2023-03-17T04:29:42.928302Z",
     "iopub.status.idle": "2023-03-17T04:29:42.945810Z",
     "shell.execute_reply": "2023-03-17T04:29:42.944976Z"
    },
    "id": "IJjLT8em-y9G",
    "papermill": {
     "duration": 0.026223,
     "end_time": "2023-03-17T04:29:42.947992",
     "exception": false,
     "start_time": "2023-03-17T04:29:42.921769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_feat(path):\n",
    "    feat = torch.load(path)\n",
    "    return feat\n",
    "\n",
    "def shift(x, n):\n",
    "    if n < 0:\n",
    "        left = x[0].repeat(-n, 1)\n",
    "        right = x[:n]\n",
    "    elif n > 0:\n",
    "        right = x[-1].repeat(n, 1)\n",
    "        left = x[n:]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "    return torch.cat((left, right), dim=0)\n",
    "\n",
    "def concat_feat(x, concat_n):\n",
    "    assert concat_n % 2 == 1 # n must be odd\n",
    "    if concat_n < 2:\n",
    "        return x\n",
    "    seq_len, feature_dim = x.size(0), x.size(1)\n",
    "    x = x.repeat(1, concat_n) \n",
    "    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n",
    "    mid = (concat_n // 2)\n",
    "    for r_idx in range(1, mid+1):\n",
    "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
    "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
    "\n",
    "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
    "\n",
    "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8):\n",
    "    class_num = 41 # NOTE: pre-computed, should not need change\n",
    "\n",
    "    if split == 'train' or split == 'val':\n",
    "        mode = 'train'\n",
    "    elif split == 'test':\n",
    "        mode = 'test'\n",
    "    else:\n",
    "        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
    "\n",
    "    label_dict = {}\n",
    "    if mode == 'train':\n",
    "        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n",
    "            line = line.strip('\\n').split(' ')\n",
    "            label_dict[line[0]] = [int(p) for p in line[1:]]\n",
    "        \n",
    "        # split training and validation data\n",
    "        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n",
    "        random.shuffle(usage_list)\n",
    "        train_len = int(len(usage_list) * train_ratio)\n",
    "        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n",
    "\n",
    "    elif mode == 'test':\n",
    "        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
    "\n",
    "    usage_list = [line.strip('\\n') for line in usage_list]\n",
    "    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
    "\n",
    "    max_len = 3000000\n",
    "    X = torch.empty(max_len, 39 * concat_nframes)\n",
    "    if mode == 'train':\n",
    "        y = torch.empty(max_len, dtype=torch.long)\n",
    "\n",
    "    idx = 0\n",
    "    for i, fname in tqdm(enumerate(usage_list)):\n",
    "        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
    "        cur_len = len(feat)\n",
    "        feat = concat_feat(feat, concat_nframes)\n",
    "        if mode == 'train':\n",
    "          label = torch.LongTensor(label_dict[fname])\n",
    "\n",
    "        X[idx: idx + cur_len, :] = feat\n",
    "        if mode == 'train':\n",
    "          y[idx: idx + cur_len] = label\n",
    "\n",
    "        idx += cur_len\n",
    "\n",
    "    X = X[:idx, :]\n",
    "    if mode == 'train':\n",
    "      y = y[:idx]\n",
    "\n",
    "    print(f'[INFO] {split} set')\n",
    "    print(X.shape)\n",
    "    if mode == 'train':\n",
    "      print(y.shape)\n",
    "      return X, y\n",
    "    else:\n",
    "      return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5aa448",
   "metadata": {
    "id": "us5XW_x6udZQ",
    "papermill": {
     "duration": 0.005117,
     "end_time": "2023-03-17T04:29:42.958251",
     "exception": false,
     "start_time": "2023-03-17T04:29:42.953134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb52f5c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:29:42.970135Z",
     "iopub.status.busy": "2023-03-17T04:29:42.969564Z",
     "iopub.status.idle": "2023-03-17T04:29:42.976940Z",
     "shell.execute_reply": "2023-03-17T04:29:42.975908Z"
    },
    "id": "Fjf5EcmJtf4e",
    "papermill": {
     "duration": 0.015629,
     "end_time": "2023-03-17T04:29:42.978984",
     "exception": false,
     "start_time": "2023-03-17T04:29:42.963355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LibriDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.data = X\n",
    "        if y is not None:\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106b7f5d",
   "metadata": {
    "id": "IRqKNvNZwe3V",
    "papermill": {
     "duration": 0.005035,
     "end_time": "2023-03-17T04:29:42.989107",
     "exception": false,
     "start_time": "2023-03-17T04:29:42.984072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model\n",
    "Feel free to modify the structure of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d35f0513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:29:43.001075Z",
     "iopub.status.busy": "2023-03-17T04:29:43.000261Z",
     "iopub.status.idle": "2023-03-17T04:29:43.008556Z",
     "shell.execute_reply": "2023-03-17T04:29:43.007698Z"
    },
    "id": "Bg-GRd7ywdrL",
    "papermill": {
     "duration": 0.016431,
     "end_time": "2023-03-17T04:29:43.010665",
     "exception": false,
     "start_time": "2023-03-17T04:29:42.994234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(input_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            BasicBlock(input_dim, hidden_dim),\n",
    "            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "            \n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "#         x = nn.functional.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb41954",
   "metadata": {
    "id": "TlIq8JeqvvHC",
    "papermill": {
     "duration": 0.005049,
     "end_time": "2023-03-17T04:29:43.020824",
     "exception": false,
     "start_time": "2023-03-17T04:29:43.015775",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8684ae1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:29:43.032474Z",
     "iopub.status.busy": "2023-03-17T04:29:43.032195Z",
     "iopub.status.idle": "2023-03-17T04:29:43.037313Z",
     "shell.execute_reply": "2023-03-17T04:29:43.036334Z"
    },
    "id": "iIHn79Iav1ri",
    "papermill": {
     "duration": 0.013406,
     "end_time": "2023-03-17T04:29:43.039388",
     "exception": false,
     "start_time": "2023-03-17T04:29:43.025982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data prarameters\n",
    "concat_nframes = 25      # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
    "train_ratio = 0.9              # the ratio of data used for training, the rest will be used for validation\n",
    "\n",
    "# training parameters\n",
    "seed = 1102                        # random seed\n",
    "batch_size = 512                # batch size\n",
    "num_epoch = 20                  # the number of training epoch\n",
    "learning_rate = 1e-4         # learning rate\n",
    "model_path = './model.ckpt'     # the path where the checkpoint will be saved\n",
    "\n",
    "# model parameters\n",
    "input_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\n",
    "hidden_layers = 6           # the number of hidden layers\n",
    "hidden_dim = 700            # the hidden dim\n",
    "\n",
    "estimators = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87372a4",
   "metadata": {
    "id": "IIUFRgG5yoDn",
    "papermill": {
     "duration": 0.005224,
     "end_time": "2023-03-17T04:29:43.049683",
     "exception": false,
     "start_time": "2023-03-17T04:29:43.044459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61054277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:29:43.061461Z",
     "iopub.status.busy": "2023-03-17T04:29:43.060818Z",
     "iopub.status.idle": "2023-03-17T04:30:10.710191Z",
     "shell.execute_reply": "2023-03-17T04:30:10.708756Z"
    },
    "id": "c1zI3v5jyrDn",
    "outputId": "6e7eeb1b-b76a-4846-b9b4-055d66c05661",
    "papermill": {
     "duration": 27.658972,
     "end_time": "2023-03-17T04:30:10.713734",
     "exception": false,
     "start_time": "2023-03-17T04:29:43.054762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "[Dataset] - # phone classes: 41, number of utterances for train: 3086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3086it [00:24, 124.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] train set\n",
      "torch.Size([1902169, 975])\n",
      "torch.Size([1902169])\n",
      "[Dataset] - # phone classes: 41, number of utterances for val: 343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "343it [00:01, 234.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] val set\n",
      "torch.Size([212222, 975])\n",
      "torch.Size([212222])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "\n",
    "same_seeds(seed)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'DEVICE: {device}')\n",
    "\n",
    "# preprocess data\n",
    "train_X, train_y = preprocess_data(split='train', feat_dir='/kaggle/input/ml2023spring-hw2/libriphone/feat', phone_path='/kaggle/input/ml2023spring-hw2/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
    "val_X, val_y = preprocess_data(split='val', feat_dir='/kaggle/input/ml2023spring-hw2/libriphone/feat', phone_path='/kaggle/input/ml2023spring-hw2/libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio)\n",
    "\n",
    "# get dataset\n",
    "train_set = LibriDataset(train_X, train_y)\n",
    "val_set = LibriDataset(val_X, val_y)\n",
    "\n",
    "# remove raw feature to save memory\n",
    "del train_X, train_y, val_X, val_y\n",
    "gc.collect()\n",
    "\n",
    "# get dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1b6a36d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T04:30:10.753397Z",
     "iopub.status.busy": "2023-03-17T04:30:10.752817Z",
     "iopub.status.idle": "2023-03-17T05:31:51.143817Z",
     "shell.execute_reply": "2023-03-17T05:31:51.142645Z"
    },
    "papermill": {
     "duration": 3700.412888,
     "end_time": "2023-03-17T05:31:51.146722",
     "exception": false,
     "start_time": "2023-03-17T04:30:10.733834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log will be saved in '/kaggle/working/logs'.\n",
      "Create folder 'logs/'\n",
      "Start logging into file /kaggle/working/logs/log-2023_03_17_04_30.log...\n",
      "Estimator: 000 | Epoch: 000 | Batch: 000 | Loss: 3.77359 | Correct: 10/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 100 | Loss: 2.64725 | Correct: 185/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 200 | Loss: 2.34307 | Correct: 210/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 300 | Loss: 2.18118 | Correct: 242/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 400 | Loss: 2.06105 | Correct: 256/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 500 | Loss: 2.04797 | Correct: 268/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 600 | Loss: 2.03602 | Correct: 260/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 700 | Loss: 2.03355 | Correct: 259/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 800 | Loss: 1.97293 | Correct: 266/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 900 | Loss: 1.92430 | Correct: 288/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 1000 | Loss: 1.87795 | Correct: 288/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 1100 | Loss: 1.89343 | Correct: 288/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 1200 | Loss: 1.85421 | Correct: 306/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 1300 | Loss: 1.82364 | Correct: 304/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 1400 | Loss: 1.87364 | Correct: 286/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 1500 | Loss: 1.87402 | Correct: 281/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 1600 | Loss: 1.83074 | Correct: 293/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 1700 | Loss: 1.80853 | Correct: 306/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 1800 | Loss: 1.81685 | Correct: 284/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 1900 | Loss: 1.75670 | Correct: 304/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 2000 | Loss: 1.79551 | Correct: 316/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 2100 | Loss: 1.78017 | Correct: 305/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 2200 | Loss: 1.87638 | Correct: 295/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 2300 | Loss: 1.84611 | Correct: 291/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 2400 | Loss: 1.78652 | Correct: 301/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 2500 | Loss: 1.70102 | Correct: 324/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 2600 | Loss: 1.70886 | Correct: 319/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 2700 | Loss: 1.76754 | Correct: 299/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 2800 | Loss: 1.82125 | Correct: 296/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 2900 | Loss: 1.85181 | Correct: 292/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 3000 | Loss: 1.70248 | Correct: 308/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 3100 | Loss: 1.75194 | Correct: 304/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 3200 | Loss: 1.78646 | Correct: 307/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 3300 | Loss: 1.76264 | Correct: 302/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 3400 | Loss: 1.79520 | Correct: 291/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 3500 | Loss: 1.82275 | Correct: 280/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 3600 | Loss: 1.69876 | Correct: 329/512\n",
      "Estimator: 000 | Epoch: 000 | Batch: 3700 | Loss: 1.76849 | Correct: 301/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 000 | Loss: 3.80523 | Correct: 5/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 100 | Loss: 2.51080 | Correct: 200/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 200 | Loss: 2.28814 | Correct: 222/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 300 | Loss: 2.12914 | Correct: 252/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 400 | Loss: 2.16465 | Correct: 240/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 500 | Loss: 2.02200 | Correct: 272/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 600 | Loss: 2.08333 | Correct: 240/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 700 | Loss: 1.93525 | Correct: 280/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 800 | Loss: 1.94120 | Correct: 284/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 900 | Loss: 1.92977 | Correct: 264/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 1000 | Loss: 1.95818 | Correct: 267/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 1100 | Loss: 1.88156 | Correct: 295/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 1200 | Loss: 1.91584 | Correct: 283/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 1300 | Loss: 1.95087 | Correct: 273/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 1400 | Loss: 1.80372 | Correct: 305/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 1500 | Loss: 1.81893 | Correct: 300/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 1600 | Loss: 1.80591 | Correct: 296/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 1700 | Loss: 1.83296 | Correct: 279/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 1800 | Loss: 1.79510 | Correct: 298/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 1900 | Loss: 1.81659 | Correct: 296/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 2000 | Loss: 1.84781 | Correct: 287/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 2100 | Loss: 1.88596 | Correct: 292/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 2200 | Loss: 1.79516 | Correct: 310/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 2300 | Loss: 1.83723 | Correct: 278/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 2400 | Loss: 1.79609 | Correct: 295/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 2500 | Loss: 1.78528 | Correct: 303/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 2600 | Loss: 1.75269 | Correct: 306/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 2700 | Loss: 1.77106 | Correct: 298/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 2800 | Loss: 1.74337 | Correct: 315/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 2900 | Loss: 1.73594 | Correct: 314/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 3000 | Loss: 1.73589 | Correct: 309/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 3100 | Loss: 1.76673 | Correct: 308/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 3200 | Loss: 1.72001 | Correct: 315/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 3300 | Loss: 1.71837 | Correct: 310/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 3400 | Loss: 1.75429 | Correct: 315/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 3500 | Loss: 1.77778 | Correct: 313/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 3600 | Loss: 1.74831 | Correct: 316/512\n",
      "Estimator: 001 | Epoch: 000 | Batch: 3700 | Loss: 1.63930 | Correct: 329/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 000 | Loss: 3.81037 | Correct: 4/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 100 | Loss: 2.57394 | Correct: 200/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 200 | Loss: 2.26822 | Correct: 227/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 300 | Loss: 2.06793 | Correct: 248/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 400 | Loss: 2.12406 | Correct: 259/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 500 | Loss: 2.11010 | Correct: 244/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 600 | Loss: 1.99473 | Correct: 277/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 700 | Loss: 2.00144 | Correct: 259/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 800 | Loss: 1.88195 | Correct: 273/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 900 | Loss: 1.93977 | Correct: 288/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 1000 | Loss: 1.96678 | Correct: 279/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 1100 | Loss: 1.95424 | Correct: 280/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 1200 | Loss: 1.87519 | Correct: 291/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 1300 | Loss: 1.86204 | Correct: 287/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 1400 | Loss: 1.88060 | Correct: 278/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 1500 | Loss: 1.90342 | Correct: 285/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 1600 | Loss: 1.87539 | Correct: 290/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 1700 | Loss: 1.86136 | Correct: 298/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 1800 | Loss: 1.82162 | Correct: 301/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 1900 | Loss: 1.87151 | Correct: 285/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 2000 | Loss: 1.86508 | Correct: 276/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 2100 | Loss: 1.81173 | Correct: 313/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 2200 | Loss: 1.75484 | Correct: 305/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 2300 | Loss: 1.71640 | Correct: 309/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 2400 | Loss: 1.82999 | Correct: 300/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 2500 | Loss: 1.77404 | Correct: 309/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 2600 | Loss: 1.84521 | Correct: 298/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 2700 | Loss: 1.81837 | Correct: 316/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 2800 | Loss: 1.83516 | Correct: 292/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 2900 | Loss: 1.82378 | Correct: 301/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 3000 | Loss: 1.77446 | Correct: 294/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 3100 | Loss: 1.69984 | Correct: 329/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 3200 | Loss: 1.71999 | Correct: 313/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 3300 | Loss: 1.78943 | Correct: 306/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 3400 | Loss: 1.74865 | Correct: 309/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 3500 | Loss: 1.72949 | Correct: 301/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 3600 | Loss: 1.70903 | Correct: 311/512\n",
      "Estimator: 002 | Epoch: 000 | Batch: 3700 | Loss: 1.69038 | Correct: 316/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 000 | Loss: 3.80009 | Correct: 8/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 100 | Loss: 2.49213 | Correct: 196/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 200 | Loss: 2.27919 | Correct: 231/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 300 | Loss: 2.23055 | Correct: 224/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 400 | Loss: 2.14470 | Correct: 256/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 500 | Loss: 2.10446 | Correct: 254/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 600 | Loss: 2.00683 | Correct: 268/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 700 | Loss: 1.97529 | Correct: 285/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 800 | Loss: 1.96846 | Correct: 266/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 900 | Loss: 1.97095 | Correct: 254/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 1000 | Loss: 1.80049 | Correct: 287/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 1100 | Loss: 1.89412 | Correct: 288/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 1200 | Loss: 1.84944 | Correct: 295/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 1300 | Loss: 1.84966 | Correct: 313/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 1400 | Loss: 1.80350 | Correct: 302/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 1500 | Loss: 1.84216 | Correct: 297/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 1600 | Loss: 1.91338 | Correct: 281/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 1700 | Loss: 1.86303 | Correct: 286/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 1800 | Loss: 1.82300 | Correct: 301/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 1900 | Loss: 1.68464 | Correct: 320/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 2000 | Loss: 1.86692 | Correct: 285/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 2100 | Loss: 1.79341 | Correct: 311/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 2200 | Loss: 1.78041 | Correct: 308/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 2300 | Loss: 1.72376 | Correct: 323/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 2400 | Loss: 1.72750 | Correct: 324/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 2500 | Loss: 1.74595 | Correct: 312/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 2600 | Loss: 1.75693 | Correct: 310/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 2700 | Loss: 1.67873 | Correct: 332/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 2800 | Loss: 1.78309 | Correct: 294/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 2900 | Loss: 1.70498 | Correct: 314/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 3000 | Loss: 1.75639 | Correct: 317/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 3100 | Loss: 1.80802 | Correct: 297/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 3200 | Loss: 1.72932 | Correct: 315/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 3300 | Loss: 1.78225 | Correct: 296/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 3400 | Loss: 1.70835 | Correct: 321/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 3500 | Loss: 1.70721 | Correct: 318/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 3600 | Loss: 1.69058 | Correct: 321/512\n",
      "Estimator: 003 | Epoch: 000 | Batch: 3700 | Loss: 1.76392 | Correct: 313/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 000 | Loss: 3.80166 | Correct: 4/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 100 | Loss: 2.46978 | Correct: 204/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 200 | Loss: 2.23063 | Correct: 227/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 300 | Loss: 2.11683 | Correct: 246/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 400 | Loss: 2.19321 | Correct: 235/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 500 | Loss: 2.11542 | Correct: 245/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 600 | Loss: 2.06382 | Correct: 245/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 700 | Loss: 1.97627 | Correct: 272/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 800 | Loss: 2.01549 | Correct: 266/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 900 | Loss: 1.87571 | Correct: 290/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 1000 | Loss: 1.87798 | Correct: 291/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 1100 | Loss: 1.82487 | Correct: 302/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 1200 | Loss: 1.91298 | Correct: 285/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 1300 | Loss: 1.81452 | Correct: 301/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 1400 | Loss: 1.79818 | Correct: 304/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 1500 | Loss: 1.82052 | Correct: 294/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 1600 | Loss: 1.89002 | Correct: 281/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 1700 | Loss: 1.85376 | Correct: 294/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 1800 | Loss: 1.78143 | Correct: 302/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 1900 | Loss: 1.84674 | Correct: 287/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 2000 | Loss: 1.84937 | Correct: 303/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 2100 | Loss: 1.65991 | Correct: 329/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 2200 | Loss: 1.77706 | Correct: 312/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 2300 | Loss: 1.78491 | Correct: 302/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 2400 | Loss: 1.89191 | Correct: 279/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 2500 | Loss: 1.79471 | Correct: 302/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 2600 | Loss: 1.78285 | Correct: 300/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 2700 | Loss: 1.85333 | Correct: 293/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 2800 | Loss: 1.77034 | Correct: 314/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 2900 | Loss: 1.77788 | Correct: 304/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 3000 | Loss: 1.78270 | Correct: 310/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 3100 | Loss: 1.67562 | Correct: 321/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 3200 | Loss: 1.71074 | Correct: 318/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 3300 | Loss: 1.74649 | Correct: 310/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 3400 | Loss: 1.81399 | Correct: 306/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 3500 | Loss: 1.82088 | Correct: 300/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 3600 | Loss: 1.72034 | Correct: 316/512\n",
      "Estimator: 004 | Epoch: 000 | Batch: 3700 | Loss: 1.77058 | Correct: 298/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 04:33:33,873 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 04:33:34,016 - INFO: Epoch: 000 | Validation Acc: 63.675 % | Historical Best: 63.675 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 001 | Batch: 000 | Loss: 1.68488 | Correct: 322/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 100 | Loss: 1.80528 | Correct: 311/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 200 | Loss: 1.74678 | Correct: 304/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 300 | Loss: 1.71058 | Correct: 318/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 400 | Loss: 1.67187 | Correct: 319/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 500 | Loss: 1.74478 | Correct: 312/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 600 | Loss: 1.78413 | Correct: 293/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 700 | Loss: 1.61722 | Correct: 339/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 800 | Loss: 1.65374 | Correct: 332/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 900 | Loss: 1.67443 | Correct: 321/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 1000 | Loss: 1.71028 | Correct: 333/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 1100 | Loss: 1.70154 | Correct: 328/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 1200 | Loss: 1.74436 | Correct: 319/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 1300 | Loss: 1.67761 | Correct: 327/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 1400 | Loss: 1.72449 | Correct: 311/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 1500 | Loss: 1.55483 | Correct: 336/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 1600 | Loss: 1.74193 | Correct: 309/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 1700 | Loss: 1.75534 | Correct: 305/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 1800 | Loss: 1.68280 | Correct: 335/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 1900 | Loss: 1.66790 | Correct: 331/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 2000 | Loss: 1.61693 | Correct: 339/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 2100 | Loss: 1.64887 | Correct: 326/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 2200 | Loss: 1.63885 | Correct: 334/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 2300 | Loss: 1.69800 | Correct: 319/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 2400 | Loss: 1.66222 | Correct: 326/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 2500 | Loss: 1.63132 | Correct: 331/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 2600 | Loss: 1.59688 | Correct: 344/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 2700 | Loss: 1.69175 | Correct: 308/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 2800 | Loss: 1.63438 | Correct: 319/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 2900 | Loss: 1.60421 | Correct: 319/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 3000 | Loss: 1.65669 | Correct: 325/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 3100 | Loss: 1.63362 | Correct: 326/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 3200 | Loss: 1.67566 | Correct: 321/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 3300 | Loss: 1.60370 | Correct: 340/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 3400 | Loss: 1.72423 | Correct: 308/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 3500 | Loss: 1.72675 | Correct: 314/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 3600 | Loss: 1.61997 | Correct: 324/512\n",
      "Estimator: 000 | Epoch: 001 | Batch: 3700 | Loss: 1.69768 | Correct: 320/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 000 | Loss: 1.67683 | Correct: 329/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 100 | Loss: 1.60441 | Correct: 336/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 200 | Loss: 1.70231 | Correct: 322/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 300 | Loss: 1.66249 | Correct: 328/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 400 | Loss: 1.69067 | Correct: 323/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 500 | Loss: 1.77719 | Correct: 304/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 600 | Loss: 1.64007 | Correct: 339/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 700 | Loss: 1.72665 | Correct: 323/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 800 | Loss: 1.79854 | Correct: 307/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 900 | Loss: 1.69044 | Correct: 316/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 1000 | Loss: 1.67240 | Correct: 327/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 1100 | Loss: 1.71440 | Correct: 323/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 1200 | Loss: 1.69424 | Correct: 316/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 1300 | Loss: 1.77097 | Correct: 322/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 1400 | Loss: 1.69809 | Correct: 317/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 1500 | Loss: 1.60442 | Correct: 335/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 1600 | Loss: 1.68858 | Correct: 321/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 1700 | Loss: 1.77403 | Correct: 307/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 1800 | Loss: 1.66916 | Correct: 311/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 1900 | Loss: 1.67588 | Correct: 328/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 2000 | Loss: 1.76601 | Correct: 303/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 2100 | Loss: 1.62133 | Correct: 327/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 2200 | Loss: 1.65741 | Correct: 320/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 2300 | Loss: 1.73282 | Correct: 308/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 2400 | Loss: 1.61714 | Correct: 346/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 2500 | Loss: 1.55639 | Correct: 347/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 2600 | Loss: 1.69760 | Correct: 311/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 2700 | Loss: 1.65724 | Correct: 326/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 2800 | Loss: 1.64260 | Correct: 333/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 2900 | Loss: 1.67178 | Correct: 318/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 3000 | Loss: 1.62844 | Correct: 341/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 3100 | Loss: 1.61752 | Correct: 328/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 3200 | Loss: 1.66176 | Correct: 321/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 3300 | Loss: 1.65717 | Correct: 330/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 3400 | Loss: 1.62692 | Correct: 332/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 3500 | Loss: 1.60698 | Correct: 329/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 3600 | Loss: 1.60959 | Correct: 335/512\n",
      "Estimator: 001 | Epoch: 001 | Batch: 3700 | Loss: 1.67056 | Correct: 322/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 000 | Loss: 1.70029 | Correct: 314/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 100 | Loss: 1.74674 | Correct: 297/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 200 | Loss: 1.73229 | Correct: 315/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 300 | Loss: 1.74125 | Correct: 307/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 400 | Loss: 1.74951 | Correct: 313/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 500 | Loss: 1.68904 | Correct: 335/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 600 | Loss: 1.63542 | Correct: 326/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 700 | Loss: 1.72453 | Correct: 318/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 800 | Loss: 1.60398 | Correct: 347/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 900 | Loss: 1.68271 | Correct: 319/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 1000 | Loss: 1.75281 | Correct: 315/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 1100 | Loss: 1.73063 | Correct: 316/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 1200 | Loss: 1.68484 | Correct: 320/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 1300 | Loss: 1.70877 | Correct: 309/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 1400 | Loss: 1.65145 | Correct: 335/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 1500 | Loss: 1.70338 | Correct: 316/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 1600 | Loss: 1.62103 | Correct: 325/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 1700 | Loss: 1.62764 | Correct: 334/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 1800 | Loss: 1.68133 | Correct: 324/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 1900 | Loss: 1.70506 | Correct: 311/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 2000 | Loss: 1.67966 | Correct: 319/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 2100 | Loss: 1.70154 | Correct: 318/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 2200 | Loss: 1.56118 | Correct: 343/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 2300 | Loss: 1.61358 | Correct: 329/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 2400 | Loss: 1.69277 | Correct: 314/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 2500 | Loss: 1.62283 | Correct: 329/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 2600 | Loss: 1.65470 | Correct: 329/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 2700 | Loss: 1.70873 | Correct: 321/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 2800 | Loss: 1.57605 | Correct: 345/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 2900 | Loss: 1.64520 | Correct: 326/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 3000 | Loss: 1.60099 | Correct: 333/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 3100 | Loss: 1.67043 | Correct: 324/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 3200 | Loss: 1.68042 | Correct: 322/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 3300 | Loss: 1.63710 | Correct: 325/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 3400 | Loss: 1.70356 | Correct: 327/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 3500 | Loss: 1.71321 | Correct: 314/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 3600 | Loss: 1.57715 | Correct: 353/512\n",
      "Estimator: 002 | Epoch: 001 | Batch: 3700 | Loss: 1.66762 | Correct: 322/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 000 | Loss: 1.72344 | Correct: 313/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 100 | Loss: 1.80914 | Correct: 312/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 200 | Loss: 1.75260 | Correct: 300/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 300 | Loss: 1.69802 | Correct: 317/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 400 | Loss: 1.68090 | Correct: 316/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 500 | Loss: 1.73104 | Correct: 303/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 600 | Loss: 1.70259 | Correct: 315/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 700 | Loss: 1.71203 | Correct: 304/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 800 | Loss: 1.71128 | Correct: 317/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 900 | Loss: 1.71200 | Correct: 314/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 1000 | Loss: 1.69128 | Correct: 333/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 1100 | Loss: 1.65478 | Correct: 316/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 1200 | Loss: 1.63105 | Correct: 332/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 1300 | Loss: 1.76185 | Correct: 316/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 1400 | Loss: 1.67160 | Correct: 329/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 1500 | Loss: 1.68707 | Correct: 313/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 1600 | Loss: 1.71417 | Correct: 314/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 1700 | Loss: 1.70586 | Correct: 318/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 1800 | Loss: 1.75223 | Correct: 298/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 1900 | Loss: 1.62744 | Correct: 321/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 2000 | Loss: 1.57455 | Correct: 341/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 2100 | Loss: 1.68777 | Correct: 312/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 2200 | Loss: 1.60707 | Correct: 341/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 2300 | Loss: 1.69279 | Correct: 320/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 2400 | Loss: 1.70552 | Correct: 317/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 2500 | Loss: 1.67123 | Correct: 324/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 2600 | Loss: 1.63328 | Correct: 330/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 2700 | Loss: 1.61755 | Correct: 337/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 2800 | Loss: 1.62865 | Correct: 335/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 2900 | Loss: 1.54445 | Correct: 334/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 3000 | Loss: 1.66815 | Correct: 321/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 3100 | Loss: 1.55691 | Correct: 344/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 3200 | Loss: 1.60907 | Correct: 321/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 3300 | Loss: 1.64473 | Correct: 327/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 3400 | Loss: 1.69751 | Correct: 326/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 3500 | Loss: 1.53793 | Correct: 344/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 3600 | Loss: 1.66615 | Correct: 322/512\n",
      "Estimator: 003 | Epoch: 001 | Batch: 3700 | Loss: 1.69899 | Correct: 325/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 000 | Loss: 1.64355 | Correct: 330/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 100 | Loss: 1.73475 | Correct: 306/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 200 | Loss: 1.71073 | Correct: 326/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 300 | Loss: 1.76278 | Correct: 305/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 400 | Loss: 1.74284 | Correct: 310/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 500 | Loss: 1.71165 | Correct: 320/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 600 | Loss: 1.65460 | Correct: 327/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 700 | Loss: 1.62114 | Correct: 343/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 800 | Loss: 1.59911 | Correct: 332/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 900 | Loss: 1.68725 | Correct: 320/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 1000 | Loss: 1.75649 | Correct: 313/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 1100 | Loss: 1.71056 | Correct: 318/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 1200 | Loss: 1.62636 | Correct: 335/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 1300 | Loss: 1.68920 | Correct: 315/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 1400 | Loss: 1.68697 | Correct: 315/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 1500 | Loss: 1.71743 | Correct: 304/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 1600 | Loss: 1.61269 | Correct: 340/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 1700 | Loss: 1.65512 | Correct: 338/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 1800 | Loss: 1.64884 | Correct: 331/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 1900 | Loss: 1.62657 | Correct: 320/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 2000 | Loss: 1.63922 | Correct: 331/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 2100 | Loss: 1.68933 | Correct: 318/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 2200 | Loss: 1.69731 | Correct: 312/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 2300 | Loss: 1.66282 | Correct: 317/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 2400 | Loss: 1.66750 | Correct: 323/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 2500 | Loss: 1.67934 | Correct: 328/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 2600 | Loss: 1.56233 | Correct: 342/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 2700 | Loss: 1.73234 | Correct: 305/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 2800 | Loss: 1.69206 | Correct: 315/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 2900 | Loss: 1.62622 | Correct: 339/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 3000 | Loss: 1.56020 | Correct: 344/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 3100 | Loss: 1.61952 | Correct: 333/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 3200 | Loss: 1.67093 | Correct: 323/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 3300 | Loss: 1.64269 | Correct: 338/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 3400 | Loss: 1.47994 | Correct: 349/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 3500 | Loss: 1.62695 | Correct: 318/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 3600 | Loss: 1.65555 | Correct: 330/512\n",
      "Estimator: 004 | Epoch: 001 | Batch: 3700 | Loss: 1.61527 | Correct: 316/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 04:36:38,686 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 04:36:38,904 - INFO: Epoch: 001 | Validation Acc: 70.808 % | Historical Best: 70.808 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 002 | Batch: 000 | Loss: 1.68038 | Correct: 325/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 100 | Loss: 1.56562 | Correct: 356/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 200 | Loss: 1.63043 | Correct: 329/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 300 | Loss: 1.55221 | Correct: 343/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 400 | Loss: 1.62874 | Correct: 330/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 500 | Loss: 1.57668 | Correct: 342/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 600 | Loss: 1.64223 | Correct: 325/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 700 | Loss: 1.59091 | Correct: 343/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 800 | Loss: 1.64411 | Correct: 327/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 900 | Loss: 1.71426 | Correct: 314/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 1000 | Loss: 1.65810 | Correct: 323/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 1100 | Loss: 1.56866 | Correct: 342/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 1200 | Loss: 1.60311 | Correct: 339/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 1300 | Loss: 1.66239 | Correct: 322/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 1400 | Loss: 1.57571 | Correct: 339/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 1500 | Loss: 1.64569 | Correct: 327/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 1600 | Loss: 1.58349 | Correct: 342/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 1700 | Loss: 1.57430 | Correct: 340/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 1800 | Loss: 1.63976 | Correct: 330/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 1900 | Loss: 1.59154 | Correct: 344/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 2000 | Loss: 1.66397 | Correct: 329/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 2100 | Loss: 1.63786 | Correct: 330/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 2200 | Loss: 1.51083 | Correct: 355/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 2300 | Loss: 1.57709 | Correct: 347/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 2400 | Loss: 1.63680 | Correct: 319/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 2500 | Loss: 1.63980 | Correct: 331/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 2600 | Loss: 1.65018 | Correct: 333/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 2700 | Loss: 1.63743 | Correct: 330/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 2800 | Loss: 1.59118 | Correct: 336/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 2900 | Loss: 1.64208 | Correct: 330/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 3000 | Loss: 1.57240 | Correct: 337/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 3100 | Loss: 1.58704 | Correct: 347/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 3200 | Loss: 1.51751 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 3300 | Loss: 1.46489 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 3400 | Loss: 1.63229 | Correct: 338/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 3500 | Loss: 1.60680 | Correct: 337/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 3600 | Loss: 1.48089 | Correct: 364/512\n",
      "Estimator: 000 | Epoch: 002 | Batch: 3700 | Loss: 1.60080 | Correct: 341/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 000 | Loss: 1.59307 | Correct: 343/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 100 | Loss: 1.62865 | Correct: 340/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 200 | Loss: 1.67352 | Correct: 325/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 300 | Loss: 1.67655 | Correct: 324/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 400 | Loss: 1.66089 | Correct: 326/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 500 | Loss: 1.58061 | Correct: 339/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 600 | Loss: 1.63974 | Correct: 326/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 700 | Loss: 1.60257 | Correct: 349/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 800 | Loss: 1.66603 | Correct: 318/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 900 | Loss: 1.70282 | Correct: 313/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 1000 | Loss: 1.52917 | Correct: 355/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 1100 | Loss: 1.55882 | Correct: 327/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 1200 | Loss: 1.63942 | Correct: 320/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 1300 | Loss: 1.55561 | Correct: 334/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 1400 | Loss: 1.70389 | Correct: 312/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 1500 | Loss: 1.55212 | Correct: 345/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 1600 | Loss: 1.64459 | Correct: 332/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 1700 | Loss: 1.62958 | Correct: 331/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 1800 | Loss: 1.53728 | Correct: 342/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 1900 | Loss: 1.69013 | Correct: 312/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 2000 | Loss: 1.62286 | Correct: 324/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 2100 | Loss: 1.57572 | Correct: 343/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 2200 | Loss: 1.58218 | Correct: 332/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 2300 | Loss: 1.52171 | Correct: 356/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 2400 | Loss: 1.67140 | Correct: 326/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 2500 | Loss: 1.63218 | Correct: 335/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 2600 | Loss: 1.60566 | Correct: 331/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 2700 | Loss: 1.71294 | Correct: 317/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 2800 | Loss: 1.59617 | Correct: 341/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 2900 | Loss: 1.62172 | Correct: 339/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 3000 | Loss: 1.71710 | Correct: 322/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 3100 | Loss: 1.60774 | Correct: 334/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 3200 | Loss: 1.52634 | Correct: 349/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 3300 | Loss: 1.68220 | Correct: 320/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 3400 | Loss: 1.55838 | Correct: 326/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 3500 | Loss: 1.60112 | Correct: 341/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 3600 | Loss: 1.60656 | Correct: 339/512\n",
      "Estimator: 001 | Epoch: 002 | Batch: 3700 | Loss: 1.54886 | Correct: 349/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 000 | Loss: 1.62888 | Correct: 323/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 100 | Loss: 1.57372 | Correct: 332/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 200 | Loss: 1.60369 | Correct: 338/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 300 | Loss: 1.64725 | Correct: 318/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 400 | Loss: 1.60214 | Correct: 339/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 500 | Loss: 1.64203 | Correct: 324/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 600 | Loss: 1.63490 | Correct: 325/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 700 | Loss: 1.55074 | Correct: 345/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 800 | Loss: 1.65729 | Correct: 327/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 900 | Loss: 1.56260 | Correct: 338/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 1000 | Loss: 1.63672 | Correct: 326/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 1100 | Loss: 1.69244 | Correct: 310/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 1200 | Loss: 1.56591 | Correct: 335/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 1300 | Loss: 1.63419 | Correct: 339/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 1400 | Loss: 1.61424 | Correct: 326/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 1500 | Loss: 1.60293 | Correct: 343/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 1600 | Loss: 1.56175 | Correct: 343/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 1700 | Loss: 1.60815 | Correct: 333/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 1800 | Loss: 1.56307 | Correct: 330/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 1900 | Loss: 1.67643 | Correct: 328/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 2000 | Loss: 1.53600 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 2100 | Loss: 1.53762 | Correct: 347/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 2200 | Loss: 1.62149 | Correct: 331/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 2300 | Loss: 1.57878 | Correct: 340/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 2400 | Loss: 1.64166 | Correct: 323/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 2500 | Loss: 1.62730 | Correct: 340/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 2600 | Loss: 1.61473 | Correct: 341/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 2700 | Loss: 1.58735 | Correct: 339/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 2800 | Loss: 1.60958 | Correct: 340/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 2900 | Loss: 1.63541 | Correct: 329/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 3000 | Loss: 1.59122 | Correct: 335/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 3100 | Loss: 1.62745 | Correct: 325/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 3200 | Loss: 1.56776 | Correct: 337/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 3300 | Loss: 1.61151 | Correct: 324/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 3400 | Loss: 1.59547 | Correct: 325/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 3500 | Loss: 1.55604 | Correct: 343/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 3600 | Loss: 1.53228 | Correct: 353/512\n",
      "Estimator: 002 | Epoch: 002 | Batch: 3700 | Loss: 1.58724 | Correct: 327/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 000 | Loss: 1.57123 | Correct: 341/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 100 | Loss: 1.68781 | Correct: 326/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 200 | Loss: 1.62803 | Correct: 318/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 300 | Loss: 1.62783 | Correct: 319/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 400 | Loss: 1.64313 | Correct: 323/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 500 | Loss: 1.54710 | Correct: 329/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 600 | Loss: 1.61756 | Correct: 331/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 700 | Loss: 1.67832 | Correct: 320/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 800 | Loss: 1.60701 | Correct: 331/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 900 | Loss: 1.64395 | Correct: 315/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 1000 | Loss: 1.62109 | Correct: 332/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 1100 | Loss: 1.72517 | Correct: 318/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 1200 | Loss: 1.64870 | Correct: 332/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 1300 | Loss: 1.66836 | Correct: 332/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 1400 | Loss: 1.62036 | Correct: 333/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 1500 | Loss: 1.63621 | Correct: 333/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 1600 | Loss: 1.64023 | Correct: 332/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 1700 | Loss: 1.54027 | Correct: 336/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 1800 | Loss: 1.58608 | Correct: 339/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 1900 | Loss: 1.65074 | Correct: 326/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 2000 | Loss: 1.61452 | Correct: 331/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 2100 | Loss: 1.63371 | Correct: 333/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 2200 | Loss: 1.62365 | Correct: 317/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 2300 | Loss: 1.57201 | Correct: 339/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 2400 | Loss: 1.64451 | Correct: 337/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 2500 | Loss: 1.58008 | Correct: 335/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 2600 | Loss: 1.60398 | Correct: 342/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 2700 | Loss: 1.57003 | Correct: 346/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 2800 | Loss: 1.59237 | Correct: 338/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 2900 | Loss: 1.63614 | Correct: 337/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 3000 | Loss: 1.65161 | Correct: 322/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 3100 | Loss: 1.67954 | Correct: 322/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 3200 | Loss: 1.55300 | Correct: 346/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 3300 | Loss: 1.50415 | Correct: 355/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 3400 | Loss: 1.55756 | Correct: 342/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 3500 | Loss: 1.61163 | Correct: 335/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 3600 | Loss: 1.61249 | Correct: 326/512\n",
      "Estimator: 003 | Epoch: 002 | Batch: 3700 | Loss: 1.55380 | Correct: 358/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 000 | Loss: 1.65565 | Correct: 330/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 100 | Loss: 1.54915 | Correct: 353/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 200 | Loss: 1.51144 | Correct: 356/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 300 | Loss: 1.59435 | Correct: 344/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 400 | Loss: 1.68561 | Correct: 314/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 500 | Loss: 1.52978 | Correct: 349/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 600 | Loss: 1.54633 | Correct: 334/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 700 | Loss: 1.66601 | Correct: 324/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 800 | Loss: 1.60136 | Correct: 328/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 900 | Loss: 1.65216 | Correct: 309/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 1000 | Loss: 1.65643 | Correct: 314/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 1100 | Loss: 1.60483 | Correct: 334/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 1200 | Loss: 1.64983 | Correct: 333/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 1300 | Loss: 1.58216 | Correct: 337/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 1400 | Loss: 1.64768 | Correct: 317/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 1500 | Loss: 1.62074 | Correct: 322/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 1600 | Loss: 1.66708 | Correct: 313/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 1700 | Loss: 1.64662 | Correct: 328/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 1800 | Loss: 1.67557 | Correct: 327/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 1900 | Loss: 1.62220 | Correct: 339/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 2000 | Loss: 1.60569 | Correct: 338/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 2100 | Loss: 1.59178 | Correct: 348/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 2200 | Loss: 1.60309 | Correct: 341/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 2300 | Loss: 1.62662 | Correct: 334/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 2400 | Loss: 1.59430 | Correct: 341/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 2500 | Loss: 1.61607 | Correct: 339/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 2600 | Loss: 1.66172 | Correct: 326/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 2700 | Loss: 1.55583 | Correct: 337/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 2800 | Loss: 1.63358 | Correct: 319/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 2900 | Loss: 1.54398 | Correct: 349/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 3000 | Loss: 1.67741 | Correct: 326/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 3100 | Loss: 1.62335 | Correct: 328/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 3200 | Loss: 1.57223 | Correct: 335/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 3300 | Loss: 1.55533 | Correct: 331/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 3400 | Loss: 1.61745 | Correct: 343/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 3500 | Loss: 1.58782 | Correct: 349/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 3600 | Loss: 1.59985 | Correct: 334/512\n",
      "Estimator: 004 | Epoch: 002 | Batch: 3700 | Loss: 1.52251 | Correct: 356/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 04:39:43,827 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 04:39:44,042 - INFO: Epoch: 002 | Validation Acc: 72.741 % | Historical Best: 72.741 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 003 | Batch: 000 | Loss: 1.52985 | Correct: 341/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 100 | Loss: 1.53377 | Correct: 353/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 200 | Loss: 1.59223 | Correct: 333/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 300 | Loss: 1.57232 | Correct: 337/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 400 | Loss: 1.58101 | Correct: 341/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 500 | Loss: 1.60785 | Correct: 323/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 600 | Loss: 1.61097 | Correct: 318/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 700 | Loss: 1.55445 | Correct: 337/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 800 | Loss: 1.56530 | Correct: 344/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 900 | Loss: 1.49598 | Correct: 349/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 1000 | Loss: 1.54798 | Correct: 349/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 1100 | Loss: 1.55849 | Correct: 348/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 1200 | Loss: 1.57397 | Correct: 328/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 1300 | Loss: 1.64656 | Correct: 335/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 1400 | Loss: 1.53205 | Correct: 349/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 1500 | Loss: 1.56599 | Correct: 348/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 1600 | Loss: 1.54881 | Correct: 348/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 1700 | Loss: 1.55089 | Correct: 332/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 1800 | Loss: 1.54288 | Correct: 344/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 1900 | Loss: 1.58435 | Correct: 340/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 2000 | Loss: 1.62660 | Correct: 328/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 2100 | Loss: 1.56043 | Correct: 338/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 2200 | Loss: 1.52147 | Correct: 348/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 2300 | Loss: 1.57665 | Correct: 347/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 2400 | Loss: 1.53650 | Correct: 342/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 2500 | Loss: 1.53110 | Correct: 346/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 2600 | Loss: 1.57823 | Correct: 336/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 2700 | Loss: 1.48947 | Correct: 345/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 2800 | Loss: 1.52434 | Correct: 344/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 2900 | Loss: 1.52090 | Correct: 342/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 3000 | Loss: 1.48667 | Correct: 353/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 3100 | Loss: 1.54084 | Correct: 338/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 3200 | Loss: 1.63147 | Correct: 327/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 3300 | Loss: 1.61459 | Correct: 327/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 3400 | Loss: 1.46717 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 3500 | Loss: 1.54957 | Correct: 344/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 3600 | Loss: 1.58238 | Correct: 333/512\n",
      "Estimator: 000 | Epoch: 003 | Batch: 3700 | Loss: 1.52445 | Correct: 352/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 000 | Loss: 1.57501 | Correct: 351/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 100 | Loss: 1.53865 | Correct: 343/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 200 | Loss: 1.56525 | Correct: 349/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 300 | Loss: 1.56004 | Correct: 344/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 400 | Loss: 1.56168 | Correct: 338/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 500 | Loss: 1.61340 | Correct: 328/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 600 | Loss: 1.58598 | Correct: 350/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 700 | Loss: 1.59095 | Correct: 342/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 800 | Loss: 1.60840 | Correct: 323/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 900 | Loss: 1.58222 | Correct: 342/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 1000 | Loss: 1.61214 | Correct: 335/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 1100 | Loss: 1.57439 | Correct: 345/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 1200 | Loss: 1.54137 | Correct: 352/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 1300 | Loss: 1.57443 | Correct: 331/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 1400 | Loss: 1.45155 | Correct: 355/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 1500 | Loss: 1.60674 | Correct: 325/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 1600 | Loss: 1.55575 | Correct: 342/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 1700 | Loss: 1.56931 | Correct: 334/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 1800 | Loss: 1.56778 | Correct: 338/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 1900 | Loss: 1.57276 | Correct: 347/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 2000 | Loss: 1.51001 | Correct: 356/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 2100 | Loss: 1.56313 | Correct: 349/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 2200 | Loss: 1.53467 | Correct: 341/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 2300 | Loss: 1.50241 | Correct: 345/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 2400 | Loss: 1.60963 | Correct: 324/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 2500 | Loss: 1.60218 | Correct: 338/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 2600 | Loss: 1.69410 | Correct: 317/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 2700 | Loss: 1.52923 | Correct: 342/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 2800 | Loss: 1.52185 | Correct: 355/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 2900 | Loss: 1.56992 | Correct: 341/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 3000 | Loss: 1.49291 | Correct: 355/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 3100 | Loss: 1.58095 | Correct: 336/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 3200 | Loss: 1.60565 | Correct: 324/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 3300 | Loss: 1.48158 | Correct: 351/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 3400 | Loss: 1.58161 | Correct: 331/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 3500 | Loss: 1.44123 | Correct: 356/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 3600 | Loss: 1.57477 | Correct: 339/512\n",
      "Estimator: 001 | Epoch: 003 | Batch: 3700 | Loss: 1.55691 | Correct: 345/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 000 | Loss: 1.62656 | Correct: 328/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 100 | Loss: 1.54918 | Correct: 345/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 200 | Loss: 1.53761 | Correct: 346/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 300 | Loss: 1.54034 | Correct: 354/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 400 | Loss: 1.56182 | Correct: 344/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 500 | Loss: 1.52187 | Correct: 346/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 600 | Loss: 1.66825 | Correct: 330/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 700 | Loss: 1.58977 | Correct: 340/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 800 | Loss: 1.64857 | Correct: 328/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 900 | Loss: 1.57991 | Correct: 341/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 1000 | Loss: 1.65491 | Correct: 319/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 1100 | Loss: 1.55688 | Correct: 355/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 1200 | Loss: 1.58172 | Correct: 338/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 1300 | Loss: 1.56583 | Correct: 335/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 1400 | Loss: 1.52713 | Correct: 347/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 1500 | Loss: 1.63637 | Correct: 322/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 1600 | Loss: 1.52920 | Correct: 342/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 1700 | Loss: 1.63707 | Correct: 332/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 1800 | Loss: 1.68351 | Correct: 315/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 1900 | Loss: 1.54615 | Correct: 351/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 2000 | Loss: 1.58911 | Correct: 336/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 2100 | Loss: 1.52838 | Correct: 338/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 2200 | Loss: 1.54936 | Correct: 333/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 2300 | Loss: 1.60783 | Correct: 338/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 2400 | Loss: 1.54787 | Correct: 336/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 2500 | Loss: 1.50953 | Correct: 346/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 2600 | Loss: 1.51677 | Correct: 345/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 2700 | Loss: 1.55594 | Correct: 342/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 2800 | Loss: 1.57530 | Correct: 351/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 2900 | Loss: 1.56900 | Correct: 335/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 3000 | Loss: 1.54324 | Correct: 350/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 3100 | Loss: 1.51587 | Correct: 351/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 3200 | Loss: 1.55081 | Correct: 343/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 3300 | Loss: 1.54200 | Correct: 353/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 3400 | Loss: 1.51654 | Correct: 364/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 3500 | Loss: 1.54662 | Correct: 342/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 3600 | Loss: 1.47015 | Correct: 356/512\n",
      "Estimator: 002 | Epoch: 003 | Batch: 3700 | Loss: 1.50820 | Correct: 348/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 000 | Loss: 1.51555 | Correct: 348/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 100 | Loss: 1.61349 | Correct: 322/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 200 | Loss: 1.67069 | Correct: 323/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 300 | Loss: 1.56681 | Correct: 343/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 400 | Loss: 1.58415 | Correct: 344/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 500 | Loss: 1.54595 | Correct: 348/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 600 | Loss: 1.60337 | Correct: 347/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 700 | Loss: 1.57032 | Correct: 345/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 800 | Loss: 1.47193 | Correct: 352/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 900 | Loss: 1.58398 | Correct: 336/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 1000 | Loss: 1.58422 | Correct: 326/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 1100 | Loss: 1.53558 | Correct: 352/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 1200 | Loss: 1.56906 | Correct: 349/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 1300 | Loss: 1.46361 | Correct: 357/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 1400 | Loss: 1.56933 | Correct: 341/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 1500 | Loss: 1.60499 | Correct: 326/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 1600 | Loss: 1.56960 | Correct: 343/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 1700 | Loss: 1.50032 | Correct: 347/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 1800 | Loss: 1.55645 | Correct: 339/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 1900 | Loss: 1.60798 | Correct: 338/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 2000 | Loss: 1.53247 | Correct: 341/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 2100 | Loss: 1.56010 | Correct: 343/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 2200 | Loss: 1.58548 | Correct: 326/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 2300 | Loss: 1.46315 | Correct: 360/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 2400 | Loss: 1.53105 | Correct: 337/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 2500 | Loss: 1.49459 | Correct: 347/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 2600 | Loss: 1.55321 | Correct: 336/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 2700 | Loss: 1.54614 | Correct: 340/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 2800 | Loss: 1.54117 | Correct: 344/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 2900 | Loss: 1.54644 | Correct: 354/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 3000 | Loss: 1.56065 | Correct: 333/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 3100 | Loss: 1.53520 | Correct: 344/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 3200 | Loss: 1.55023 | Correct: 341/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 3300 | Loss: 1.60729 | Correct: 344/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 3400 | Loss: 1.53823 | Correct: 342/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 3500 | Loss: 1.51310 | Correct: 348/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 3600 | Loss: 1.51211 | Correct: 346/512\n",
      "Estimator: 003 | Epoch: 003 | Batch: 3700 | Loss: 1.58696 | Correct: 336/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 000 | Loss: 1.58940 | Correct: 337/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 100 | Loss: 1.58300 | Correct: 334/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 200 | Loss: 1.57244 | Correct: 337/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 300 | Loss: 1.54107 | Correct: 351/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 400 | Loss: 1.64632 | Correct: 329/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 500 | Loss: 1.54040 | Correct: 356/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 600 | Loss: 1.62431 | Correct: 335/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 700 | Loss: 1.53329 | Correct: 356/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 800 | Loss: 1.63423 | Correct: 327/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 900 | Loss: 1.50952 | Correct: 350/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 1000 | Loss: 1.46859 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 1100 | Loss: 1.53037 | Correct: 339/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 1200 | Loss: 1.56007 | Correct: 339/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 1300 | Loss: 1.57038 | Correct: 333/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 1400 | Loss: 1.50274 | Correct: 356/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 1500 | Loss: 1.58711 | Correct: 346/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 1600 | Loss: 1.58339 | Correct: 344/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 1700 | Loss: 1.59779 | Correct: 323/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 1800 | Loss: 1.52225 | Correct: 353/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 1900 | Loss: 1.46514 | Correct: 347/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 2000 | Loss: 1.49625 | Correct: 350/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 2100 | Loss: 1.59203 | Correct: 330/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 2200 | Loss: 1.65471 | Correct: 326/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 2300 | Loss: 1.65047 | Correct: 340/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 2400 | Loss: 1.59997 | Correct: 334/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 2500 | Loss: 1.57571 | Correct: 354/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 2600 | Loss: 1.50057 | Correct: 349/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 2700 | Loss: 1.55454 | Correct: 350/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 2800 | Loss: 1.60476 | Correct: 332/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 2900 | Loss: 1.62093 | Correct: 329/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 3000 | Loss: 1.53431 | Correct: 354/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 3100 | Loss: 1.55590 | Correct: 333/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 3200 | Loss: 1.51718 | Correct: 342/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 3300 | Loss: 1.61084 | Correct: 336/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 3400 | Loss: 1.50741 | Correct: 347/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 3500 | Loss: 1.49148 | Correct: 363/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 3600 | Loss: 1.51089 | Correct: 346/512\n",
      "Estimator: 004 | Epoch: 003 | Batch: 3700 | Loss: 1.57058 | Correct: 355/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 04:42:47,980 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 04:42:48,200 - INFO: Epoch: 003 | Validation Acc: 74.215 % | Historical Best: 74.215 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 004 | Batch: 000 | Loss: 1.56120 | Correct: 354/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 100 | Loss: 1.47523 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 200 | Loss: 1.49897 | Correct: 349/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 300 | Loss: 1.59415 | Correct: 347/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 400 | Loss: 1.54838 | Correct: 353/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 500 | Loss: 1.54026 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 600 | Loss: 1.47713 | Correct: 364/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 700 | Loss: 1.49127 | Correct: 353/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 800 | Loss: 1.57342 | Correct: 343/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 900 | Loss: 1.51330 | Correct: 353/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 1000 | Loss: 1.47076 | Correct: 363/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 1100 | Loss: 1.46287 | Correct: 369/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 1200 | Loss: 1.51224 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 1300 | Loss: 1.51711 | Correct: 349/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 1400 | Loss: 1.54301 | Correct: 352/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 1500 | Loss: 1.56211 | Correct: 344/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 1600 | Loss: 1.58325 | Correct: 338/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 1700 | Loss: 1.53126 | Correct: 343/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 1800 | Loss: 1.52072 | Correct: 345/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 1900 | Loss: 1.52085 | Correct: 355/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 2000 | Loss: 1.55040 | Correct: 355/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 2100 | Loss: 1.54178 | Correct: 342/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 2200 | Loss: 1.52374 | Correct: 339/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 2300 | Loss: 1.51951 | Correct: 348/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 2400 | Loss: 1.50254 | Correct: 351/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 2500 | Loss: 1.56047 | Correct: 351/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 2600 | Loss: 1.44320 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 2700 | Loss: 1.49875 | Correct: 351/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 2800 | Loss: 1.54961 | Correct: 349/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 2900 | Loss: 1.59085 | Correct: 339/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 3000 | Loss: 1.56337 | Correct: 345/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 3100 | Loss: 1.50156 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 3200 | Loss: 1.53146 | Correct: 355/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 3300 | Loss: 1.54708 | Correct: 355/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 3400 | Loss: 1.50822 | Correct: 350/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 3500 | Loss: 1.45850 | Correct: 359/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 3600 | Loss: 1.51996 | Correct: 340/512\n",
      "Estimator: 000 | Epoch: 004 | Batch: 3700 | Loss: 1.44319 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 000 | Loss: 1.56762 | Correct: 338/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 100 | Loss: 1.59869 | Correct: 339/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 200 | Loss: 1.50305 | Correct: 347/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 300 | Loss: 1.50824 | Correct: 347/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 400 | Loss: 1.52352 | Correct: 361/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 500 | Loss: 1.65770 | Correct: 324/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 600 | Loss: 1.49354 | Correct: 355/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 700 | Loss: 1.55631 | Correct: 346/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 800 | Loss: 1.57704 | Correct: 331/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 900 | Loss: 1.60776 | Correct: 325/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 1000 | Loss: 1.52683 | Correct: 344/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 1100 | Loss: 1.49375 | Correct: 359/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 1200 | Loss: 1.61622 | Correct: 324/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 1300 | Loss: 1.51740 | Correct: 357/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 1400 | Loss: 1.56830 | Correct: 338/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 1500 | Loss: 1.54528 | Correct: 342/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 1600 | Loss: 1.47837 | Correct: 359/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 1700 | Loss: 1.50889 | Correct: 353/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 1800 | Loss: 1.44412 | Correct: 374/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 1900 | Loss: 1.50186 | Correct: 353/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 2000 | Loss: 1.53502 | Correct: 345/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 2100 | Loss: 1.58362 | Correct: 338/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 2200 | Loss: 1.52990 | Correct: 352/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 2300 | Loss: 1.56240 | Correct: 340/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 2400 | Loss: 1.49095 | Correct: 351/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 2500 | Loss: 1.54548 | Correct: 338/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 2600 | Loss: 1.52176 | Correct: 354/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 2700 | Loss: 1.57019 | Correct: 343/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 2800 | Loss: 1.50698 | Correct: 354/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 2900 | Loss: 1.51367 | Correct: 348/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 3000 | Loss: 1.55784 | Correct: 346/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 3100 | Loss: 1.44491 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 3200 | Loss: 1.56277 | Correct: 350/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 3300 | Loss: 1.49265 | Correct: 357/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 3400 | Loss: 1.52637 | Correct: 348/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 3500 | Loss: 1.51068 | Correct: 348/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 3600 | Loss: 1.53351 | Correct: 343/512\n",
      "Estimator: 001 | Epoch: 004 | Batch: 3700 | Loss: 1.54817 | Correct: 351/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 000 | Loss: 1.42795 | Correct: 358/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 100 | Loss: 1.59592 | Correct: 329/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 200 | Loss: 1.63941 | Correct: 329/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 300 | Loss: 1.62506 | Correct: 339/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 400 | Loss: 1.61957 | Correct: 331/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 500 | Loss: 1.52450 | Correct: 357/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 600 | Loss: 1.66315 | Correct: 321/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 700 | Loss: 1.51429 | Correct: 345/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 800 | Loss: 1.54963 | Correct: 332/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 900 | Loss: 1.54570 | Correct: 347/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 1000 | Loss: 1.58164 | Correct: 337/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 1100 | Loss: 1.49560 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 1200 | Loss: 1.54367 | Correct: 344/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 1300 | Loss: 1.52982 | Correct: 356/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 1400 | Loss: 1.42281 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 1500 | Loss: 1.48565 | Correct: 364/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 1600 | Loss: 1.58341 | Correct: 336/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 1700 | Loss: 1.60254 | Correct: 330/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 1800 | Loss: 1.51401 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 1900 | Loss: 1.53904 | Correct: 344/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 2000 | Loss: 1.48438 | Correct: 364/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 2100 | Loss: 1.54079 | Correct: 338/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 2200 | Loss: 1.53221 | Correct: 353/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 2300 | Loss: 1.46357 | Correct: 355/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 2400 | Loss: 1.51805 | Correct: 349/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 2500 | Loss: 1.49176 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 2600 | Loss: 1.46813 | Correct: 364/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 2700 | Loss: 1.58516 | Correct: 334/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 2800 | Loss: 1.52789 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 2900 | Loss: 1.50285 | Correct: 357/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 3000 | Loss: 1.61379 | Correct: 331/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 3100 | Loss: 1.54379 | Correct: 363/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 3200 | Loss: 1.46490 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 3300 | Loss: 1.51609 | Correct: 344/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 3400 | Loss: 1.47669 | Correct: 361/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 3500 | Loss: 1.54465 | Correct: 348/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 3600 | Loss: 1.53403 | Correct: 340/512\n",
      "Estimator: 002 | Epoch: 004 | Batch: 3700 | Loss: 1.52959 | Correct: 353/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 000 | Loss: 1.49640 | Correct: 353/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 100 | Loss: 1.57024 | Correct: 343/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 200 | Loss: 1.53953 | Correct: 343/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 300 | Loss: 1.57038 | Correct: 345/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 400 | Loss: 1.54192 | Correct: 336/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 500 | Loss: 1.58843 | Correct: 346/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 600 | Loss: 1.58964 | Correct: 337/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 700 | Loss: 1.53275 | Correct: 343/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 800 | Loss: 1.53561 | Correct: 339/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 900 | Loss: 1.51916 | Correct: 348/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 1000 | Loss: 1.51784 | Correct: 356/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 1100 | Loss: 1.55850 | Correct: 345/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 1200 | Loss: 1.47758 | Correct: 357/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 1300 | Loss: 1.50877 | Correct: 351/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 1400 | Loss: 1.51254 | Correct: 349/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 1500 | Loss: 1.47779 | Correct: 350/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 1600 | Loss: 1.54146 | Correct: 337/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 1700 | Loss: 1.50878 | Correct: 351/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 1800 | Loss: 1.48367 | Correct: 349/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 1900 | Loss: 1.56067 | Correct: 341/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 2000 | Loss: 1.55280 | Correct: 348/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 2100 | Loss: 1.49652 | Correct: 367/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 2200 | Loss: 1.53540 | Correct: 345/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 2300 | Loss: 1.53888 | Correct: 333/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 2400 | Loss: 1.54741 | Correct: 346/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 2500 | Loss: 1.57910 | Correct: 340/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 2600 | Loss: 1.54842 | Correct: 343/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 2700 | Loss: 1.54122 | Correct: 341/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 2800 | Loss: 1.48157 | Correct: 347/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 2900 | Loss: 1.44481 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 3000 | Loss: 1.46956 | Correct: 355/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 3100 | Loss: 1.53723 | Correct: 340/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 3200 | Loss: 1.53478 | Correct: 353/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 3300 | Loss: 1.50773 | Correct: 354/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 3400 | Loss: 1.55042 | Correct: 353/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 3500 | Loss: 1.60036 | Correct: 334/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 3600 | Loss: 1.47254 | Correct: 358/512\n",
      "Estimator: 003 | Epoch: 004 | Batch: 3700 | Loss: 1.48427 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 000 | Loss: 1.58123 | Correct: 322/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 100 | Loss: 1.53791 | Correct: 355/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 200 | Loss: 1.51724 | Correct: 351/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 300 | Loss: 1.50929 | Correct: 356/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 400 | Loss: 1.52820 | Correct: 354/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 500 | Loss: 1.45931 | Correct: 364/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 600 | Loss: 1.50753 | Correct: 339/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 700 | Loss: 1.51578 | Correct: 350/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 800 | Loss: 1.56622 | Correct: 339/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 900 | Loss: 1.62466 | Correct: 338/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 1000 | Loss: 1.48060 | Correct: 360/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 1100 | Loss: 1.52255 | Correct: 351/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 1200 | Loss: 1.49608 | Correct: 347/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 1300 | Loss: 1.46467 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 1400 | Loss: 1.58678 | Correct: 337/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 1500 | Loss: 1.55292 | Correct: 351/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 1600 | Loss: 1.52466 | Correct: 355/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 1700 | Loss: 1.56956 | Correct: 340/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 1800 | Loss: 1.51381 | Correct: 353/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 1900 | Loss: 1.56594 | Correct: 339/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 2000 | Loss: 1.54897 | Correct: 344/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 2100 | Loss: 1.53830 | Correct: 345/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 2200 | Loss: 1.59312 | Correct: 341/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 2300 | Loss: 1.54539 | Correct: 344/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 2400 | Loss: 1.60359 | Correct: 333/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 2500 | Loss: 1.51863 | Correct: 347/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 2600 | Loss: 1.46240 | Correct: 371/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 2700 | Loss: 1.46938 | Correct: 364/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 2800 | Loss: 1.52604 | Correct: 347/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 2900 | Loss: 1.58518 | Correct: 335/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 3000 | Loss: 1.50996 | Correct: 353/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 3100 | Loss: 1.53503 | Correct: 343/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 3200 | Loss: 1.54140 | Correct: 351/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 3300 | Loss: 1.54470 | Correct: 347/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 3400 | Loss: 1.55232 | Correct: 349/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 3500 | Loss: 1.50242 | Correct: 351/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 3600 | Loss: 1.56141 | Correct: 335/512\n",
      "Estimator: 004 | Epoch: 004 | Batch: 3700 | Loss: 1.48378 | Correct: 358/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 04:45:52,014 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 04:45:52,237 - INFO: Epoch: 004 | Validation Acc: 75.327 % | Historical Best: 75.327 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 005 | Batch: 000 | Loss: 1.44118 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 100 | Loss: 1.52573 | Correct: 345/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 200 | Loss: 1.51085 | Correct: 351/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 300 | Loss: 1.53285 | Correct: 336/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 400 | Loss: 1.43294 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 500 | Loss: 1.47643 | Correct: 345/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 600 | Loss: 1.54852 | Correct: 342/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 700 | Loss: 1.56666 | Correct: 345/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 800 | Loss: 1.42912 | Correct: 373/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 900 | Loss: 1.54165 | Correct: 333/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 1000 | Loss: 1.52300 | Correct: 339/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 1100 | Loss: 1.48842 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 1200 | Loss: 1.52708 | Correct: 339/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 1300 | Loss: 1.49214 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 1400 | Loss: 1.53541 | Correct: 349/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 1500 | Loss: 1.42553 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 1600 | Loss: 1.49293 | Correct: 349/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 1700 | Loss: 1.59164 | Correct: 336/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 1800 | Loss: 1.60090 | Correct: 338/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 1900 | Loss: 1.54197 | Correct: 353/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 2000 | Loss: 1.44300 | Correct: 364/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 2100 | Loss: 1.49342 | Correct: 342/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 2200 | Loss: 1.51132 | Correct: 350/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 2300 | Loss: 1.53831 | Correct: 334/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 2400 | Loss: 1.43266 | Correct: 363/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 2500 | Loss: 1.44981 | Correct: 361/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 2600 | Loss: 1.43513 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 2700 | Loss: 1.48722 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 2800 | Loss: 1.48155 | Correct: 347/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 2900 | Loss: 1.48222 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 3000 | Loss: 1.44402 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 3100 | Loss: 1.54986 | Correct: 343/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 3200 | Loss: 1.49858 | Correct: 352/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 3300 | Loss: 1.42705 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 3400 | Loss: 1.48283 | Correct: 349/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 3500 | Loss: 1.61229 | Correct: 331/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 3600 | Loss: 1.48629 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 005 | Batch: 3700 | Loss: 1.44650 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 000 | Loss: 1.42849 | Correct: 360/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 100 | Loss: 1.49816 | Correct: 363/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 200 | Loss: 1.52712 | Correct: 352/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 300 | Loss: 1.45925 | Correct: 361/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 400 | Loss: 1.45436 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 500 | Loss: 1.49007 | Correct: 344/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 600 | Loss: 1.56279 | Correct: 338/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 700 | Loss: 1.61245 | Correct: 337/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 800 | Loss: 1.42784 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 900 | Loss: 1.44469 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 1000 | Loss: 1.45445 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 1100 | Loss: 1.51345 | Correct: 353/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 1200 | Loss: 1.49299 | Correct: 358/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 1300 | Loss: 1.51543 | Correct: 357/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 1400 | Loss: 1.54510 | Correct: 349/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 1500 | Loss: 1.45494 | Correct: 363/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 1600 | Loss: 1.46408 | Correct: 350/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 1700 | Loss: 1.46315 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 1800 | Loss: 1.45429 | Correct: 359/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 1900 | Loss: 1.51841 | Correct: 340/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 2000 | Loss: 1.47493 | Correct: 354/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 2100 | Loss: 1.47890 | Correct: 353/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 2200 | Loss: 1.52005 | Correct: 350/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 2300 | Loss: 1.59005 | Correct: 328/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 2400 | Loss: 1.51167 | Correct: 351/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 2500 | Loss: 1.55569 | Correct: 338/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 2600 | Loss: 1.48519 | Correct: 347/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 2700 | Loss: 1.56545 | Correct: 333/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 2800 | Loss: 1.50021 | Correct: 359/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 2900 | Loss: 1.50072 | Correct: 355/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 3000 | Loss: 1.42609 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 3100 | Loss: 1.45665 | Correct: 360/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 3200 | Loss: 1.47195 | Correct: 360/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 3300 | Loss: 1.46944 | Correct: 356/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 3400 | Loss: 1.57429 | Correct: 352/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 3500 | Loss: 1.46969 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 3600 | Loss: 1.49735 | Correct: 357/512\n",
      "Estimator: 001 | Epoch: 005 | Batch: 3700 | Loss: 1.47075 | Correct: 356/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 000 | Loss: 1.51292 | Correct: 349/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 100 | Loss: 1.46045 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 200 | Loss: 1.52833 | Correct: 353/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 300 | Loss: 1.47900 | Correct: 361/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 400 | Loss: 1.51143 | Correct: 361/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 500 | Loss: 1.53361 | Correct: 360/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 600 | Loss: 1.51893 | Correct: 360/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 700 | Loss: 1.45906 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 800 | Loss: 1.52366 | Correct: 345/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 900 | Loss: 1.44742 | Correct: 354/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 1000 | Loss: 1.49821 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 1100 | Loss: 1.51188 | Correct: 347/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 1200 | Loss: 1.48994 | Correct: 358/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 1300 | Loss: 1.58094 | Correct: 343/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 1400 | Loss: 1.49809 | Correct: 348/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 1500 | Loss: 1.50732 | Correct: 358/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 1600 | Loss: 1.55632 | Correct: 337/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 1700 | Loss: 1.52321 | Correct: 350/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 1800 | Loss: 1.54130 | Correct: 342/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 1900 | Loss: 1.42159 | Correct: 382/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 2000 | Loss: 1.49021 | Correct: 355/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 2100 | Loss: 1.50665 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 2200 | Loss: 1.46585 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 2300 | Loss: 1.46993 | Correct: 362/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 2400 | Loss: 1.54059 | Correct: 358/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 2500 | Loss: 1.49990 | Correct: 356/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 2600 | Loss: 1.47130 | Correct: 370/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 2700 | Loss: 1.48992 | Correct: 354/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 2800 | Loss: 1.49350 | Correct: 361/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 2900 | Loss: 1.50743 | Correct: 350/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 3000 | Loss: 1.47531 | Correct: 369/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 3100 | Loss: 1.54201 | Correct: 357/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 3200 | Loss: 1.46111 | Correct: 357/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 3300 | Loss: 1.48741 | Correct: 361/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 3400 | Loss: 1.48125 | Correct: 351/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 3500 | Loss: 1.55178 | Correct: 345/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 3600 | Loss: 1.54324 | Correct: 356/512\n",
      "Estimator: 002 | Epoch: 005 | Batch: 3700 | Loss: 1.50845 | Correct: 353/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 000 | Loss: 1.56107 | Correct: 344/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 100 | Loss: 1.45804 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 200 | Loss: 1.60367 | Correct: 328/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 300 | Loss: 1.51746 | Correct: 338/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 400 | Loss: 1.61457 | Correct: 330/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 500 | Loss: 1.53133 | Correct: 353/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 600 | Loss: 1.47155 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 700 | Loss: 1.46091 | Correct: 354/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 800 | Loss: 1.59141 | Correct: 325/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 900 | Loss: 1.46183 | Correct: 351/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 1000 | Loss: 1.47306 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 1100 | Loss: 1.48012 | Correct: 350/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 1200 | Loss: 1.49212 | Correct: 354/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 1300 | Loss: 1.45569 | Correct: 357/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 1400 | Loss: 1.50030 | Correct: 352/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 1500 | Loss: 1.56416 | Correct: 343/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 1600 | Loss: 1.60599 | Correct: 349/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 1700 | Loss: 1.50106 | Correct: 345/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 1800 | Loss: 1.51119 | Correct: 345/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 1900 | Loss: 1.55921 | Correct: 344/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 2000 | Loss: 1.54279 | Correct: 351/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 2100 | Loss: 1.50417 | Correct: 355/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 2200 | Loss: 1.50864 | Correct: 352/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 2300 | Loss: 1.53231 | Correct: 349/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 2400 | Loss: 1.51992 | Correct: 346/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 2500 | Loss: 1.47674 | Correct: 361/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 2600 | Loss: 1.45146 | Correct: 369/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 2700 | Loss: 1.51698 | Correct: 357/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 2800 | Loss: 1.48368 | Correct: 354/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 2900 | Loss: 1.47818 | Correct: 355/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 3000 | Loss: 1.40974 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 3100 | Loss: 1.50837 | Correct: 358/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 3200 | Loss: 1.43512 | Correct: 363/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 3300 | Loss: 1.37037 | Correct: 368/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 3400 | Loss: 1.48906 | Correct: 353/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 3500 | Loss: 1.63048 | Correct: 331/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 3600 | Loss: 1.47456 | Correct: 362/512\n",
      "Estimator: 003 | Epoch: 005 | Batch: 3700 | Loss: 1.49712 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 000 | Loss: 1.42049 | Correct: 367/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 100 | Loss: 1.57513 | Correct: 330/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 200 | Loss: 1.51460 | Correct: 353/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 300 | Loss: 1.47254 | Correct: 355/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 400 | Loss: 1.50064 | Correct: 357/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 500 | Loss: 1.44559 | Correct: 372/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 600 | Loss: 1.46827 | Correct: 353/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 700 | Loss: 1.50275 | Correct: 351/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 800 | Loss: 1.49819 | Correct: 355/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 900 | Loss: 1.49716 | Correct: 356/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 1000 | Loss: 1.53342 | Correct: 343/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 1100 | Loss: 1.48807 | Correct: 349/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 1200 | Loss: 1.43532 | Correct: 364/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 1300 | Loss: 1.48997 | Correct: 361/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 1400 | Loss: 1.44624 | Correct: 363/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 1500 | Loss: 1.45631 | Correct: 364/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 1600 | Loss: 1.51300 | Correct: 353/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 1700 | Loss: 1.47990 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 1800 | Loss: 1.44302 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 1900 | Loss: 1.49004 | Correct: 360/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 2000 | Loss: 1.52452 | Correct: 346/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 2100 | Loss: 1.48950 | Correct: 359/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 2200 | Loss: 1.51214 | Correct: 359/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 2300 | Loss: 1.44773 | Correct: 353/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 2400 | Loss: 1.54180 | Correct: 339/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 2500 | Loss: 1.51501 | Correct: 353/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 2600 | Loss: 1.51237 | Correct: 351/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 2700 | Loss: 1.63004 | Correct: 325/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 2800 | Loss: 1.48662 | Correct: 356/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 2900 | Loss: 1.51339 | Correct: 359/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 3000 | Loss: 1.43004 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 3100 | Loss: 1.46178 | Correct: 360/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 3200 | Loss: 1.48833 | Correct: 354/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 3300 | Loss: 1.51367 | Correct: 357/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 3400 | Loss: 1.42913 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 3500 | Loss: 1.54188 | Correct: 338/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 3600 | Loss: 1.49803 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 005 | Batch: 3700 | Loss: 1.49073 | Correct: 357/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 04:48:55,765 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 04:48:55,989 - INFO: Epoch: 005 | Validation Acc: 76.291 % | Historical Best: 76.291 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 006 | Batch: 000 | Loss: 1.45954 | Correct: 362/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 100 | Loss: 1.49748 | Correct: 349/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 200 | Loss: 1.41107 | Correct: 367/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 300 | Loss: 1.42941 | Correct: 362/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 400 | Loss: 1.40514 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 500 | Loss: 1.51562 | Correct: 346/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 600 | Loss: 1.49009 | Correct: 350/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 700 | Loss: 1.53773 | Correct: 354/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 800 | Loss: 1.45126 | Correct: 364/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 900 | Loss: 1.44061 | Correct: 360/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 1000 | Loss: 1.46470 | Correct: 356/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 1100 | Loss: 1.46841 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 1200 | Loss: 1.56422 | Correct: 336/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 1300 | Loss: 1.45408 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 1400 | Loss: 1.46105 | Correct: 363/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 1500 | Loss: 1.46998 | Correct: 360/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 1600 | Loss: 1.47136 | Correct: 362/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 1700 | Loss: 1.51065 | Correct: 353/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 1800 | Loss: 1.48878 | Correct: 360/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 1900 | Loss: 1.47893 | Correct: 352/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 2000 | Loss: 1.51761 | Correct: 346/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 2100 | Loss: 1.50164 | Correct: 353/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 2200 | Loss: 1.40959 | Correct: 369/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 2300 | Loss: 1.46147 | Correct: 352/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 2400 | Loss: 1.50167 | Correct: 351/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 2500 | Loss: 1.44031 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 2600 | Loss: 1.50453 | Correct: 356/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 2700 | Loss: 1.46760 | Correct: 361/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 2800 | Loss: 1.48758 | Correct: 348/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 2900 | Loss: 1.48487 | Correct: 354/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 3000 | Loss: 1.51064 | Correct: 348/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 3100 | Loss: 1.43483 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 3200 | Loss: 1.50298 | Correct: 363/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 3300 | Loss: 1.48762 | Correct: 356/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 3400 | Loss: 1.43097 | Correct: 369/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 3500 | Loss: 1.50516 | Correct: 355/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 3600 | Loss: 1.48957 | Correct: 354/512\n",
      "Estimator: 000 | Epoch: 006 | Batch: 3700 | Loss: 1.41796 | Correct: 358/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 000 | Loss: 1.51833 | Correct: 358/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 100 | Loss: 1.50938 | Correct: 339/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 200 | Loss: 1.54882 | Correct: 347/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 300 | Loss: 1.57530 | Correct: 343/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 400 | Loss: 1.48187 | Correct: 353/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 500 | Loss: 1.45780 | Correct: 353/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 600 | Loss: 1.51711 | Correct: 343/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 700 | Loss: 1.46660 | Correct: 357/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 800 | Loss: 1.42586 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 900 | Loss: 1.46302 | Correct: 369/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 1000 | Loss: 1.40751 | Correct: 374/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 1100 | Loss: 1.40808 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 1200 | Loss: 1.50173 | Correct: 345/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 1300 | Loss: 1.49570 | Correct: 349/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 1400 | Loss: 1.49640 | Correct: 354/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 1500 | Loss: 1.49874 | Correct: 357/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 1600 | Loss: 1.45929 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 1700 | Loss: 1.46417 | Correct: 362/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 1800 | Loss: 1.47569 | Correct: 349/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 1900 | Loss: 1.57707 | Correct: 331/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 2000 | Loss: 1.46125 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 2100 | Loss: 1.46529 | Correct: 359/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 2200 | Loss: 1.50766 | Correct: 355/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 2300 | Loss: 1.49419 | Correct: 358/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 2400 | Loss: 1.50945 | Correct: 343/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 2500 | Loss: 1.48428 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 2600 | Loss: 1.55100 | Correct: 347/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 2700 | Loss: 1.51158 | Correct: 356/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 2800 | Loss: 1.47445 | Correct: 352/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 2900 | Loss: 1.46771 | Correct: 356/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 3000 | Loss: 1.53454 | Correct: 359/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 3100 | Loss: 1.50884 | Correct: 361/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 3200 | Loss: 1.50239 | Correct: 358/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 3300 | Loss: 1.40799 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 3400 | Loss: 1.46915 | Correct: 363/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 3500 | Loss: 1.55512 | Correct: 335/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 3600 | Loss: 1.47534 | Correct: 359/512\n",
      "Estimator: 001 | Epoch: 006 | Batch: 3700 | Loss: 1.51204 | Correct: 347/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 000 | Loss: 1.44426 | Correct: 367/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 100 | Loss: 1.46902 | Correct: 355/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 200 | Loss: 1.50089 | Correct: 360/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 300 | Loss: 1.52818 | Correct: 355/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 400 | Loss: 1.52090 | Correct: 353/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 500 | Loss: 1.52715 | Correct: 341/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 600 | Loss: 1.48362 | Correct: 358/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 700 | Loss: 1.40659 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 800 | Loss: 1.47875 | Correct: 348/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 900 | Loss: 1.50716 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 1000 | Loss: 1.53001 | Correct: 344/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 1100 | Loss: 1.55360 | Correct: 343/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 1200 | Loss: 1.48181 | Correct: 356/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 1300 | Loss: 1.44419 | Correct: 366/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 1400 | Loss: 1.51399 | Correct: 351/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 1500 | Loss: 1.45928 | Correct: 362/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 1600 | Loss: 1.41484 | Correct: 361/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 1700 | Loss: 1.55750 | Correct: 345/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 1800 | Loss: 1.49260 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 1900 | Loss: 1.45950 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 2000 | Loss: 1.50242 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 2100 | Loss: 1.49080 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 2200 | Loss: 1.44843 | Correct: 361/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 2300 | Loss: 1.47063 | Correct: 361/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 2400 | Loss: 1.49209 | Correct: 355/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 2500 | Loss: 1.40361 | Correct: 376/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 2600 | Loss: 1.44062 | Correct: 361/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 2700 | Loss: 1.54604 | Correct: 342/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 2800 | Loss: 1.47910 | Correct: 357/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 2900 | Loss: 1.41993 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 3000 | Loss: 1.51525 | Correct: 341/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 3100 | Loss: 1.51361 | Correct: 343/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 3200 | Loss: 1.50755 | Correct: 356/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 3300 | Loss: 1.51141 | Correct: 346/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 3400 | Loss: 1.55143 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 3500 | Loss: 1.46824 | Correct: 362/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 3600 | Loss: 1.50154 | Correct: 350/512\n",
      "Estimator: 002 | Epoch: 006 | Batch: 3700 | Loss: 1.45945 | Correct: 355/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 000 | Loss: 1.51724 | Correct: 350/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 100 | Loss: 1.45359 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 200 | Loss: 1.48842 | Correct: 352/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 300 | Loss: 1.49830 | Correct: 347/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 400 | Loss: 1.47439 | Correct: 359/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 500 | Loss: 1.45138 | Correct: 359/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 600 | Loss: 1.37286 | Correct: 385/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 700 | Loss: 1.47356 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 800 | Loss: 1.46443 | Correct: 359/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 900 | Loss: 1.52960 | Correct: 348/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 1000 | Loss: 1.50506 | Correct: 348/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 1100 | Loss: 1.53197 | Correct: 348/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 1200 | Loss: 1.45005 | Correct: 363/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 1300 | Loss: 1.44634 | Correct: 368/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 1400 | Loss: 1.47935 | Correct: 355/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 1500 | Loss: 1.33514 | Correct: 386/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 1600 | Loss: 1.49273 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 1700 | Loss: 1.51822 | Correct: 345/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 1800 | Loss: 1.40676 | Correct: 381/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 1900 | Loss: 1.50100 | Correct: 354/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 2000 | Loss: 1.43551 | Correct: 362/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 2100 | Loss: 1.47415 | Correct: 360/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 2200 | Loss: 1.45740 | Correct: 349/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 2300 | Loss: 1.44612 | Correct: 360/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 2400 | Loss: 1.51453 | Correct: 350/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 2500 | Loss: 1.50464 | Correct: 352/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 2600 | Loss: 1.49309 | Correct: 361/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 2700 | Loss: 1.51901 | Correct: 349/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 2800 | Loss: 1.50356 | Correct: 346/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 2900 | Loss: 1.40081 | Correct: 363/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 3000 | Loss: 1.50852 | Correct: 342/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 3100 | Loss: 1.50903 | Correct: 345/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 3200 | Loss: 1.51005 | Correct: 354/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 3300 | Loss: 1.43649 | Correct: 369/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 3400 | Loss: 1.43531 | Correct: 361/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 3500 | Loss: 1.52565 | Correct: 343/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 3600 | Loss: 1.49592 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 006 | Batch: 3700 | Loss: 1.41986 | Correct: 358/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 000 | Loss: 1.61033 | Correct: 336/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 100 | Loss: 1.43379 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 200 | Loss: 1.47849 | Correct: 359/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 300 | Loss: 1.52212 | Correct: 340/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 400 | Loss: 1.47058 | Correct: 363/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 500 | Loss: 1.51724 | Correct: 352/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 600 | Loss: 1.46714 | Correct: 359/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 700 | Loss: 1.48581 | Correct: 358/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 800 | Loss: 1.47821 | Correct: 355/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 900 | Loss: 1.45872 | Correct: 367/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 1000 | Loss: 1.50563 | Correct: 351/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 1100 | Loss: 1.43524 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 1200 | Loss: 1.56033 | Correct: 347/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 1300 | Loss: 1.43863 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 1400 | Loss: 1.50890 | Correct: 355/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 1500 | Loss: 1.44932 | Correct: 363/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 1600 | Loss: 1.52765 | Correct: 344/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 1700 | Loss: 1.43939 | Correct: 357/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 1800 | Loss: 1.51840 | Correct: 334/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 1900 | Loss: 1.46526 | Correct: 370/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 2000 | Loss: 1.39308 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 2100 | Loss: 1.48990 | Correct: 352/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 2200 | Loss: 1.51001 | Correct: 359/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 2300 | Loss: 1.40508 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 2400 | Loss: 1.49127 | Correct: 358/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 2500 | Loss: 1.41717 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 2600 | Loss: 1.41233 | Correct: 372/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 2700 | Loss: 1.47526 | Correct: 360/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 2800 | Loss: 1.53351 | Correct: 340/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 2900 | Loss: 1.47378 | Correct: 349/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 3000 | Loss: 1.56818 | Correct: 349/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 3100 | Loss: 1.46429 | Correct: 351/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 3200 | Loss: 1.44094 | Correct: 357/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 3300 | Loss: 1.43899 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 3400 | Loss: 1.49622 | Correct: 354/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 3500 | Loss: 1.48682 | Correct: 357/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 3600 | Loss: 1.41084 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 006 | Batch: 3700 | Loss: 1.43573 | Correct: 352/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 04:52:01,373 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 04:52:01,646 - INFO: Epoch: 006 | Validation Acc: 77.071 % | Historical Best: 77.071 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 007 | Batch: 000 | Loss: 1.47025 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 100 | Loss: 1.48320 | Correct: 367/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 200 | Loss: 1.39893 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 300 | Loss: 1.53281 | Correct: 344/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 400 | Loss: 1.42544 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 500 | Loss: 1.49358 | Correct: 349/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 600 | Loss: 1.49145 | Correct: 355/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 700 | Loss: 1.39167 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 800 | Loss: 1.46004 | Correct: 361/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 900 | Loss: 1.50050 | Correct: 347/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 1000 | Loss: 1.47011 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 1100 | Loss: 1.36719 | Correct: 386/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 1200 | Loss: 1.49361 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 1300 | Loss: 1.45650 | Correct: 362/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 1400 | Loss: 1.46442 | Correct: 360/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 1500 | Loss: 1.45323 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 1600 | Loss: 1.52714 | Correct: 346/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 1700 | Loss: 1.48996 | Correct: 359/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 1800 | Loss: 1.46892 | Correct: 360/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 1900 | Loss: 1.46058 | Correct: 355/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 2000 | Loss: 1.46508 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 2100 | Loss: 1.47196 | Correct: 348/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 2200 | Loss: 1.41438 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 2300 | Loss: 1.51518 | Correct: 345/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 2400 | Loss: 1.45180 | Correct: 366/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 2500 | Loss: 1.43193 | Correct: 364/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 2600 | Loss: 1.44344 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 2700 | Loss: 1.46216 | Correct: 365/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 2800 | Loss: 1.40353 | Correct: 375/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 2900 | Loss: 1.48062 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 3000 | Loss: 1.47303 | Correct: 365/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 3100 | Loss: 1.50982 | Correct: 346/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 3200 | Loss: 1.46994 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 3300 | Loss: 1.39846 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 3400 | Loss: 1.50389 | Correct: 352/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 3500 | Loss: 1.49996 | Correct: 345/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 3600 | Loss: 1.44977 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 007 | Batch: 3700 | Loss: 1.43277 | Correct: 367/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 000 | Loss: 1.43202 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 100 | Loss: 1.44957 | Correct: 358/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 200 | Loss: 1.46283 | Correct: 358/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 300 | Loss: 1.48156 | Correct: 359/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 400 | Loss: 1.40839 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 500 | Loss: 1.49657 | Correct: 360/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 600 | Loss: 1.40501 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 700 | Loss: 1.45736 | Correct: 363/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 800 | Loss: 1.38701 | Correct: 367/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 900 | Loss: 1.42450 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 1000 | Loss: 1.42796 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 1100 | Loss: 1.34835 | Correct: 386/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 1200 | Loss: 1.48226 | Correct: 359/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 1300 | Loss: 1.47202 | Correct: 352/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 1400 | Loss: 1.49226 | Correct: 350/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 1500 | Loss: 1.42783 | Correct: 375/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 1600 | Loss: 1.46952 | Correct: 362/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 1700 | Loss: 1.40746 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 1800 | Loss: 1.43882 | Correct: 362/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 1900 | Loss: 1.44138 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 2000 | Loss: 1.41387 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 2100 | Loss: 1.44873 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 2200 | Loss: 1.52095 | Correct: 346/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 2300 | Loss: 1.47284 | Correct: 361/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 2400 | Loss: 1.51854 | Correct: 354/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 2500 | Loss: 1.41866 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 2600 | Loss: 1.49731 | Correct: 357/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 2700 | Loss: 1.35383 | Correct: 386/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 2800 | Loss: 1.48074 | Correct: 355/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 2900 | Loss: 1.42664 | Correct: 375/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 3000 | Loss: 1.54923 | Correct: 340/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 3100 | Loss: 1.42423 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 3200 | Loss: 1.51277 | Correct: 359/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 3300 | Loss: 1.41495 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 3400 | Loss: 1.43874 | Correct: 375/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 3500 | Loss: 1.42196 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 3600 | Loss: 1.47104 | Correct: 354/512\n",
      "Estimator: 001 | Epoch: 007 | Batch: 3700 | Loss: 1.47502 | Correct: 357/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 000 | Loss: 1.47864 | Correct: 351/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 100 | Loss: 1.42586 | Correct: 356/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 200 | Loss: 1.41166 | Correct: 360/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 300 | Loss: 1.41629 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 400 | Loss: 1.37354 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 500 | Loss: 1.48146 | Correct: 360/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 600 | Loss: 1.50653 | Correct: 354/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 700 | Loss: 1.44359 | Correct: 361/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 800 | Loss: 1.45387 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 900 | Loss: 1.47363 | Correct: 360/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 1000 | Loss: 1.46371 | Correct: 367/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 1100 | Loss: 1.45556 | Correct: 360/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 1200 | Loss: 1.49615 | Correct: 351/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 1300 | Loss: 1.42914 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 1400 | Loss: 1.55225 | Correct: 327/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 1500 | Loss: 1.51369 | Correct: 354/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 1600 | Loss: 1.39513 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 1700 | Loss: 1.43061 | Correct: 362/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 1800 | Loss: 1.48543 | Correct: 353/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 1900 | Loss: 1.47310 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 2000 | Loss: 1.51180 | Correct: 356/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 2100 | Loss: 1.39735 | Correct: 365/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 2200 | Loss: 1.48496 | Correct: 365/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 2300 | Loss: 1.42515 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 2400 | Loss: 1.43907 | Correct: 366/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 2500 | Loss: 1.46109 | Correct: 364/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 2600 | Loss: 1.45940 | Correct: 358/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 2700 | Loss: 1.48285 | Correct: 361/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 2800 | Loss: 1.49765 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 2900 | Loss: 1.47032 | Correct: 369/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 3000 | Loss: 1.39085 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 3100 | Loss: 1.50229 | Correct: 353/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 3200 | Loss: 1.47644 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 3300 | Loss: 1.42603 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 3400 | Loss: 1.50152 | Correct: 358/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 3500 | Loss: 1.45567 | Correct: 369/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 3600 | Loss: 1.51694 | Correct: 356/512\n",
      "Estimator: 002 | Epoch: 007 | Batch: 3700 | Loss: 1.43773 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 000 | Loss: 1.44923 | Correct: 355/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 100 | Loss: 1.44966 | Correct: 358/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 200 | Loss: 1.51795 | Correct: 347/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 300 | Loss: 1.49817 | Correct: 350/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 400 | Loss: 1.48592 | Correct: 358/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 500 | Loss: 1.46943 | Correct: 360/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 600 | Loss: 1.44409 | Correct: 358/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 700 | Loss: 1.45114 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 800 | Loss: 1.39618 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 900 | Loss: 1.52100 | Correct: 349/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 1000 | Loss: 1.48591 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 1100 | Loss: 1.44929 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 1200 | Loss: 1.40789 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 1300 | Loss: 1.48700 | Correct: 352/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 1400 | Loss: 1.40990 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 1500 | Loss: 1.43355 | Correct: 364/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 1600 | Loss: 1.39976 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 1700 | Loss: 1.49592 | Correct: 347/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 1800 | Loss: 1.39827 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 1900 | Loss: 1.43315 | Correct: 356/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 2000 | Loss: 1.49805 | Correct: 346/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 2100 | Loss: 1.39244 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 2200 | Loss: 1.45041 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 2300 | Loss: 1.45775 | Correct: 357/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 2400 | Loss: 1.39729 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 2500 | Loss: 1.37804 | Correct: 369/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 2600 | Loss: 1.44116 | Correct: 374/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 2700 | Loss: 1.49120 | Correct: 350/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 2800 | Loss: 1.48727 | Correct: 356/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 2900 | Loss: 1.49698 | Correct: 359/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 3000 | Loss: 1.54306 | Correct: 348/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 3100 | Loss: 1.45137 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 3200 | Loss: 1.45805 | Correct: 361/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 3300 | Loss: 1.48777 | Correct: 351/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 3400 | Loss: 1.39716 | Correct: 368/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 3500 | Loss: 1.40800 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 3600 | Loss: 1.52767 | Correct: 342/512\n",
      "Estimator: 003 | Epoch: 007 | Batch: 3700 | Loss: 1.47603 | Correct: 361/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 000 | Loss: 1.45015 | Correct: 363/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 100 | Loss: 1.48551 | Correct: 354/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 200 | Loss: 1.44302 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 300 | Loss: 1.45870 | Correct: 367/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 400 | Loss: 1.44140 | Correct: 360/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 500 | Loss: 1.51037 | Correct: 346/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 600 | Loss: 1.52846 | Correct: 355/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 700 | Loss: 1.42396 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 800 | Loss: 1.47424 | Correct: 352/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 900 | Loss: 1.42631 | Correct: 370/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 1000 | Loss: 1.54926 | Correct: 344/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 1100 | Loss: 1.42828 | Correct: 370/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 1200 | Loss: 1.50056 | Correct: 353/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 1300 | Loss: 1.52651 | Correct: 354/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 1400 | Loss: 1.36299 | Correct: 387/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 1500 | Loss: 1.48553 | Correct: 358/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 1600 | Loss: 1.50834 | Correct: 342/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 1700 | Loss: 1.42990 | Correct: 371/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 1800 | Loss: 1.47680 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 1900 | Loss: 1.40826 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 2000 | Loss: 1.46347 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 2100 | Loss: 1.39092 | Correct: 378/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 2200 | Loss: 1.49334 | Correct: 348/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 2300 | Loss: 1.45354 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 2400 | Loss: 1.45177 | Correct: 361/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 2500 | Loss: 1.54789 | Correct: 343/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 2600 | Loss: 1.42089 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 2700 | Loss: 1.49890 | Correct: 354/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 2800 | Loss: 1.44861 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 2900 | Loss: 1.44630 | Correct: 360/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 3000 | Loss: 1.40840 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 3100 | Loss: 1.49707 | Correct: 351/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 3200 | Loss: 1.51017 | Correct: 345/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 3300 | Loss: 1.42695 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 3400 | Loss: 1.49174 | Correct: 355/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 3500 | Loss: 1.38282 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 3600 | Loss: 1.46621 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 007 | Batch: 3700 | Loss: 1.46081 | Correct: 365/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 04:55:04,356 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 04:55:04,573 - INFO: Epoch: 007 | Validation Acc: 77.776 % | Historical Best: 77.776 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 008 | Batch: 000 | Loss: 1.47150 | Correct: 366/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 100 | Loss: 1.46180 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 200 | Loss: 1.52989 | Correct: 349/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 300 | Loss: 1.39393 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 400 | Loss: 1.44168 | Correct: 366/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 500 | Loss: 1.48513 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 600 | Loss: 1.49879 | Correct: 349/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 700 | Loss: 1.48854 | Correct: 359/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 800 | Loss: 1.45644 | Correct: 351/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 900 | Loss: 1.43398 | Correct: 362/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 1000 | Loss: 1.39248 | Correct: 383/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 1100 | Loss: 1.49818 | Correct: 347/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 1200 | Loss: 1.44595 | Correct: 354/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 1300 | Loss: 1.45398 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 1400 | Loss: 1.49039 | Correct: 353/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 1500 | Loss: 1.41580 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 1600 | Loss: 1.51843 | Correct: 360/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 1700 | Loss: 1.40732 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 1800 | Loss: 1.50803 | Correct: 341/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 1900 | Loss: 1.37292 | Correct: 366/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 2000 | Loss: 1.50288 | Correct: 346/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 2100 | Loss: 1.43068 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 2200 | Loss: 1.40978 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 2300 | Loss: 1.43801 | Correct: 362/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 2400 | Loss: 1.42257 | Correct: 365/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 2500 | Loss: 1.36538 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 2600 | Loss: 1.39258 | Correct: 390/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 2700 | Loss: 1.48161 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 2800 | Loss: 1.43697 | Correct: 354/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 2900 | Loss: 1.38554 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 3000 | Loss: 1.42267 | Correct: 364/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 3100 | Loss: 1.44928 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 3200 | Loss: 1.45809 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 3300 | Loss: 1.49088 | Correct: 350/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 3400 | Loss: 1.46047 | Correct: 354/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 3500 | Loss: 1.40014 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 3600 | Loss: 1.49523 | Correct: 353/512\n",
      "Estimator: 000 | Epoch: 008 | Batch: 3700 | Loss: 1.39445 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 000 | Loss: 1.39865 | Correct: 363/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 100 | Loss: 1.43314 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 200 | Loss: 1.38435 | Correct: 383/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 300 | Loss: 1.51397 | Correct: 339/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 400 | Loss: 1.44851 | Correct: 355/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 500 | Loss: 1.42143 | Correct: 369/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 600 | Loss: 1.34423 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 700 | Loss: 1.41833 | Correct: 361/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 800 | Loss: 1.42361 | Correct: 358/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 900 | Loss: 1.38937 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 1000 | Loss: 1.41983 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 1100 | Loss: 1.44627 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 1200 | Loss: 1.36977 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 1300 | Loss: 1.39629 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 1400 | Loss: 1.37747 | Correct: 379/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 1500 | Loss: 1.43882 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 1600 | Loss: 1.41554 | Correct: 363/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 1700 | Loss: 1.43203 | Correct: 374/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 1800 | Loss: 1.44799 | Correct: 362/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 1900 | Loss: 1.40699 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 2000 | Loss: 1.47524 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 2100 | Loss: 1.47800 | Correct: 355/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 2200 | Loss: 1.42587 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 2300 | Loss: 1.42959 | Correct: 347/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 2400 | Loss: 1.44297 | Correct: 363/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 2500 | Loss: 1.38889 | Correct: 374/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 2600 | Loss: 1.39641 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 2700 | Loss: 1.42065 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 2800 | Loss: 1.43606 | Correct: 369/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 2900 | Loss: 1.50874 | Correct: 348/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 3000 | Loss: 1.46100 | Correct: 356/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 3100 | Loss: 1.59977 | Correct: 334/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 3200 | Loss: 1.41526 | Correct: 360/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 3300 | Loss: 1.42147 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 3400 | Loss: 1.42871 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 3500 | Loss: 1.42345 | Correct: 359/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 3600 | Loss: 1.40424 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 008 | Batch: 3700 | Loss: 1.48705 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 000 | Loss: 1.43156 | Correct: 362/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 100 | Loss: 1.47435 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 200 | Loss: 1.48967 | Correct: 360/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 300 | Loss: 1.49042 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 400 | Loss: 1.47444 | Correct: 365/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 500 | Loss: 1.45257 | Correct: 361/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 600 | Loss: 1.49578 | Correct: 361/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 700 | Loss: 1.46803 | Correct: 361/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 800 | Loss: 1.49919 | Correct: 353/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 900 | Loss: 1.45066 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 1000 | Loss: 1.47761 | Correct: 351/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 1100 | Loss: 1.47400 | Correct: 363/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 1200 | Loss: 1.46114 | Correct: 364/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 1300 | Loss: 1.49852 | Correct: 346/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 1400 | Loss: 1.38409 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 1500 | Loss: 1.42194 | Correct: 379/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 1600 | Loss: 1.42789 | Correct: 366/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 1700 | Loss: 1.43526 | Correct: 367/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 1800 | Loss: 1.56495 | Correct: 341/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 1900 | Loss: 1.51106 | Correct: 357/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 2000 | Loss: 1.45374 | Correct: 356/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 2100 | Loss: 1.45550 | Correct: 360/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 2200 | Loss: 1.49730 | Correct: 354/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 2300 | Loss: 1.44473 | Correct: 357/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 2400 | Loss: 1.43337 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 2500 | Loss: 1.48307 | Correct: 355/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 2600 | Loss: 1.52590 | Correct: 341/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 2700 | Loss: 1.44594 | Correct: 362/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 2800 | Loss: 1.45339 | Correct: 364/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 2900 | Loss: 1.40610 | Correct: 377/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 3000 | Loss: 1.43403 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 3100 | Loss: 1.43165 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 3200 | Loss: 1.34012 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 3300 | Loss: 1.52714 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 3400 | Loss: 1.42253 | Correct: 367/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 3500 | Loss: 1.37846 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 3600 | Loss: 1.39722 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 008 | Batch: 3700 | Loss: 1.41027 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 000 | Loss: 1.39810 | Correct: 385/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 100 | Loss: 1.47678 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 200 | Loss: 1.43656 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 300 | Loss: 1.45575 | Correct: 361/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 400 | Loss: 1.40741 | Correct: 367/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 500 | Loss: 1.40225 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 600 | Loss: 1.39824 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 700 | Loss: 1.57066 | Correct: 342/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 800 | Loss: 1.40520 | Correct: 374/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 900 | Loss: 1.46543 | Correct: 353/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 1000 | Loss: 1.48405 | Correct: 351/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 1100 | Loss: 1.46348 | Correct: 348/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 1200 | Loss: 1.43947 | Correct: 359/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 1300 | Loss: 1.45264 | Correct: 353/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 1400 | Loss: 1.46491 | Correct: 359/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 1500 | Loss: 1.44151 | Correct: 375/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 1600 | Loss: 1.46952 | Correct: 363/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 1700 | Loss: 1.50057 | Correct: 351/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 1800 | Loss: 1.43582 | Correct: 364/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 1900 | Loss: 1.48467 | Correct: 349/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 2000 | Loss: 1.42789 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 2100 | Loss: 1.46636 | Correct: 361/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 2200 | Loss: 1.38670 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 2300 | Loss: 1.42024 | Correct: 364/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 2400 | Loss: 1.40363 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 2500 | Loss: 1.44962 | Correct: 360/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 2600 | Loss: 1.48638 | Correct: 354/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 2700 | Loss: 1.44914 | Correct: 360/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 2800 | Loss: 1.39135 | Correct: 376/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 2900 | Loss: 1.52566 | Correct: 349/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 3000 | Loss: 1.41617 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 3100 | Loss: 1.39284 | Correct: 378/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 3200 | Loss: 1.50605 | Correct: 356/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 3300 | Loss: 1.43867 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 3400 | Loss: 1.41160 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 3500 | Loss: 1.48554 | Correct: 356/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 3600 | Loss: 1.45518 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 008 | Batch: 3700 | Loss: 1.46594 | Correct: 357/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 000 | Loss: 1.39447 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 100 | Loss: 1.40063 | Correct: 372/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 200 | Loss: 1.43717 | Correct: 361/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 300 | Loss: 1.42592 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 400 | Loss: 1.47431 | Correct: 347/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 500 | Loss: 1.43355 | Correct: 370/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 600 | Loss: 1.41064 | Correct: 372/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 700 | Loss: 1.45289 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 800 | Loss: 1.41426 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 900 | Loss: 1.41671 | Correct: 365/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 1000 | Loss: 1.47302 | Correct: 359/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 1100 | Loss: 1.44715 | Correct: 365/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 1200 | Loss: 1.47920 | Correct: 361/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 1300 | Loss: 1.47257 | Correct: 356/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 1400 | Loss: 1.43752 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 1500 | Loss: 1.46203 | Correct: 359/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 1600 | Loss: 1.42333 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 1700 | Loss: 1.47091 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 1800 | Loss: 1.43938 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 1900 | Loss: 1.47296 | Correct: 355/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 2000 | Loss: 1.41242 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 2100 | Loss: 1.39567 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 2200 | Loss: 1.42141 | Correct: 361/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 2300 | Loss: 1.42077 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 2400 | Loss: 1.35711 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 2500 | Loss: 1.50602 | Correct: 356/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 2600 | Loss: 1.43476 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 2700 | Loss: 1.51670 | Correct: 353/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 2800 | Loss: 1.46108 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 2900 | Loss: 1.44068 | Correct: 365/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 3000 | Loss: 1.42917 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 3100 | Loss: 1.38725 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 3200 | Loss: 1.45763 | Correct: 360/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 3300 | Loss: 1.43927 | Correct: 357/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 3400 | Loss: 1.43192 | Correct: 365/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 3500 | Loss: 1.33741 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 3600 | Loss: 1.43820 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 008 | Batch: 3700 | Loss: 1.44914 | Correct: 371/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 04:58:07,643 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 04:58:07,880 - INFO: Epoch: 008 | Validation Acc: 78.459 % | Historical Best: 78.459 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 009 | Batch: 000 | Loss: 1.46053 | Correct: 369/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 100 | Loss: 1.40003 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 200 | Loss: 1.49371 | Correct: 361/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 300 | Loss: 1.44951 | Correct: 352/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 400 | Loss: 1.42444 | Correct: 360/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 500 | Loss: 1.42090 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 600 | Loss: 1.43580 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 700 | Loss: 1.39165 | Correct: 362/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 800 | Loss: 1.39296 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 900 | Loss: 1.52364 | Correct: 346/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 1000 | Loss: 1.38830 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 1100 | Loss: 1.37274 | Correct: 376/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 1200 | Loss: 1.46812 | Correct: 363/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 1300 | Loss: 1.45333 | Correct: 359/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 1400 | Loss: 1.49781 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 1500 | Loss: 1.43605 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 1600 | Loss: 1.43895 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 1700 | Loss: 1.43163 | Correct: 369/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 1800 | Loss: 1.40928 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 1900 | Loss: 1.40578 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 2000 | Loss: 1.43620 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 2100 | Loss: 1.42516 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 2200 | Loss: 1.41726 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 2300 | Loss: 1.45751 | Correct: 360/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 2400 | Loss: 1.40225 | Correct: 376/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 2500 | Loss: 1.42797 | Correct: 363/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 2600 | Loss: 1.45998 | Correct: 362/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 2700 | Loss: 1.41464 | Correct: 379/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 2800 | Loss: 1.38123 | Correct: 375/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 2900 | Loss: 1.46612 | Correct: 363/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 3000 | Loss: 1.40058 | Correct: 366/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 3100 | Loss: 1.41667 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 3200 | Loss: 1.43784 | Correct: 363/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 3300 | Loss: 1.37910 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 3400 | Loss: 1.44711 | Correct: 369/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 3500 | Loss: 1.52863 | Correct: 356/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 3600 | Loss: 1.46217 | Correct: 362/512\n",
      "Estimator: 000 | Epoch: 009 | Batch: 3700 | Loss: 1.49222 | Correct: 353/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 000 | Loss: 1.42175 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 100 | Loss: 1.42410 | Correct: 369/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 200 | Loss: 1.45743 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 300 | Loss: 1.37804 | Correct: 379/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 400 | Loss: 1.51351 | Correct: 346/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 500 | Loss: 1.40665 | Correct: 369/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 600 | Loss: 1.40731 | Correct: 362/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 700 | Loss: 1.42848 | Correct: 363/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 800 | Loss: 1.44917 | Correct: 362/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 900 | Loss: 1.48086 | Correct: 359/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 1000 | Loss: 1.43001 | Correct: 362/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 1100 | Loss: 1.36036 | Correct: 394/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 1200 | Loss: 1.46306 | Correct: 357/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 1300 | Loss: 1.44041 | Correct: 369/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 1400 | Loss: 1.38536 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 1500 | Loss: 1.45465 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 1600 | Loss: 1.45406 | Correct: 367/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 1700 | Loss: 1.45040 | Correct: 362/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 1800 | Loss: 1.40310 | Correct: 362/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 1900 | Loss: 1.42494 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 2000 | Loss: 1.41059 | Correct: 374/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 2100 | Loss: 1.42608 | Correct: 361/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 2200 | Loss: 1.42248 | Correct: 358/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 2300 | Loss: 1.44654 | Correct: 363/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 2400 | Loss: 1.43224 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 2500 | Loss: 1.42583 | Correct: 358/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 2600 | Loss: 1.48367 | Correct: 367/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 2700 | Loss: 1.41462 | Correct: 374/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 2800 | Loss: 1.44509 | Correct: 362/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 2900 | Loss: 1.41294 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 3000 | Loss: 1.38151 | Correct: 391/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 3100 | Loss: 1.40384 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 3200 | Loss: 1.46681 | Correct: 367/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 3300 | Loss: 1.44011 | Correct: 363/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 3400 | Loss: 1.50828 | Correct: 346/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 3500 | Loss: 1.39099 | Correct: 374/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 3600 | Loss: 1.37518 | Correct: 367/512\n",
      "Estimator: 001 | Epoch: 009 | Batch: 3700 | Loss: 1.45960 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 000 | Loss: 1.35923 | Correct: 388/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 100 | Loss: 1.39861 | Correct: 363/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 200 | Loss: 1.47899 | Correct: 358/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 300 | Loss: 1.44392 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 400 | Loss: 1.45136 | Correct: 356/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 500 | Loss: 1.31090 | Correct: 391/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 600 | Loss: 1.39833 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 700 | Loss: 1.41301 | Correct: 379/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 800 | Loss: 1.43206 | Correct: 368/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 900 | Loss: 1.41215 | Correct: 370/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 1000 | Loss: 1.43910 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 1100 | Loss: 1.47007 | Correct: 357/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 1200 | Loss: 1.40572 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 1300 | Loss: 1.44223 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 1400 | Loss: 1.45051 | Correct: 355/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 1500 | Loss: 1.47593 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 1600 | Loss: 1.43509 | Correct: 366/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 1700 | Loss: 1.43447 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 1800 | Loss: 1.45755 | Correct: 366/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 1900 | Loss: 1.39925 | Correct: 368/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 2000 | Loss: 1.43582 | Correct: 355/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 2100 | Loss: 1.42627 | Correct: 364/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 2200 | Loss: 1.45019 | Correct: 368/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 2300 | Loss: 1.47800 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 2400 | Loss: 1.35719 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 2500 | Loss: 1.37725 | Correct: 379/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 2600 | Loss: 1.39963 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 2700 | Loss: 1.46162 | Correct: 360/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 2800 | Loss: 1.40669 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 2900 | Loss: 1.44287 | Correct: 348/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 3000 | Loss: 1.54057 | Correct: 344/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 3100 | Loss: 1.39682 | Correct: 366/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 3200 | Loss: 1.49170 | Correct: 362/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 3300 | Loss: 1.43051 | Correct: 369/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 3400 | Loss: 1.45111 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 3500 | Loss: 1.41203 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 3600 | Loss: 1.42465 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 009 | Batch: 3700 | Loss: 1.39485 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 000 | Loss: 1.47963 | Correct: 356/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 100 | Loss: 1.41117 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 200 | Loss: 1.45888 | Correct: 359/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 300 | Loss: 1.38565 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 400 | Loss: 1.41129 | Correct: 367/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 500 | Loss: 1.39818 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 600 | Loss: 1.45876 | Correct: 363/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 700 | Loss: 1.34999 | Correct: 383/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 800 | Loss: 1.35707 | Correct: 379/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 900 | Loss: 1.40967 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 1000 | Loss: 1.39733 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 1100 | Loss: 1.38375 | Correct: 374/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 1200 | Loss: 1.38713 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 1300 | Loss: 1.44452 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 1400 | Loss: 1.44924 | Correct: 363/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 1500 | Loss: 1.42121 | Correct: 367/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 1600 | Loss: 1.46159 | Correct: 364/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 1700 | Loss: 1.37495 | Correct: 375/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 1800 | Loss: 1.43311 | Correct: 369/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 1900 | Loss: 1.40923 | Correct: 376/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 2000 | Loss: 1.40281 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 2100 | Loss: 1.46405 | Correct: 358/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 2200 | Loss: 1.51488 | Correct: 353/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 2300 | Loss: 1.45116 | Correct: 362/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 2400 | Loss: 1.48597 | Correct: 348/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 2500 | Loss: 1.38662 | Correct: 384/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 2600 | Loss: 1.40219 | Correct: 376/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 2700 | Loss: 1.40120 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 2800 | Loss: 1.42088 | Correct: 364/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 2900 | Loss: 1.47841 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 3000 | Loss: 1.46541 | Correct: 361/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 3100 | Loss: 1.43266 | Correct: 375/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 3200 | Loss: 1.36282 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 3300 | Loss: 1.48097 | Correct: 358/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 3400 | Loss: 1.43609 | Correct: 357/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 3500 | Loss: 1.43972 | Correct: 351/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 3600 | Loss: 1.45187 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 009 | Batch: 3700 | Loss: 1.45563 | Correct: 367/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 000 | Loss: 1.42082 | Correct: 364/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 100 | Loss: 1.44216 | Correct: 365/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 200 | Loss: 1.40246 | Correct: 370/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 300 | Loss: 1.49224 | Correct: 357/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 400 | Loss: 1.44178 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 500 | Loss: 1.38443 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 600 | Loss: 1.38865 | Correct: 370/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 700 | Loss: 1.41211 | Correct: 360/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 800 | Loss: 1.45593 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 900 | Loss: 1.37064 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 1000 | Loss: 1.42573 | Correct: 364/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 1100 | Loss: 1.43547 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 1200 | Loss: 1.44129 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 1300 | Loss: 1.38002 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 1400 | Loss: 1.44143 | Correct: 363/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 1500 | Loss: 1.44611 | Correct: 365/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 1600 | Loss: 1.40940 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 1700 | Loss: 1.43159 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 1800 | Loss: 1.41298 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 1900 | Loss: 1.40936 | Correct: 371/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 2000 | Loss: 1.44808 | Correct: 356/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 2100 | Loss: 1.43703 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 2200 | Loss: 1.42892 | Correct: 364/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 2300 | Loss: 1.48574 | Correct: 361/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 2400 | Loss: 1.48365 | Correct: 351/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 2500 | Loss: 1.48932 | Correct: 358/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 2600 | Loss: 1.47625 | Correct: 355/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 2700 | Loss: 1.40605 | Correct: 370/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 2800 | Loss: 1.42237 | Correct: 363/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 2900 | Loss: 1.49490 | Correct: 356/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 3000 | Loss: 1.48312 | Correct: 352/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 3100 | Loss: 1.44800 | Correct: 367/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 3200 | Loss: 1.42667 | Correct: 370/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 3300 | Loss: 1.47179 | Correct: 356/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 3400 | Loss: 1.37036 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 3500 | Loss: 1.47511 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 3600 | Loss: 1.42786 | Correct: 371/512\n",
      "Estimator: 004 | Epoch: 009 | Batch: 3700 | Loss: 1.47227 | Correct: 370/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 05:01:12,186 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 05:01:12,412 - INFO: Epoch: 009 | Validation Acc: 78.938 % | Historical Best: 78.938 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 010 | Batch: 000 | Loss: 1.43021 | Correct: 362/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 100 | Loss: 1.37692 | Correct: 382/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 200 | Loss: 1.36511 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 300 | Loss: 1.38493 | Correct: 361/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 400 | Loss: 1.38547 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 500 | Loss: 1.46332 | Correct: 350/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 600 | Loss: 1.40387 | Correct: 376/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 700 | Loss: 1.42125 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 800 | Loss: 1.47228 | Correct: 365/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 900 | Loss: 1.41977 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 1000 | Loss: 1.51977 | Correct: 353/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 1100 | Loss: 1.48103 | Correct: 352/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 1200 | Loss: 1.45956 | Correct: 360/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 1300 | Loss: 1.36372 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 1400 | Loss: 1.47844 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 1500 | Loss: 1.41249 | Correct: 384/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 1600 | Loss: 1.36858 | Correct: 385/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 1700 | Loss: 1.38430 | Correct: 369/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 1800 | Loss: 1.42096 | Correct: 364/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 1900 | Loss: 1.40063 | Correct: 367/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 2000 | Loss: 1.39577 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 2100 | Loss: 1.47899 | Correct: 350/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 2200 | Loss: 1.46975 | Correct: 360/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 2300 | Loss: 1.44894 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 2400 | Loss: 1.28952 | Correct: 399/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 2500 | Loss: 1.46557 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 2600 | Loss: 1.38049 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 2700 | Loss: 1.40060 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 2800 | Loss: 1.44787 | Correct: 352/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 2900 | Loss: 1.40477 | Correct: 369/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 3000 | Loss: 1.41956 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 3100 | Loss: 1.42433 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 3200 | Loss: 1.44419 | Correct: 360/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 3300 | Loss: 1.42694 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 3400 | Loss: 1.42543 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 3500 | Loss: 1.38207 | Correct: 375/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 3600 | Loss: 1.38431 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 010 | Batch: 3700 | Loss: 1.45695 | Correct: 363/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 000 | Loss: 1.35683 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 100 | Loss: 1.39360 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 200 | Loss: 1.41750 | Correct: 369/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 300 | Loss: 1.33883 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 400 | Loss: 1.35749 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 500 | Loss: 1.33340 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 600 | Loss: 1.38363 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 700 | Loss: 1.50887 | Correct: 354/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 800 | Loss: 1.41244 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 900 | Loss: 1.44511 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 1000 | Loss: 1.39475 | Correct: 375/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 1100 | Loss: 1.46117 | Correct: 357/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 1200 | Loss: 1.39434 | Correct: 387/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 1300 | Loss: 1.45317 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 1400 | Loss: 1.41777 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 1500 | Loss: 1.43091 | Correct: 367/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 1600 | Loss: 1.49728 | Correct: 356/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 1700 | Loss: 1.44856 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 1800 | Loss: 1.44237 | Correct: 369/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 1900 | Loss: 1.39348 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 2000 | Loss: 1.32640 | Correct: 392/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 2100 | Loss: 1.50101 | Correct: 345/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 2200 | Loss: 1.42156 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 2300 | Loss: 1.42939 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 2400 | Loss: 1.44014 | Correct: 358/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 2500 | Loss: 1.38405 | Correct: 374/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 2600 | Loss: 1.41992 | Correct: 358/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 2700 | Loss: 1.38151 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 2800 | Loss: 1.40260 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 2900 | Loss: 1.40080 | Correct: 367/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 3000 | Loss: 1.48751 | Correct: 354/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 3100 | Loss: 1.43886 | Correct: 362/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 3200 | Loss: 1.41785 | Correct: 374/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 3300 | Loss: 1.45805 | Correct: 353/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 3400 | Loss: 1.40819 | Correct: 371/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 3500 | Loss: 1.51648 | Correct: 346/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 3600 | Loss: 1.46985 | Correct: 362/512\n",
      "Estimator: 001 | Epoch: 010 | Batch: 3700 | Loss: 1.37578 | Correct: 365/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 000 | Loss: 1.39752 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 100 | Loss: 1.44605 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 200 | Loss: 1.43488 | Correct: 366/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 300 | Loss: 1.44042 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 400 | Loss: 1.48062 | Correct: 356/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 500 | Loss: 1.40177 | Correct: 365/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 600 | Loss: 1.38058 | Correct: 376/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 700 | Loss: 1.39541 | Correct: 370/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 800 | Loss: 1.40616 | Correct: 365/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 900 | Loss: 1.38308 | Correct: 376/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 1000 | Loss: 1.36957 | Correct: 377/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 1100 | Loss: 1.46930 | Correct: 364/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 1200 | Loss: 1.33407 | Correct: 397/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 1300 | Loss: 1.42887 | Correct: 358/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 1400 | Loss: 1.41991 | Correct: 363/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 1500 | Loss: 1.45079 | Correct: 363/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 1600 | Loss: 1.35304 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 1700 | Loss: 1.35440 | Correct: 366/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 1800 | Loss: 1.36960 | Correct: 387/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 1900 | Loss: 1.35378 | Correct: 389/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 2000 | Loss: 1.38604 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 2100 | Loss: 1.41837 | Correct: 367/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 2200 | Loss: 1.36385 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 2300 | Loss: 1.37068 | Correct: 376/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 2400 | Loss: 1.43974 | Correct: 367/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 2500 | Loss: 1.30966 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 2600 | Loss: 1.40694 | Correct: 366/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 2700 | Loss: 1.45957 | Correct: 354/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 2800 | Loss: 1.41517 | Correct: 364/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 2900 | Loss: 1.33629 | Correct: 390/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 3000 | Loss: 1.47149 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 3100 | Loss: 1.40725 | Correct: 379/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 3200 | Loss: 1.42890 | Correct: 369/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 3300 | Loss: 1.43892 | Correct: 365/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 3400 | Loss: 1.37401 | Correct: 382/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 3500 | Loss: 1.39051 | Correct: 365/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 3600 | Loss: 1.48245 | Correct: 364/512\n",
      "Estimator: 002 | Epoch: 010 | Batch: 3700 | Loss: 1.41753 | Correct: 378/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 000 | Loss: 1.40378 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 100 | Loss: 1.40300 | Correct: 376/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 200 | Loss: 1.41447 | Correct: 368/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 300 | Loss: 1.41184 | Correct: 367/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 400 | Loss: 1.47506 | Correct: 359/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 500 | Loss: 1.42635 | Correct: 361/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 600 | Loss: 1.48680 | Correct: 356/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 700 | Loss: 1.45845 | Correct: 353/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 800 | Loss: 1.36584 | Correct: 369/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 900 | Loss: 1.45231 | Correct: 363/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 1000 | Loss: 1.45924 | Correct: 353/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 1100 | Loss: 1.40591 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 1200 | Loss: 1.38636 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 1300 | Loss: 1.39415 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 1400 | Loss: 1.47394 | Correct: 364/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 1500 | Loss: 1.42345 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 1600 | Loss: 1.39737 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 1700 | Loss: 1.41066 | Correct: 374/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 1800 | Loss: 1.45530 | Correct: 363/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 1900 | Loss: 1.40779 | Correct: 368/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 2000 | Loss: 1.48305 | Correct: 360/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 2100 | Loss: 1.42940 | Correct: 362/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 2200 | Loss: 1.37107 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 2300 | Loss: 1.49395 | Correct: 363/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 2400 | Loss: 1.42229 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 2500 | Loss: 1.48697 | Correct: 360/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 2600 | Loss: 1.45038 | Correct: 362/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 2700 | Loss: 1.52021 | Correct: 350/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 2800 | Loss: 1.42921 | Correct: 364/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 2900 | Loss: 1.43856 | Correct: 374/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 3000 | Loss: 1.44009 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 3100 | Loss: 1.42237 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 3200 | Loss: 1.37161 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 3300 | Loss: 1.33735 | Correct: 390/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 3400 | Loss: 1.41676 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 3500 | Loss: 1.44439 | Correct: 369/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 3600 | Loss: 1.42514 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 010 | Batch: 3700 | Loss: 1.43997 | Correct: 363/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 000 | Loss: 1.31540 | Correct: 390/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 100 | Loss: 1.40080 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 200 | Loss: 1.45497 | Correct: 359/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 300 | Loss: 1.42241 | Correct: 363/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 400 | Loss: 1.37707 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 500 | Loss: 1.40186 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 600 | Loss: 1.36675 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 700 | Loss: 1.38696 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 800 | Loss: 1.47642 | Correct: 354/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 900 | Loss: 1.37575 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 1000 | Loss: 1.41534 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 1100 | Loss: 1.41150 | Correct: 378/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 1200 | Loss: 1.40526 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 1300 | Loss: 1.38640 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 1400 | Loss: 1.41137 | Correct: 361/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 1500 | Loss: 1.40727 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 1600 | Loss: 1.33823 | Correct: 389/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 1700 | Loss: 1.37656 | Correct: 371/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 1800 | Loss: 1.37347 | Correct: 371/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 1900 | Loss: 1.49313 | Correct: 346/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 2000 | Loss: 1.42549 | Correct: 360/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 2100 | Loss: 1.39536 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 2200 | Loss: 1.42730 | Correct: 360/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 2300 | Loss: 1.35854 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 2400 | Loss: 1.47140 | Correct: 350/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 2500 | Loss: 1.38243 | Correct: 371/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 2600 | Loss: 1.39730 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 2700 | Loss: 1.48420 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 2800 | Loss: 1.35951 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 2900 | Loss: 1.54468 | Correct: 344/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 3000 | Loss: 1.41079 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 3100 | Loss: 1.44283 | Correct: 370/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 3200 | Loss: 1.44535 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 3300 | Loss: 1.45001 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 3400 | Loss: 1.43124 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 3500 | Loss: 1.36955 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 3600 | Loss: 1.47317 | Correct: 355/512\n",
      "Estimator: 004 | Epoch: 010 | Batch: 3700 | Loss: 1.47081 | Correct: 364/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 05:04:16,719 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 05:04:16,941 - INFO: Epoch: 010 | Validation Acc: 79.524 % | Historical Best: 79.524 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 011 | Batch: 000 | Loss: 1.39950 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 100 | Loss: 1.37547 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 200 | Loss: 1.43422 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 300 | Loss: 1.36148 | Correct: 373/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 400 | Loss: 1.38799 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 500 | Loss: 1.51133 | Correct: 354/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 600 | Loss: 1.37779 | Correct: 375/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 700 | Loss: 1.44195 | Correct: 355/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 800 | Loss: 1.43362 | Correct: 367/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 900 | Loss: 1.43038 | Correct: 366/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 1000 | Loss: 1.42006 | Correct: 365/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 1100 | Loss: 1.37073 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 1200 | Loss: 1.37977 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 1300 | Loss: 1.38479 | Correct: 376/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 1400 | Loss: 1.33264 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 1500 | Loss: 1.41722 | Correct: 363/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 1600 | Loss: 1.44103 | Correct: 351/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 1700 | Loss: 1.48290 | Correct: 356/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 1800 | Loss: 1.38651 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 1900 | Loss: 1.49619 | Correct: 346/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 2000 | Loss: 1.42156 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 2100 | Loss: 1.38206 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 2200 | Loss: 1.45969 | Correct: 353/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 2300 | Loss: 1.45641 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 2400 | Loss: 1.41324 | Correct: 369/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 2500 | Loss: 1.38622 | Correct: 387/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 2600 | Loss: 1.40013 | Correct: 384/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 2700 | Loss: 1.39204 | Correct: 373/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 2800 | Loss: 1.44653 | Correct: 362/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 2900 | Loss: 1.36661 | Correct: 375/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 3000 | Loss: 1.43643 | Correct: 364/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 3100 | Loss: 1.38624 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 3200 | Loss: 1.40983 | Correct: 384/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 3300 | Loss: 1.47569 | Correct: 363/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 3400 | Loss: 1.43740 | Correct: 361/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 3500 | Loss: 1.39243 | Correct: 375/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 3600 | Loss: 1.42316 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 011 | Batch: 3700 | Loss: 1.39279 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 000 | Loss: 1.38874 | Correct: 360/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 100 | Loss: 1.37971 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 200 | Loss: 1.35537 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 300 | Loss: 1.42248 | Correct: 375/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 400 | Loss: 1.33053 | Correct: 386/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 500 | Loss: 1.44942 | Correct: 361/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 600 | Loss: 1.44727 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 700 | Loss: 1.40166 | Correct: 369/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 800 | Loss: 1.39760 | Correct: 363/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 900 | Loss: 1.48270 | Correct: 361/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 1000 | Loss: 1.33607 | Correct: 390/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 1100 | Loss: 1.44795 | Correct: 357/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 1200 | Loss: 1.49680 | Correct: 351/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 1300 | Loss: 1.48868 | Correct: 354/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 1400 | Loss: 1.42355 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 1500 | Loss: 1.46856 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 1600 | Loss: 1.39160 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 1700 | Loss: 1.43447 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 1800 | Loss: 1.42817 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 1900 | Loss: 1.34056 | Correct: 371/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 2000 | Loss: 1.43882 | Correct: 363/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 2100 | Loss: 1.41624 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 2200 | Loss: 1.40786 | Correct: 359/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 2300 | Loss: 1.41543 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 2400 | Loss: 1.39850 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 2500 | Loss: 1.51800 | Correct: 347/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 2600 | Loss: 1.44672 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 2700 | Loss: 1.45246 | Correct: 362/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 2800 | Loss: 1.36815 | Correct: 375/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 2900 | Loss: 1.41667 | Correct: 367/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 3000 | Loss: 1.43659 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 3100 | Loss: 1.40991 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 3200 | Loss: 1.35534 | Correct: 375/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 3300 | Loss: 1.42434 | Correct: 367/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 3400 | Loss: 1.33790 | Correct: 389/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 3500 | Loss: 1.38788 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 3600 | Loss: 1.40490 | Correct: 360/512\n",
      "Estimator: 001 | Epoch: 011 | Batch: 3700 | Loss: 1.41203 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 000 | Loss: 1.43198 | Correct: 368/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 100 | Loss: 1.37444 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 200 | Loss: 1.38080 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 300 | Loss: 1.39539 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 400 | Loss: 1.38078 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 500 | Loss: 1.38716 | Correct: 377/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 600 | Loss: 1.41026 | Correct: 376/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 700 | Loss: 1.37264 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 800 | Loss: 1.43630 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 900 | Loss: 1.39381 | Correct: 379/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 1000 | Loss: 1.41007 | Correct: 367/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 1100 | Loss: 1.39081 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 1200 | Loss: 1.41402 | Correct: 369/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 1300 | Loss: 1.33628 | Correct: 391/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 1400 | Loss: 1.42425 | Correct: 358/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 1500 | Loss: 1.44102 | Correct: 366/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 1600 | Loss: 1.43579 | Correct: 354/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 1700 | Loss: 1.32088 | Correct: 389/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 1800 | Loss: 1.42589 | Correct: 378/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 1900 | Loss: 1.35832 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 2000 | Loss: 1.39207 | Correct: 367/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 2100 | Loss: 1.37923 | Correct: 390/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 2200 | Loss: 1.28952 | Correct: 408/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 2300 | Loss: 1.40712 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 2400 | Loss: 1.44884 | Correct: 353/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 2500 | Loss: 1.39236 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 2600 | Loss: 1.34916 | Correct: 385/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 2700 | Loss: 1.46158 | Correct: 362/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 2800 | Loss: 1.46326 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 2900 | Loss: 1.46833 | Correct: 367/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 3000 | Loss: 1.34468 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 3100 | Loss: 1.31977 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 3200 | Loss: 1.35776 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 3300 | Loss: 1.45844 | Correct: 362/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 3400 | Loss: 1.40027 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 3500 | Loss: 1.36517 | Correct: 378/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 3600 | Loss: 1.35021 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 011 | Batch: 3700 | Loss: 1.44383 | Correct: 374/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 000 | Loss: 1.46820 | Correct: 361/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 100 | Loss: 1.41110 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 200 | Loss: 1.32384 | Correct: 386/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 300 | Loss: 1.36154 | Correct: 378/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 400 | Loss: 1.37280 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 500 | Loss: 1.43049 | Correct: 369/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 600 | Loss: 1.44148 | Correct: 356/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 700 | Loss: 1.34303 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 800 | Loss: 1.32547 | Correct: 385/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 900 | Loss: 1.38840 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 1000 | Loss: 1.40775 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 1100 | Loss: 1.37166 | Correct: 378/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 1200 | Loss: 1.49140 | Correct: 356/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 1300 | Loss: 1.46243 | Correct: 358/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 1400 | Loss: 1.44535 | Correct: 358/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 1500 | Loss: 1.42985 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 1600 | Loss: 1.37552 | Correct: 367/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 1700 | Loss: 1.44010 | Correct: 367/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 1800 | Loss: 1.37459 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 1900 | Loss: 1.52006 | Correct: 350/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 2000 | Loss: 1.40494 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 2100 | Loss: 1.41524 | Correct: 369/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 2200 | Loss: 1.43042 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 2300 | Loss: 1.41699 | Correct: 374/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 2400 | Loss: 1.42007 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 2500 | Loss: 1.37274 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 2600 | Loss: 1.42167 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 2700 | Loss: 1.44985 | Correct: 354/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 2800 | Loss: 1.42321 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 2900 | Loss: 1.42113 | Correct: 357/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 3000 | Loss: 1.38113 | Correct: 379/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 3100 | Loss: 1.44675 | Correct: 357/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 3200 | Loss: 1.41462 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 3300 | Loss: 1.43156 | Correct: 364/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 3400 | Loss: 1.40854 | Correct: 367/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 3500 | Loss: 1.38423 | Correct: 374/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 3600 | Loss: 1.47241 | Correct: 357/512\n",
      "Estimator: 003 | Epoch: 011 | Batch: 3700 | Loss: 1.43638 | Correct: 354/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 000 | Loss: 1.40371 | Correct: 367/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 100 | Loss: 1.36256 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 200 | Loss: 1.41997 | Correct: 357/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 300 | Loss: 1.38042 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 400 | Loss: 1.40039 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 500 | Loss: 1.51464 | Correct: 337/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 600 | Loss: 1.42010 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 700 | Loss: 1.42370 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 800 | Loss: 1.34238 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 900 | Loss: 1.51596 | Correct: 360/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 1000 | Loss: 1.43298 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 1100 | Loss: 1.35518 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 1200 | Loss: 1.37510 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 1300 | Loss: 1.34018 | Correct: 388/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 1400 | Loss: 1.39078 | Correct: 378/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 1500 | Loss: 1.38134 | Correct: 371/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 1600 | Loss: 1.31817 | Correct: 387/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 1700 | Loss: 1.39421 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 1800 | Loss: 1.37008 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 1900 | Loss: 1.40657 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 2000 | Loss: 1.32721 | Correct: 398/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 2100 | Loss: 1.44709 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 2200 | Loss: 1.35135 | Correct: 384/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 2300 | Loss: 1.44713 | Correct: 361/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 2400 | Loss: 1.40064 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 2500 | Loss: 1.38112 | Correct: 367/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 2600 | Loss: 1.37368 | Correct: 371/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 2700 | Loss: 1.35364 | Correct: 372/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 2800 | Loss: 1.37812 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 2900 | Loss: 1.45125 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 3000 | Loss: 1.34363 | Correct: 388/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 3100 | Loss: 1.39370 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 3200 | Loss: 1.42730 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 3300 | Loss: 1.35744 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 3400 | Loss: 1.43064 | Correct: 361/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 3500 | Loss: 1.38002 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 3600 | Loss: 1.42542 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 011 | Batch: 3700 | Loss: 1.38733 | Correct: 371/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 05:07:22,687 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 05:07:22,912 - INFO: Epoch: 011 | Validation Acc: 79.933 % | Historical Best: 79.933 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 012 | Batch: 000 | Loss: 1.34332 | Correct: 366/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 100 | Loss: 1.37412 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 200 | Loss: 1.37273 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 300 | Loss: 1.35482 | Correct: 384/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 400 | Loss: 1.44823 | Correct: 364/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 500 | Loss: 1.33956 | Correct: 383/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 600 | Loss: 1.37402 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 700 | Loss: 1.34416 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 800 | Loss: 1.40001 | Correct: 384/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 900 | Loss: 1.32038 | Correct: 394/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 1000 | Loss: 1.36593 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 1100 | Loss: 1.37964 | Correct: 366/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 1200 | Loss: 1.34985 | Correct: 384/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 1300 | Loss: 1.39631 | Correct: 367/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 1400 | Loss: 1.46384 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 1500 | Loss: 1.40779 | Correct: 363/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 1600 | Loss: 1.41386 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 1700 | Loss: 1.40938 | Correct: 376/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 1800 | Loss: 1.35122 | Correct: 376/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 1900 | Loss: 1.43811 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 2000 | Loss: 1.36380 | Correct: 375/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 2100 | Loss: 1.34118 | Correct: 383/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 2200 | Loss: 1.37106 | Correct: 376/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 2300 | Loss: 1.45471 | Correct: 366/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 2400 | Loss: 1.39299 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 2500 | Loss: 1.32946 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 2600 | Loss: 1.38072 | Correct: 384/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 2700 | Loss: 1.38886 | Correct: 376/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 2800 | Loss: 1.31833 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 2900 | Loss: 1.39757 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 3000 | Loss: 1.36720 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 3100 | Loss: 1.43543 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 3200 | Loss: 1.41820 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 3300 | Loss: 1.35780 | Correct: 379/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 3400 | Loss: 1.40605 | Correct: 363/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 3500 | Loss: 1.38856 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 3600 | Loss: 1.44259 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 012 | Batch: 3700 | Loss: 1.37949 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 000 | Loss: 1.44084 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 100 | Loss: 1.35249 | Correct: 388/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 200 | Loss: 1.37083 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 300 | Loss: 1.35737 | Correct: 371/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 400 | Loss: 1.37710 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 500 | Loss: 1.37516 | Correct: 371/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 600 | Loss: 1.39378 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 700 | Loss: 1.37405 | Correct: 379/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 800 | Loss: 1.43076 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 900 | Loss: 1.34428 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 1000 | Loss: 1.39256 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 1100 | Loss: 1.41273 | Correct: 374/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 1200 | Loss: 1.37672 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 1300 | Loss: 1.41899 | Correct: 354/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 1400 | Loss: 1.39882 | Correct: 361/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 1500 | Loss: 1.34427 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 1600 | Loss: 1.42564 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 1700 | Loss: 1.32244 | Correct: 379/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 1800 | Loss: 1.42195 | Correct: 360/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 1900 | Loss: 1.34053 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 2000 | Loss: 1.40515 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 2100 | Loss: 1.39017 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 2200 | Loss: 1.42199 | Correct: 363/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 2300 | Loss: 1.41446 | Correct: 367/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 2400 | Loss: 1.40974 | Correct: 371/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 2500 | Loss: 1.40096 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 2600 | Loss: 1.36022 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 2700 | Loss: 1.37710 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 2800 | Loss: 1.48457 | Correct: 357/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 2900 | Loss: 1.37781 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 3000 | Loss: 1.37081 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 3100 | Loss: 1.46238 | Correct: 360/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 3200 | Loss: 1.40068 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 3300 | Loss: 1.44514 | Correct: 352/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 3400 | Loss: 1.33250 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 3500 | Loss: 1.36152 | Correct: 385/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 3600 | Loss: 1.38679 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 012 | Batch: 3700 | Loss: 1.39560 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 000 | Loss: 1.43285 | Correct: 363/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 100 | Loss: 1.37856 | Correct: 376/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 200 | Loss: 1.42382 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 300 | Loss: 1.35315 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 400 | Loss: 1.36924 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 500 | Loss: 1.37858 | Correct: 379/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 600 | Loss: 1.40633 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 700 | Loss: 1.39501 | Correct: 369/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 800 | Loss: 1.38359 | Correct: 369/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 900 | Loss: 1.46759 | Correct: 364/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 1000 | Loss: 1.47948 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 1100 | Loss: 1.40333 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 1200 | Loss: 1.45269 | Correct: 350/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 1300 | Loss: 1.39620 | Correct: 382/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 1400 | Loss: 1.48456 | Correct: 354/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 1500 | Loss: 1.37438 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 1600 | Loss: 1.39721 | Correct: 363/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 1700 | Loss: 1.44122 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 1800 | Loss: 1.35079 | Correct: 382/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 1900 | Loss: 1.38257 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 2000 | Loss: 1.42205 | Correct: 369/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 2100 | Loss: 1.35597 | Correct: 376/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 2200 | Loss: 1.32485 | Correct: 379/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 2300 | Loss: 1.36778 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 2400 | Loss: 1.38510 | Correct: 385/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 2500 | Loss: 1.38777 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 2600 | Loss: 1.34179 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 2700 | Loss: 1.44832 | Correct: 368/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 2800 | Loss: 1.35205 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 2900 | Loss: 1.44051 | Correct: 370/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 3000 | Loss: 1.38333 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 3100 | Loss: 1.39919 | Correct: 370/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 3200 | Loss: 1.37717 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 3300 | Loss: 1.39264 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 3400 | Loss: 1.38788 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 3500 | Loss: 1.46953 | Correct: 365/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 3600 | Loss: 1.37955 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 012 | Batch: 3700 | Loss: 1.36968 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 000 | Loss: 1.40621 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 100 | Loss: 1.38371 | Correct: 374/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 200 | Loss: 1.41180 | Correct: 380/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 300 | Loss: 1.40421 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 400 | Loss: 1.35282 | Correct: 380/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 500 | Loss: 1.34285 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 600 | Loss: 1.40971 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 700 | Loss: 1.44675 | Correct: 375/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 800 | Loss: 1.37592 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 900 | Loss: 1.36594 | Correct: 390/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 1000 | Loss: 1.35228 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 1100 | Loss: 1.48248 | Correct: 367/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 1200 | Loss: 1.39756 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 1300 | Loss: 1.51687 | Correct: 353/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 1400 | Loss: 1.37149 | Correct: 369/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 1500 | Loss: 1.41157 | Correct: 369/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 1600 | Loss: 1.38950 | Correct: 361/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 1700 | Loss: 1.37630 | Correct: 369/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 1800 | Loss: 1.32278 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 1900 | Loss: 1.45652 | Correct: 356/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 2000 | Loss: 1.39384 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 2100 | Loss: 1.37126 | Correct: 381/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 2200 | Loss: 1.37610 | Correct: 375/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 2300 | Loss: 1.37215 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 2400 | Loss: 1.39495 | Correct: 369/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 2500 | Loss: 1.44772 | Correct: 363/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 2600 | Loss: 1.35398 | Correct: 384/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 2700 | Loss: 1.44392 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 2800 | Loss: 1.38183 | Correct: 381/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 2900 | Loss: 1.39887 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 3000 | Loss: 1.37201 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 3100 | Loss: 1.32139 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 3200 | Loss: 1.39930 | Correct: 357/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 3300 | Loss: 1.32828 | Correct: 376/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 3400 | Loss: 1.32705 | Correct: 384/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 3500 | Loss: 1.49313 | Correct: 350/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 3600 | Loss: 1.40999 | Correct: 378/512\n",
      "Estimator: 003 | Epoch: 012 | Batch: 3700 | Loss: 1.37708 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 000 | Loss: 1.40906 | Correct: 363/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 100 | Loss: 1.36704 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 200 | Loss: 1.42087 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 300 | Loss: 1.46211 | Correct: 365/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 400 | Loss: 1.39734 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 500 | Loss: 1.33298 | Correct: 391/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 600 | Loss: 1.34688 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 700 | Loss: 1.37794 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 800 | Loss: 1.41825 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 900 | Loss: 1.39458 | Correct: 372/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 1000 | Loss: 1.44021 | Correct: 358/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 1100 | Loss: 1.37005 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 1200 | Loss: 1.34221 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 1300 | Loss: 1.47552 | Correct: 361/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 1400 | Loss: 1.39799 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 1500 | Loss: 1.40100 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 1600 | Loss: 1.41181 | Correct: 385/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 1700 | Loss: 1.41767 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 1800 | Loss: 1.40714 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 1900 | Loss: 1.41209 | Correct: 370/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 2000 | Loss: 1.43792 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 2100 | Loss: 1.44854 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 2200 | Loss: 1.45947 | Correct: 355/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 2300 | Loss: 1.40430 | Correct: 385/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 2400 | Loss: 1.32959 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 2500 | Loss: 1.33818 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 2600 | Loss: 1.36165 | Correct: 384/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 2700 | Loss: 1.33202 | Correct: 393/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 2800 | Loss: 1.42053 | Correct: 361/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 2900 | Loss: 1.36021 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 3000 | Loss: 1.43504 | Correct: 360/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 3100 | Loss: 1.42222 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 3200 | Loss: 1.36950 | Correct: 383/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 3300 | Loss: 1.40847 | Correct: 347/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 3400 | Loss: 1.43050 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 3500 | Loss: 1.44095 | Correct: 367/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 3600 | Loss: 1.38488 | Correct: 378/512\n",
      "Estimator: 004 | Epoch: 012 | Batch: 3700 | Loss: 1.37073 | Correct: 374/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 05:10:26,510 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 05:10:26,734 - INFO: Epoch: 012 | Validation Acc: 80.491 % | Historical Best: 80.491 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 013 | Batch: 000 | Loss: 1.36915 | Correct: 386/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 100 | Loss: 1.43436 | Correct: 353/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 200 | Loss: 1.44455 | Correct: 365/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 300 | Loss: 1.41369 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 400 | Loss: 1.40804 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 500 | Loss: 1.45707 | Correct: 352/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 600 | Loss: 1.40373 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 700 | Loss: 1.45357 | Correct: 367/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 800 | Loss: 1.37311 | Correct: 385/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 900 | Loss: 1.42397 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 1000 | Loss: 1.36645 | Correct: 383/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 1100 | Loss: 1.37403 | Correct: 379/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 1200 | Loss: 1.35785 | Correct: 382/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 1300 | Loss: 1.38071 | Correct: 375/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 1400 | Loss: 1.32283 | Correct: 390/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 1500 | Loss: 1.40956 | Correct: 373/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 1600 | Loss: 1.28042 | Correct: 388/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 1700 | Loss: 1.37312 | Correct: 369/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 1800 | Loss: 1.41162 | Correct: 375/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 1900 | Loss: 1.41551 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 2000 | Loss: 1.38746 | Correct: 365/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 2100 | Loss: 1.43031 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 2200 | Loss: 1.41753 | Correct: 366/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 2300 | Loss: 1.42935 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 2400 | Loss: 1.40940 | Correct: 364/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 2500 | Loss: 1.41349 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 2600 | Loss: 1.37400 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 2700 | Loss: 1.30672 | Correct: 396/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 2800 | Loss: 1.46314 | Correct: 362/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 2900 | Loss: 1.34150 | Correct: 376/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 3000 | Loss: 1.37746 | Correct: 379/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 3100 | Loss: 1.33359 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 3200 | Loss: 1.35751 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 3300 | Loss: 1.39233 | Correct: 365/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 3400 | Loss: 1.37107 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 3500 | Loss: 1.35991 | Correct: 375/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 3600 | Loss: 1.38283 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 013 | Batch: 3700 | Loss: 1.34572 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 000 | Loss: 1.38725 | Correct: 363/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 100 | Loss: 1.33058 | Correct: 383/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 200 | Loss: 1.38512 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 300 | Loss: 1.29840 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 400 | Loss: 1.37239 | Correct: 390/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 500 | Loss: 1.33740 | Correct: 391/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 600 | Loss: 1.33537 | Correct: 379/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 700 | Loss: 1.34882 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 800 | Loss: 1.35743 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 900 | Loss: 1.37011 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 1000 | Loss: 1.33473 | Correct: 392/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 1100 | Loss: 1.33647 | Correct: 393/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 1200 | Loss: 1.42787 | Correct: 371/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 1300 | Loss: 1.38787 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 1400 | Loss: 1.42865 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 1500 | Loss: 1.39745 | Correct: 367/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 1600 | Loss: 1.39491 | Correct: 379/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 1700 | Loss: 1.32432 | Correct: 385/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 1800 | Loss: 1.27861 | Correct: 395/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 1900 | Loss: 1.35906 | Correct: 375/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 2000 | Loss: 1.42439 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 2100 | Loss: 1.41029 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 2200 | Loss: 1.32149 | Correct: 386/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 2300 | Loss: 1.39997 | Correct: 375/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 2400 | Loss: 1.38439 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 2500 | Loss: 1.37068 | Correct: 385/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 2600 | Loss: 1.35551 | Correct: 385/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 2700 | Loss: 1.44041 | Correct: 367/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 2800 | Loss: 1.43132 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 2900 | Loss: 1.38797 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 3000 | Loss: 1.39493 | Correct: 375/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 3100 | Loss: 1.40313 | Correct: 371/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 3200 | Loss: 1.35735 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 3300 | Loss: 1.33931 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 3400 | Loss: 1.40068 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 3500 | Loss: 1.37756 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 3600 | Loss: 1.38745 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 013 | Batch: 3700 | Loss: 1.31014 | Correct: 389/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 000 | Loss: 1.36056 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 100 | Loss: 1.40844 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 200 | Loss: 1.42829 | Correct: 365/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 300 | Loss: 1.44095 | Correct: 369/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 400 | Loss: 1.36243 | Correct: 376/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 500 | Loss: 1.42824 | Correct: 366/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 600 | Loss: 1.35750 | Correct: 385/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 700 | Loss: 1.37000 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 800 | Loss: 1.40730 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 900 | Loss: 1.43529 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 1000 | Loss: 1.43385 | Correct: 357/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 1100 | Loss: 1.37637 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 1200 | Loss: 1.30049 | Correct: 393/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 1300 | Loss: 1.48055 | Correct: 347/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 1400 | Loss: 1.39272 | Correct: 367/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 1500 | Loss: 1.37800 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 1600 | Loss: 1.37998 | Correct: 366/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 1700 | Loss: 1.30823 | Correct: 391/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 1800 | Loss: 1.35392 | Correct: 379/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 1900 | Loss: 1.40897 | Correct: 377/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 2000 | Loss: 1.36569 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 2100 | Loss: 1.32239 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 2200 | Loss: 1.42623 | Correct: 362/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 2300 | Loss: 1.44116 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 2400 | Loss: 1.34279 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 2500 | Loss: 1.45339 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 2600 | Loss: 1.36464 | Correct: 385/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 2700 | Loss: 1.39382 | Correct: 368/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 2800 | Loss: 1.41930 | Correct: 368/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 2900 | Loss: 1.41816 | Correct: 369/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 3000 | Loss: 1.36430 | Correct: 379/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 3100 | Loss: 1.34966 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 3200 | Loss: 1.38177 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 3300 | Loss: 1.34318 | Correct: 382/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 3400 | Loss: 1.38657 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 3500 | Loss: 1.36060 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 3600 | Loss: 1.46242 | Correct: 365/512\n",
      "Estimator: 002 | Epoch: 013 | Batch: 3700 | Loss: 1.40339 | Correct: 380/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 000 | Loss: 1.33323 | Correct: 384/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 100 | Loss: 1.46504 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 200 | Loss: 1.36893 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 300 | Loss: 1.29909 | Correct: 387/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 400 | Loss: 1.37830 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 500 | Loss: 1.43099 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 600 | Loss: 1.40299 | Correct: 379/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 700 | Loss: 1.33986 | Correct: 393/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 800 | Loss: 1.33472 | Correct: 383/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 900 | Loss: 1.36245 | Correct: 378/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 1000 | Loss: 1.36019 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 1100 | Loss: 1.43637 | Correct: 362/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 1200 | Loss: 1.34384 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 1300 | Loss: 1.28697 | Correct: 401/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 1400 | Loss: 1.37479 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 1500 | Loss: 1.32510 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 1600 | Loss: 1.36916 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 1700 | Loss: 1.37167 | Correct: 376/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 1800 | Loss: 1.33016 | Correct: 390/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 1900 | Loss: 1.40548 | Correct: 368/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 2000 | Loss: 1.38091 | Correct: 367/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 2100 | Loss: 1.37365 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 2200 | Loss: 1.39321 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 2300 | Loss: 1.43918 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 2400 | Loss: 1.40465 | Correct: 364/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 2500 | Loss: 1.40172 | Correct: 367/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 2600 | Loss: 1.24172 | Correct: 412/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 2700 | Loss: 1.34509 | Correct: 386/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 2800 | Loss: 1.45147 | Correct: 363/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 2900 | Loss: 1.42257 | Correct: 369/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 3000 | Loss: 1.32603 | Correct: 383/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 3100 | Loss: 1.42689 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 3200 | Loss: 1.49527 | Correct: 352/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 3300 | Loss: 1.41692 | Correct: 363/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 3400 | Loss: 1.42142 | Correct: 367/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 3500 | Loss: 1.34292 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 3600 | Loss: 1.34646 | Correct: 376/512\n",
      "Estimator: 003 | Epoch: 013 | Batch: 3700 | Loss: 1.33045 | Correct: 390/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 000 | Loss: 1.40382 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 100 | Loss: 1.37443 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 200 | Loss: 1.35862 | Correct: 388/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 300 | Loss: 1.36753 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 400 | Loss: 1.39565 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 500 | Loss: 1.36003 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 600 | Loss: 1.35761 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 700 | Loss: 1.33417 | Correct: 383/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 800 | Loss: 1.34460 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 900 | Loss: 1.36684 | Correct: 378/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 1000 | Loss: 1.40571 | Correct: 370/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 1100 | Loss: 1.40634 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 1200 | Loss: 1.37229 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 1300 | Loss: 1.37816 | Correct: 371/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 1400 | Loss: 1.36729 | Correct: 387/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 1500 | Loss: 1.41846 | Correct: 367/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 1600 | Loss: 1.38967 | Correct: 372/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 1700 | Loss: 1.35103 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 1800 | Loss: 1.36739 | Correct: 385/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 1900 | Loss: 1.37294 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 2000 | Loss: 1.35843 | Correct: 378/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 2100 | Loss: 1.37592 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 2200 | Loss: 1.34997 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 2300 | Loss: 1.45955 | Correct: 361/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 2400 | Loss: 1.40512 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 2500 | Loss: 1.40535 | Correct: 367/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 2600 | Loss: 1.33205 | Correct: 388/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 2700 | Loss: 1.45573 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 2800 | Loss: 1.38718 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 2900 | Loss: 1.36354 | Correct: 378/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 3000 | Loss: 1.36560 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 3100 | Loss: 1.34728 | Correct: 387/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 3200 | Loss: 1.50115 | Correct: 348/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 3300 | Loss: 1.37989 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 3400 | Loss: 1.40054 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 3500 | Loss: 1.42139 | Correct: 360/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 3600 | Loss: 1.38456 | Correct: 357/512\n",
      "Estimator: 004 | Epoch: 013 | Batch: 3700 | Loss: 1.42893 | Correct: 370/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 05:13:29,881 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 05:13:30,102 - INFO: Epoch: 013 | Validation Acc: 80.806 % | Historical Best: 80.806 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 014 | Batch: 000 | Loss: 1.40249 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 100 | Loss: 1.37598 | Correct: 386/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 200 | Loss: 1.34789 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 300 | Loss: 1.32452 | Correct: 379/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 400 | Loss: 1.42079 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 500 | Loss: 1.37481 | Correct: 379/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 600 | Loss: 1.35895 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 700 | Loss: 1.40791 | Correct: 365/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 800 | Loss: 1.33730 | Correct: 375/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 900 | Loss: 1.37219 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 1000 | Loss: 1.36684 | Correct: 373/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 1100 | Loss: 1.36705 | Correct: 384/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 1200 | Loss: 1.36952 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 1300 | Loss: 1.35950 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 1400 | Loss: 1.33176 | Correct: 389/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 1500 | Loss: 1.38654 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 1600 | Loss: 1.45282 | Correct: 356/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 1700 | Loss: 1.39722 | Correct: 384/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 1800 | Loss: 1.43748 | Correct: 357/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 1900 | Loss: 1.34446 | Correct: 390/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 2000 | Loss: 1.40919 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 2100 | Loss: 1.35129 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 2200 | Loss: 1.32374 | Correct: 386/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 2300 | Loss: 1.38520 | Correct: 379/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 2400 | Loss: 1.39740 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 2500 | Loss: 1.42562 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 2600 | Loss: 1.34861 | Correct: 379/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 2700 | Loss: 1.32484 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 2800 | Loss: 1.37720 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 2900 | Loss: 1.42354 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 3000 | Loss: 1.41701 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 3100 | Loss: 1.43353 | Correct: 382/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 3200 | Loss: 1.35592 | Correct: 382/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 3300 | Loss: 1.38182 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 3400 | Loss: 1.36898 | Correct: 390/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 3500 | Loss: 1.37059 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 3600 | Loss: 1.35840 | Correct: 379/512\n",
      "Estimator: 000 | Epoch: 014 | Batch: 3700 | Loss: 1.37662 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 000 | Loss: 1.30042 | Correct: 392/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 100 | Loss: 1.40375 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 200 | Loss: 1.33831 | Correct: 379/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 300 | Loss: 1.38535 | Correct: 369/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 400 | Loss: 1.35276 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 500 | Loss: 1.25805 | Correct: 399/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 600 | Loss: 1.41165 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 700 | Loss: 1.44241 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 800 | Loss: 1.36943 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 900 | Loss: 1.34079 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 1000 | Loss: 1.42524 | Correct: 361/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 1100 | Loss: 1.40859 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 1200 | Loss: 1.38401 | Correct: 367/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 1300 | Loss: 1.32254 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 1400 | Loss: 1.35715 | Correct: 389/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 1500 | Loss: 1.40441 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 1600 | Loss: 1.41107 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 1700 | Loss: 1.36911 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 1800 | Loss: 1.33242 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 1900 | Loss: 1.39864 | Correct: 374/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 2000 | Loss: 1.36994 | Correct: 389/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 2100 | Loss: 1.37482 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 2200 | Loss: 1.32971 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 2300 | Loss: 1.33998 | Correct: 387/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 2400 | Loss: 1.41508 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 2500 | Loss: 1.35363 | Correct: 393/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 2600 | Loss: 1.40699 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 2700 | Loss: 1.34725 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 2800 | Loss: 1.48084 | Correct: 359/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 2900 | Loss: 1.43368 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 3000 | Loss: 1.45514 | Correct: 354/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 3100 | Loss: 1.33858 | Correct: 385/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 3200 | Loss: 1.37580 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 3300 | Loss: 1.31409 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 3400 | Loss: 1.38340 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 3500 | Loss: 1.42730 | Correct: 352/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 3600 | Loss: 1.36284 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 014 | Batch: 3700 | Loss: 1.36642 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 000 | Loss: 1.33270 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 100 | Loss: 1.32414 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 200 | Loss: 1.44693 | Correct: 370/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 300 | Loss: 1.32125 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 400 | Loss: 1.42451 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 500 | Loss: 1.40670 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 600 | Loss: 1.38661 | Correct: 365/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 700 | Loss: 1.38715 | Correct: 370/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 800 | Loss: 1.32160 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 900 | Loss: 1.32306 | Correct: 385/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 1000 | Loss: 1.41098 | Correct: 377/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 1100 | Loss: 1.37155 | Correct: 379/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 1200 | Loss: 1.36083 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 1300 | Loss: 1.33662 | Correct: 376/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 1400 | Loss: 1.43578 | Correct: 370/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 1500 | Loss: 1.31711 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 1600 | Loss: 1.36594 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 1700 | Loss: 1.42847 | Correct: 358/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 1800 | Loss: 1.32762 | Correct: 391/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 1900 | Loss: 1.37577 | Correct: 370/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 2000 | Loss: 1.37195 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 2100 | Loss: 1.34558 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 2200 | Loss: 1.33145 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 2300 | Loss: 1.33336 | Correct: 392/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 2400 | Loss: 1.34014 | Correct: 391/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 2500 | Loss: 1.39029 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 2600 | Loss: 1.38318 | Correct: 367/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 2700 | Loss: 1.38163 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 2800 | Loss: 1.31272 | Correct: 382/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 2900 | Loss: 1.40114 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 3000 | Loss: 1.37912 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 3100 | Loss: 1.38325 | Correct: 376/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 3200 | Loss: 1.43297 | Correct: 370/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 3300 | Loss: 1.39535 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 3400 | Loss: 1.47926 | Correct: 352/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 3500 | Loss: 1.38819 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 3600 | Loss: 1.30888 | Correct: 382/512\n",
      "Estimator: 002 | Epoch: 014 | Batch: 3700 | Loss: 1.40760 | Correct: 363/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 000 | Loss: 1.38078 | Correct: 388/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 100 | Loss: 1.39548 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 200 | Loss: 1.30619 | Correct: 393/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 300 | Loss: 1.38362 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 400 | Loss: 1.37433 | Correct: 381/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 500 | Loss: 1.38617 | Correct: 380/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 600 | Loss: 1.47850 | Correct: 353/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 700 | Loss: 1.28748 | Correct: 398/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 800 | Loss: 1.33627 | Correct: 384/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 900 | Loss: 1.38764 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 1000 | Loss: 1.29719 | Correct: 398/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 1100 | Loss: 1.37361 | Correct: 367/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 1200 | Loss: 1.37773 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 1300 | Loss: 1.47555 | Correct: 360/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 1400 | Loss: 1.35903 | Correct: 389/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 1500 | Loss: 1.38828 | Correct: 384/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 1600 | Loss: 1.41484 | Correct: 374/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 1700 | Loss: 1.34314 | Correct: 383/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 1800 | Loss: 1.32970 | Correct: 396/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 1900 | Loss: 1.36699 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 2000 | Loss: 1.33327 | Correct: 386/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 2100 | Loss: 1.38269 | Correct: 357/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 2200 | Loss: 1.42038 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 2300 | Loss: 1.33064 | Correct: 386/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 2400 | Loss: 1.33734 | Correct: 384/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 2500 | Loss: 1.41332 | Correct: 362/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 2600 | Loss: 1.36508 | Correct: 378/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 2700 | Loss: 1.42779 | Correct: 361/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 2800 | Loss: 1.28243 | Correct: 396/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 2900 | Loss: 1.38881 | Correct: 366/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 3000 | Loss: 1.31332 | Correct: 393/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 3100 | Loss: 1.38440 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 3200 | Loss: 1.30128 | Correct: 393/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 3300 | Loss: 1.40826 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 3400 | Loss: 1.46919 | Correct: 357/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 3500 | Loss: 1.35349 | Correct: 375/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 3600 | Loss: 1.32205 | Correct: 386/512\n",
      "Estimator: 003 | Epoch: 014 | Batch: 3700 | Loss: 1.36773 | Correct: 378/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 000 | Loss: 1.38470 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 100 | Loss: 1.42568 | Correct: 365/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 200 | Loss: 1.37457 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 300 | Loss: 1.36732 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 400 | Loss: 1.39601 | Correct: 378/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 500 | Loss: 1.43193 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 600 | Loss: 1.40211 | Correct: 370/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 700 | Loss: 1.38449 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 800 | Loss: 1.34488 | Correct: 388/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 900 | Loss: 1.40294 | Correct: 372/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 1000 | Loss: 1.47133 | Correct: 360/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 1100 | Loss: 1.40868 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 1200 | Loss: 1.36770 | Correct: 371/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 1300 | Loss: 1.40058 | Correct: 370/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 1400 | Loss: 1.37039 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 1500 | Loss: 1.36485 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 1600 | Loss: 1.37860 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 1700 | Loss: 1.38036 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 1800 | Loss: 1.33569 | Correct: 385/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 1900 | Loss: 1.44755 | Correct: 358/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 2000 | Loss: 1.40617 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 2100 | Loss: 1.47043 | Correct: 358/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 2200 | Loss: 1.44520 | Correct: 365/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 2300 | Loss: 1.38878 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 2400 | Loss: 1.35733 | Correct: 391/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 2500 | Loss: 1.33450 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 2600 | Loss: 1.35053 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 2700 | Loss: 1.39879 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 2800 | Loss: 1.42116 | Correct: 363/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 2900 | Loss: 1.39185 | Correct: 372/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 3000 | Loss: 1.34076 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 3100 | Loss: 1.32734 | Correct: 384/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 3200 | Loss: 1.33335 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 3300 | Loss: 1.34385 | Correct: 372/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 3400 | Loss: 1.29265 | Correct: 387/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 3500 | Loss: 1.43234 | Correct: 355/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 3600 | Loss: 1.32999 | Correct: 385/512\n",
      "Estimator: 004 | Epoch: 014 | Batch: 3700 | Loss: 1.37931 | Correct: 364/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 05:16:34,030 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 05:16:34,250 - INFO: Epoch: 014 | Validation Acc: 81.296 % | Historical Best: 81.296 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 015 | Batch: 000 | Loss: 1.36458 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 100 | Loss: 1.41462 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 200 | Loss: 1.35948 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 300 | Loss: 1.37068 | Correct: 382/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 400 | Loss: 1.27279 | Correct: 397/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 500 | Loss: 1.37821 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 600 | Loss: 1.35569 | Correct: 379/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 700 | Loss: 1.33497 | Correct: 395/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 800 | Loss: 1.35986 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 900 | Loss: 1.41538 | Correct: 366/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 1000 | Loss: 1.41068 | Correct: 358/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 1100 | Loss: 1.35763 | Correct: 389/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 1200 | Loss: 1.35465 | Correct: 373/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 1300 | Loss: 1.36847 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 1400 | Loss: 1.34623 | Correct: 386/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 1500 | Loss: 1.33832 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 1600 | Loss: 1.40059 | Correct: 363/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 1700 | Loss: 1.39276 | Correct: 376/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 1800 | Loss: 1.44257 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 1900 | Loss: 1.31865 | Correct: 387/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 2000 | Loss: 1.38727 | Correct: 386/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 2100 | Loss: 1.28093 | Correct: 391/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 2200 | Loss: 1.39422 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 2300 | Loss: 1.34762 | Correct: 379/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 2400 | Loss: 1.41154 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 2500 | Loss: 1.34031 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 2600 | Loss: 1.41944 | Correct: 360/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 2700 | Loss: 1.36087 | Correct: 384/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 2800 | Loss: 1.36584 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 2900 | Loss: 1.41769 | Correct: 365/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 3000 | Loss: 1.39767 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 3100 | Loss: 1.32484 | Correct: 391/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 3200 | Loss: 1.37821 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 3300 | Loss: 1.40105 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 3400 | Loss: 1.34307 | Correct: 386/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 3500 | Loss: 1.35836 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 3600 | Loss: 1.34900 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 015 | Batch: 3700 | Loss: 1.38285 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 000 | Loss: 1.36906 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 100 | Loss: 1.36805 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 200 | Loss: 1.44284 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 300 | Loss: 1.34817 | Correct: 388/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 400 | Loss: 1.33962 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 500 | Loss: 1.32705 | Correct: 385/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 600 | Loss: 1.40320 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 700 | Loss: 1.34771 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 800 | Loss: 1.33332 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 900 | Loss: 1.37890 | Correct: 383/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 1000 | Loss: 1.35630 | Correct: 386/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 1100 | Loss: 1.35199 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 1200 | Loss: 1.36378 | Correct: 385/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 1300 | Loss: 1.36612 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 1400 | Loss: 1.42273 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 1500 | Loss: 1.34547 | Correct: 387/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 1600 | Loss: 1.37955 | Correct: 371/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 1700 | Loss: 1.42853 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 1800 | Loss: 1.34881 | Correct: 388/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 1900 | Loss: 1.39066 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 2000 | Loss: 1.32312 | Correct: 379/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 2100 | Loss: 1.33505 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 2200 | Loss: 1.46146 | Correct: 362/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 2300 | Loss: 1.30003 | Correct: 388/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 2400 | Loss: 1.36475 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 2500 | Loss: 1.34238 | Correct: 388/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 2600 | Loss: 1.35208 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 2700 | Loss: 1.38817 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 2800 | Loss: 1.36190 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 2900 | Loss: 1.33841 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 3000 | Loss: 1.32887 | Correct: 383/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 3100 | Loss: 1.35069 | Correct: 390/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 3200 | Loss: 1.36712 | Correct: 383/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 3300 | Loss: 1.37932 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 3400 | Loss: 1.44153 | Correct: 357/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 3500 | Loss: 1.36565 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 3600 | Loss: 1.45367 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 015 | Batch: 3700 | Loss: 1.34299 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 000 | Loss: 1.38620 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 100 | Loss: 1.43885 | Correct: 359/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 200 | Loss: 1.38526 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 300 | Loss: 1.37598 | Correct: 369/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 400 | Loss: 1.35231 | Correct: 378/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 500 | Loss: 1.34781 | Correct: 382/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 600 | Loss: 1.36635 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 700 | Loss: 1.34487 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 800 | Loss: 1.40079 | Correct: 366/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 900 | Loss: 1.28213 | Correct: 397/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 1000 | Loss: 1.41930 | Correct: 369/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 1100 | Loss: 1.43735 | Correct: 363/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 1200 | Loss: 1.33886 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 1300 | Loss: 1.41441 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 1400 | Loss: 1.29993 | Correct: 392/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 1500 | Loss: 1.34630 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 1600 | Loss: 1.29034 | Correct: 396/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 1700 | Loss: 1.38346 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 1800 | Loss: 1.39215 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 1900 | Loss: 1.42469 | Correct: 368/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 2000 | Loss: 1.31705 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 2100 | Loss: 1.31547 | Correct: 395/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 2200 | Loss: 1.37254 | Correct: 378/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 2300 | Loss: 1.36795 | Correct: 379/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 2400 | Loss: 1.36599 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 2500 | Loss: 1.33839 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 2600 | Loss: 1.32677 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 2700 | Loss: 1.40088 | Correct: 367/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 2800 | Loss: 1.41112 | Correct: 363/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 2900 | Loss: 1.34863 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 3000 | Loss: 1.31229 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 3100 | Loss: 1.41953 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 3200 | Loss: 1.39565 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 3300 | Loss: 1.37524 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 3400 | Loss: 1.34448 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 3500 | Loss: 1.31585 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 3600 | Loss: 1.34060 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 015 | Batch: 3700 | Loss: 1.30135 | Correct: 395/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 000 | Loss: 1.28672 | Correct: 392/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 100 | Loss: 1.35299 | Correct: 385/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 200 | Loss: 1.35887 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 300 | Loss: 1.33367 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 400 | Loss: 1.45518 | Correct: 368/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 500 | Loss: 1.36031 | Correct: 386/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 600 | Loss: 1.42697 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 700 | Loss: 1.38573 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 800 | Loss: 1.37463 | Correct: 379/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 900 | Loss: 1.30195 | Correct: 394/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 1000 | Loss: 1.32517 | Correct: 391/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 1100 | Loss: 1.35682 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 1200 | Loss: 1.38878 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 1300 | Loss: 1.33886 | Correct: 375/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 1400 | Loss: 1.42672 | Correct: 369/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 1500 | Loss: 1.27080 | Correct: 402/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 1600 | Loss: 1.42652 | Correct: 361/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 1700 | Loss: 1.44739 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 1800 | Loss: 1.42912 | Correct: 357/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 1900 | Loss: 1.36185 | Correct: 379/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 2000 | Loss: 1.40903 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 2100 | Loss: 1.35604 | Correct: 376/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 2200 | Loss: 1.40812 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 2300 | Loss: 1.43470 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 2400 | Loss: 1.40879 | Correct: 360/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 2500 | Loss: 1.42851 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 2600 | Loss: 1.32895 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 2700 | Loss: 1.42944 | Correct: 362/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 2800 | Loss: 1.41899 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 2900 | Loss: 1.30314 | Correct: 385/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 3000 | Loss: 1.34031 | Correct: 376/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 3100 | Loss: 1.38945 | Correct: 375/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 3200 | Loss: 1.32023 | Correct: 393/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 3300 | Loss: 1.37870 | Correct: 379/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 3400 | Loss: 1.37716 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 3500 | Loss: 1.41244 | Correct: 376/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 3600 | Loss: 1.42574 | Correct: 369/512\n",
      "Estimator: 003 | Epoch: 015 | Batch: 3700 | Loss: 1.38179 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 000 | Loss: 1.31498 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 100 | Loss: 1.32928 | Correct: 391/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 200 | Loss: 1.32995 | Correct: 389/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 300 | Loss: 1.34879 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 400 | Loss: 1.32124 | Correct: 391/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 500 | Loss: 1.30548 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 600 | Loss: 1.34838 | Correct: 390/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 700 | Loss: 1.32905 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 800 | Loss: 1.34259 | Correct: 389/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 900 | Loss: 1.27847 | Correct: 394/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 1000 | Loss: 1.34467 | Correct: 384/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 1100 | Loss: 1.38139 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 1200 | Loss: 1.29739 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 1300 | Loss: 1.30241 | Correct: 394/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 1400 | Loss: 1.40736 | Correct: 353/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 1500 | Loss: 1.33887 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 1600 | Loss: 1.35921 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 1700 | Loss: 1.34554 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 1800 | Loss: 1.34731 | Correct: 388/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 1900 | Loss: 1.37516 | Correct: 378/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 2000 | Loss: 1.33048 | Correct: 389/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 2100 | Loss: 1.37113 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 2200 | Loss: 1.31365 | Correct: 387/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 2300 | Loss: 1.26778 | Correct: 402/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 2400 | Loss: 1.40432 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 2500 | Loss: 1.34058 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 2600 | Loss: 1.29424 | Correct: 391/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 2700 | Loss: 1.38668 | Correct: 365/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 2800 | Loss: 1.34249 | Correct: 390/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 2900 | Loss: 1.32800 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 3000 | Loss: 1.40644 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 3100 | Loss: 1.47848 | Correct: 353/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 3200 | Loss: 1.31699 | Correct: 385/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 3300 | Loss: 1.46232 | Correct: 352/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 3400 | Loss: 1.23822 | Correct: 402/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 3500 | Loss: 1.31994 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 3600 | Loss: 1.36592 | Correct: 368/512\n",
      "Estimator: 004 | Epoch: 015 | Batch: 3700 | Loss: 1.34612 | Correct: 382/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 05:19:36,586 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 05:19:36,810 - INFO: Epoch: 015 | Validation Acc: 81.677 % | Historical Best: 81.677 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 016 | Batch: 000 | Loss: 1.34256 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 100 | Loss: 1.32475 | Correct: 397/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 200 | Loss: 1.31548 | Correct: 393/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 300 | Loss: 1.33696 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 400 | Loss: 1.33407 | Correct: 375/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 500 | Loss: 1.35844 | Correct: 379/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 600 | Loss: 1.43789 | Correct: 355/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 700 | Loss: 1.36824 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 800 | Loss: 1.35339 | Correct: 386/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 900 | Loss: 1.39479 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 1000 | Loss: 1.39892 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 1100 | Loss: 1.39120 | Correct: 362/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 1200 | Loss: 1.33408 | Correct: 373/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 1300 | Loss: 1.33742 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 1400 | Loss: 1.28437 | Correct: 391/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 1500 | Loss: 1.40375 | Correct: 376/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 1600 | Loss: 1.29180 | Correct: 394/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 1700 | Loss: 1.32337 | Correct: 393/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 1800 | Loss: 1.36821 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 1900 | Loss: 1.33110 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 2000 | Loss: 1.37820 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 2100 | Loss: 1.39238 | Correct: 369/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 2200 | Loss: 1.34121 | Correct: 386/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 2300 | Loss: 1.38731 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 2400 | Loss: 1.42119 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 2500 | Loss: 1.33528 | Correct: 384/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 2600 | Loss: 1.40994 | Correct: 362/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 2700 | Loss: 1.26731 | Correct: 398/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 2800 | Loss: 1.41118 | Correct: 373/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 2900 | Loss: 1.32166 | Correct: 400/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 3000 | Loss: 1.40711 | Correct: 367/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 3100 | Loss: 1.32584 | Correct: 385/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 3200 | Loss: 1.25028 | Correct: 395/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 3300 | Loss: 1.34887 | Correct: 376/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 3400 | Loss: 1.28141 | Correct: 397/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 3500 | Loss: 1.42090 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 3600 | Loss: 1.30727 | Correct: 388/512\n",
      "Estimator: 000 | Epoch: 016 | Batch: 3700 | Loss: 1.40123 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 000 | Loss: 1.36645 | Correct: 386/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 100 | Loss: 1.32477 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 200 | Loss: 1.34611 | Correct: 391/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 300 | Loss: 1.34529 | Correct: 383/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 400 | Loss: 1.32043 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 500 | Loss: 1.41885 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 600 | Loss: 1.40126 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 700 | Loss: 1.35278 | Correct: 390/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 800 | Loss: 1.36174 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 900 | Loss: 1.37393 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 1000 | Loss: 1.38448 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 1100 | Loss: 1.40898 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 1200 | Loss: 1.33383 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 1300 | Loss: 1.34842 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 1400 | Loss: 1.37756 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 1500 | Loss: 1.42672 | Correct: 371/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 1600 | Loss: 1.39673 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 1700 | Loss: 1.33123 | Correct: 393/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 1800 | Loss: 1.29106 | Correct: 397/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 1900 | Loss: 1.39899 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 2000 | Loss: 1.37360 | Correct: 375/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 2100 | Loss: 1.33750 | Correct: 391/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 2200 | Loss: 1.37726 | Correct: 371/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 2300 | Loss: 1.40510 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 2400 | Loss: 1.44734 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 2500 | Loss: 1.35034 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 2600 | Loss: 1.31969 | Correct: 390/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 2700 | Loss: 1.42688 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 2800 | Loss: 1.38520 | Correct: 379/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 2900 | Loss: 1.33120 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 3000 | Loss: 1.38681 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 3100 | Loss: 1.32494 | Correct: 388/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 3200 | Loss: 1.31595 | Correct: 389/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 3300 | Loss: 1.36856 | Correct: 371/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 3400 | Loss: 1.35092 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 3500 | Loss: 1.35631 | Correct: 386/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 3600 | Loss: 1.40017 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 016 | Batch: 3700 | Loss: 1.36446 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 000 | Loss: 1.29606 | Correct: 382/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 100 | Loss: 1.25211 | Correct: 402/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 200 | Loss: 1.28334 | Correct: 393/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 300 | Loss: 1.39757 | Correct: 371/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 400 | Loss: 1.40932 | Correct: 362/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 500 | Loss: 1.34681 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 600 | Loss: 1.34321 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 700 | Loss: 1.32600 | Correct: 390/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 800 | Loss: 1.34661 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 900 | Loss: 1.30567 | Correct: 394/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 1000 | Loss: 1.36128 | Correct: 379/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 1100 | Loss: 1.34758 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 1200 | Loss: 1.31826 | Correct: 377/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 1300 | Loss: 1.31728 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 1400 | Loss: 1.37348 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 1500 | Loss: 1.31261 | Correct: 407/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 1600 | Loss: 1.36643 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 1700 | Loss: 1.33928 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 1800 | Loss: 1.36491 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 1900 | Loss: 1.33207 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 2000 | Loss: 1.41068 | Correct: 364/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 2100 | Loss: 1.34778 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 2200 | Loss: 1.29228 | Correct: 403/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 2300 | Loss: 1.39579 | Correct: 378/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 2400 | Loss: 1.41520 | Correct: 368/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 2500 | Loss: 1.30850 | Correct: 382/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 2600 | Loss: 1.34908 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 2700 | Loss: 1.38518 | Correct: 369/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 2800 | Loss: 1.31436 | Correct: 390/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 2900 | Loss: 1.36537 | Correct: 387/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 3000 | Loss: 1.37110 | Correct: 377/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 3100 | Loss: 1.33232 | Correct: 387/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 3200 | Loss: 1.33512 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 3300 | Loss: 1.38168 | Correct: 368/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 3400 | Loss: 1.43156 | Correct: 356/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 3500 | Loss: 1.37727 | Correct: 382/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 3600 | Loss: 1.32178 | Correct: 385/512\n",
      "Estimator: 002 | Epoch: 016 | Batch: 3700 | Loss: 1.29404 | Correct: 388/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 000 | Loss: 1.32167 | Correct: 389/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 100 | Loss: 1.30537 | Correct: 395/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 200 | Loss: 1.34499 | Correct: 367/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 300 | Loss: 1.29740 | Correct: 383/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 400 | Loss: 1.39254 | Correct: 374/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 500 | Loss: 1.44690 | Correct: 364/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 600 | Loss: 1.28507 | Correct: 398/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 700 | Loss: 1.31255 | Correct: 390/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 800 | Loss: 1.41717 | Correct: 364/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 900 | Loss: 1.42458 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 1000 | Loss: 1.37842 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 1100 | Loss: 1.36728 | Correct: 384/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 1200 | Loss: 1.33648 | Correct: 379/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 1300 | Loss: 1.36670 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 1400 | Loss: 1.35635 | Correct: 381/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 1500 | Loss: 1.46866 | Correct: 347/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 1600 | Loss: 1.31178 | Correct: 387/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 1700 | Loss: 1.39637 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 1800 | Loss: 1.31476 | Correct: 389/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 1900 | Loss: 1.41978 | Correct: 364/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 2000 | Loss: 1.39025 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 2100 | Loss: 1.37328 | Correct: 381/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 2200 | Loss: 1.34876 | Correct: 388/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 2300 | Loss: 1.37013 | Correct: 380/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 2400 | Loss: 1.32229 | Correct: 379/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 2500 | Loss: 1.29999 | Correct: 391/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 2600 | Loss: 1.34849 | Correct: 394/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 2700 | Loss: 1.34756 | Correct: 386/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 2800 | Loss: 1.34675 | Correct: 385/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 2900 | Loss: 1.36573 | Correct: 379/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 3000 | Loss: 1.34578 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 3100 | Loss: 1.30016 | Correct: 393/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 3200 | Loss: 1.31749 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 3300 | Loss: 1.31074 | Correct: 387/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 3400 | Loss: 1.34452 | Correct: 376/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 3500 | Loss: 1.39334 | Correct: 360/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 3600 | Loss: 1.34273 | Correct: 374/512\n",
      "Estimator: 003 | Epoch: 016 | Batch: 3700 | Loss: 1.33245 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 000 | Loss: 1.36306 | Correct: 378/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 100 | Loss: 1.33529 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 200 | Loss: 1.38258 | Correct: 384/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 300 | Loss: 1.35791 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 400 | Loss: 1.34244 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 500 | Loss: 1.35358 | Correct: 385/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 600 | Loss: 1.34456 | Correct: 387/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 700 | Loss: 1.40577 | Correct: 378/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 800 | Loss: 1.32990 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 900 | Loss: 1.32549 | Correct: 389/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 1000 | Loss: 1.37592 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 1100 | Loss: 1.40281 | Correct: 361/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 1200 | Loss: 1.34440 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 1300 | Loss: 1.33752 | Correct: 392/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 1400 | Loss: 1.33756 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 1500 | Loss: 1.35949 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 1600 | Loss: 1.34920 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 1700 | Loss: 1.34454 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 1800 | Loss: 1.34087 | Correct: 387/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 1900 | Loss: 1.35926 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 2000 | Loss: 1.35407 | Correct: 371/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 2100 | Loss: 1.36648 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 2200 | Loss: 1.34811 | Correct: 391/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 2300 | Loss: 1.34966 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 2400 | Loss: 1.42515 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 2500 | Loss: 1.31336 | Correct: 383/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 2600 | Loss: 1.37357 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 2700 | Loss: 1.36394 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 2800 | Loss: 1.35396 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 2900 | Loss: 1.38387 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 3000 | Loss: 1.36488 | Correct: 387/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 3100 | Loss: 1.39627 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 3200 | Loss: 1.34600 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 3300 | Loss: 1.34059 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 3400 | Loss: 1.39263 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 3500 | Loss: 1.41145 | Correct: 355/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 3600 | Loss: 1.39772 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 016 | Batch: 3700 | Loss: 1.29598 | Correct: 390/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 05:22:39,489 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 05:22:39,723 - INFO: Epoch: 016 | Validation Acc: 82.082 % | Historical Best: 82.082 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 017 | Batch: 000 | Loss: 1.34783 | Correct: 388/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 100 | Loss: 1.37286 | Correct: 384/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 200 | Loss: 1.34426 | Correct: 369/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 300 | Loss: 1.38906 | Correct: 366/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 400 | Loss: 1.38522 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 500 | Loss: 1.38820 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 600 | Loss: 1.29768 | Correct: 393/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 700 | Loss: 1.41276 | Correct: 364/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 800 | Loss: 1.34603 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 900 | Loss: 1.36283 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 1000 | Loss: 1.38913 | Correct: 371/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 1100 | Loss: 1.29738 | Correct: 393/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 1200 | Loss: 1.34978 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 1300 | Loss: 1.43813 | Correct: 364/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 1400 | Loss: 1.35940 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 1500 | Loss: 1.41734 | Correct: 382/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 1600 | Loss: 1.31967 | Correct: 390/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 1700 | Loss: 1.34896 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 1800 | Loss: 1.40895 | Correct: 365/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 1900 | Loss: 1.30336 | Correct: 382/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 2000 | Loss: 1.31744 | Correct: 388/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 2100 | Loss: 1.33841 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 2200 | Loss: 1.44957 | Correct: 367/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 2300 | Loss: 1.33864 | Correct: 389/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 2400 | Loss: 1.36382 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 2500 | Loss: 1.32594 | Correct: 390/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 2600 | Loss: 1.36542 | Correct: 373/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 2700 | Loss: 1.40630 | Correct: 365/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 2800 | Loss: 1.40807 | Correct: 376/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 2900 | Loss: 1.37277 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 3000 | Loss: 1.34814 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 3100 | Loss: 1.30991 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 3200 | Loss: 1.40506 | Correct: 365/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 3300 | Loss: 1.36835 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 3400 | Loss: 1.34532 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 3500 | Loss: 1.38038 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 3600 | Loss: 1.38973 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 017 | Batch: 3700 | Loss: 1.33093 | Correct: 391/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 000 | Loss: 1.38811 | Correct: 371/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 100 | Loss: 1.33490 | Correct: 383/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 200 | Loss: 1.32145 | Correct: 385/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 300 | Loss: 1.37018 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 400 | Loss: 1.45268 | Correct: 359/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 500 | Loss: 1.38978 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 600 | Loss: 1.29839 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 700 | Loss: 1.37843 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 800 | Loss: 1.49967 | Correct: 331/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 900 | Loss: 1.35650 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 1000 | Loss: 1.38863 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 1100 | Loss: 1.30658 | Correct: 386/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 1200 | Loss: 1.35472 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 1300 | Loss: 1.33114 | Correct: 388/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 1400 | Loss: 1.38481 | Correct: 368/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 1500 | Loss: 1.31420 | Correct: 396/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 1600 | Loss: 1.33405 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 1700 | Loss: 1.35604 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 1800 | Loss: 1.42749 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 1900 | Loss: 1.36413 | Correct: 378/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 2000 | Loss: 1.37037 | Correct: 371/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 2100 | Loss: 1.32776 | Correct: 394/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 2200 | Loss: 1.35986 | Correct: 375/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 2300 | Loss: 1.34158 | Correct: 388/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 2400 | Loss: 1.35133 | Correct: 389/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 2500 | Loss: 1.31513 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 2600 | Loss: 1.34888 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 2700 | Loss: 1.38812 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 2800 | Loss: 1.31252 | Correct: 388/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 2900 | Loss: 1.37821 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 3000 | Loss: 1.37080 | Correct: 375/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 3100 | Loss: 1.32481 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 3200 | Loss: 1.39513 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 3300 | Loss: 1.34349 | Correct: 383/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 3400 | Loss: 1.29877 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 3500 | Loss: 1.35684 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 3600 | Loss: 1.28883 | Correct: 379/512\n",
      "Estimator: 001 | Epoch: 017 | Batch: 3700 | Loss: 1.31575 | Correct: 385/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 000 | Loss: 1.27207 | Correct: 401/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 100 | Loss: 1.34356 | Correct: 390/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 200 | Loss: 1.31975 | Correct: 377/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 300 | Loss: 1.29287 | Correct: 390/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 400 | Loss: 1.33320 | Correct: 377/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 500 | Loss: 1.32554 | Correct: 385/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 600 | Loss: 1.31123 | Correct: 392/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 700 | Loss: 1.30861 | Correct: 390/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 800 | Loss: 1.32176 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 900 | Loss: 1.34225 | Correct: 379/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 1000 | Loss: 1.34359 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 1100 | Loss: 1.41136 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 1200 | Loss: 1.38666 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 1300 | Loss: 1.31622 | Correct: 391/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 1400 | Loss: 1.33651 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 1500 | Loss: 1.29241 | Correct: 389/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 1600 | Loss: 1.34402 | Correct: 387/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 1700 | Loss: 1.31960 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 1800 | Loss: 1.32920 | Correct: 402/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 1900 | Loss: 1.32952 | Correct: 382/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 2000 | Loss: 1.26840 | Correct: 397/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 2100 | Loss: 1.26128 | Correct: 401/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 2200 | Loss: 1.35611 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 2300 | Loss: 1.42074 | Correct: 367/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 2400 | Loss: 1.27078 | Correct: 402/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 2500 | Loss: 1.35958 | Correct: 379/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 2600 | Loss: 1.37366 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 2700 | Loss: 1.31606 | Correct: 392/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 2800 | Loss: 1.39373 | Correct: 364/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 2900 | Loss: 1.36079 | Correct: 388/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 3000 | Loss: 1.25427 | Correct: 399/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 3100 | Loss: 1.35940 | Correct: 382/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 3200 | Loss: 1.28432 | Correct: 389/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 3300 | Loss: 1.35461 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 3400 | Loss: 1.39479 | Correct: 369/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 3500 | Loss: 1.33231 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 3600 | Loss: 1.24479 | Correct: 410/512\n",
      "Estimator: 002 | Epoch: 017 | Batch: 3700 | Loss: 1.33359 | Correct: 380/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 000 | Loss: 1.35459 | Correct: 383/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 100 | Loss: 1.35687 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 200 | Loss: 1.32572 | Correct: 389/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 300 | Loss: 1.27806 | Correct: 395/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 400 | Loss: 1.29841 | Correct: 381/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 500 | Loss: 1.26127 | Correct: 391/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 600 | Loss: 1.32465 | Correct: 380/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 700 | Loss: 1.33895 | Correct: 381/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 800 | Loss: 1.34292 | Correct: 380/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 900 | Loss: 1.33104 | Correct: 391/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 1000 | Loss: 1.32094 | Correct: 396/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 1100 | Loss: 1.35531 | Correct: 381/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 1200 | Loss: 1.28429 | Correct: 396/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 1300 | Loss: 1.37585 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 1400 | Loss: 1.35770 | Correct: 378/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 1500 | Loss: 1.30316 | Correct: 387/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 1600 | Loss: 1.40017 | Correct: 365/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 1700 | Loss: 1.26198 | Correct: 397/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 1800 | Loss: 1.35136 | Correct: 376/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 1900 | Loss: 1.24432 | Correct: 411/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 2000 | Loss: 1.38541 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 2100 | Loss: 1.32167 | Correct: 401/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 2200 | Loss: 1.29991 | Correct: 392/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 2300 | Loss: 1.36493 | Correct: 376/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 2400 | Loss: 1.28567 | Correct: 399/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 2500 | Loss: 1.30328 | Correct: 392/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 2600 | Loss: 1.31246 | Correct: 385/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 2700 | Loss: 1.33678 | Correct: 391/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 2800 | Loss: 1.31734 | Correct: 381/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 2900 | Loss: 1.29508 | Correct: 386/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 3000 | Loss: 1.36913 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 3100 | Loss: 1.36839 | Correct: 380/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 3200 | Loss: 1.35933 | Correct: 376/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 3300 | Loss: 1.33483 | Correct: 383/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 3400 | Loss: 1.37422 | Correct: 376/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 3500 | Loss: 1.29763 | Correct: 388/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 3600 | Loss: 1.35580 | Correct: 370/512\n",
      "Estimator: 003 | Epoch: 017 | Batch: 3700 | Loss: 1.28513 | Correct: 385/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 000 | Loss: 1.35085 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 100 | Loss: 1.33454 | Correct: 376/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 200 | Loss: 1.34013 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 300 | Loss: 1.36949 | Correct: 378/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 400 | Loss: 1.36579 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 500 | Loss: 1.36158 | Correct: 378/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 600 | Loss: 1.33394 | Correct: 371/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 700 | Loss: 1.34438 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 800 | Loss: 1.27012 | Correct: 407/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 900 | Loss: 1.35514 | Correct: 392/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 1000 | Loss: 1.26808 | Correct: 400/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 1100 | Loss: 1.37614 | Correct: 385/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 1200 | Loss: 1.35085 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 1300 | Loss: 1.32715 | Correct: 385/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 1400 | Loss: 1.32484 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 1500 | Loss: 1.32938 | Correct: 387/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 1600 | Loss: 1.33006 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 1700 | Loss: 1.36662 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 1800 | Loss: 1.35620 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 1900 | Loss: 1.31888 | Correct: 387/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 2000 | Loss: 1.33499 | Correct: 383/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 2100 | Loss: 1.34772 | Correct: 392/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 2200 | Loss: 1.36508 | Correct: 383/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 2300 | Loss: 1.33434 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 2400 | Loss: 1.36125 | Correct: 384/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 2500 | Loss: 1.35781 | Correct: 372/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 2600 | Loss: 1.29054 | Correct: 389/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 2700 | Loss: 1.30292 | Correct: 398/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 2800 | Loss: 1.36896 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 2900 | Loss: 1.27742 | Correct: 400/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 3000 | Loss: 1.39959 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 3100 | Loss: 1.30515 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 3200 | Loss: 1.28429 | Correct: 384/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 3300 | Loss: 1.41310 | Correct: 354/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 3400 | Loss: 1.34588 | Correct: 372/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 3500 | Loss: 1.34085 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 3600 | Loss: 1.39034 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 017 | Batch: 3700 | Loss: 1.31470 | Correct: 398/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 05:25:44,561 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 05:25:44,785 - INFO: Epoch: 017 | Validation Acc: 82.421 % | Historical Best: 82.421 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 018 | Batch: 000 | Loss: 1.24584 | Correct: 401/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 100 | Loss: 1.35962 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 200 | Loss: 1.26440 | Correct: 406/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 300 | Loss: 1.38952 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 400 | Loss: 1.37910 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 500 | Loss: 1.33315 | Correct: 387/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 600 | Loss: 1.35904 | Correct: 383/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 700 | Loss: 1.28505 | Correct: 390/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 800 | Loss: 1.25709 | Correct: 394/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 900 | Loss: 1.32734 | Correct: 390/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 1000 | Loss: 1.25177 | Correct: 393/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 1100 | Loss: 1.30937 | Correct: 383/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 1200 | Loss: 1.31865 | Correct: 387/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 1300 | Loss: 1.40071 | Correct: 373/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 1400 | Loss: 1.36087 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 1500 | Loss: 1.33735 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 1600 | Loss: 1.40125 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 1700 | Loss: 1.34607 | Correct: 375/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 1800 | Loss: 1.30660 | Correct: 384/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 1900 | Loss: 1.39757 | Correct: 375/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 2000 | Loss: 1.39554 | Correct: 372/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 2100 | Loss: 1.39239 | Correct: 368/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 2200 | Loss: 1.36719 | Correct: 382/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 2300 | Loss: 1.26131 | Correct: 407/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 2400 | Loss: 1.36877 | Correct: 389/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 2500 | Loss: 1.36738 | Correct: 362/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 2600 | Loss: 1.29725 | Correct: 387/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 2700 | Loss: 1.40064 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 2800 | Loss: 1.29250 | Correct: 405/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 2900 | Loss: 1.29825 | Correct: 389/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 3000 | Loss: 1.31694 | Correct: 385/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 3100 | Loss: 1.32506 | Correct: 388/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 3200 | Loss: 1.35305 | Correct: 385/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 3300 | Loss: 1.39822 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 3400 | Loss: 1.38077 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 3500 | Loss: 1.30566 | Correct: 390/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 3600 | Loss: 1.30376 | Correct: 392/512\n",
      "Estimator: 000 | Epoch: 018 | Batch: 3700 | Loss: 1.30846 | Correct: 394/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 000 | Loss: 1.31431 | Correct: 392/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 100 | Loss: 1.31593 | Correct: 387/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 200 | Loss: 1.30489 | Correct: 394/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 300 | Loss: 1.36824 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 400 | Loss: 1.37358 | Correct: 371/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 500 | Loss: 1.38830 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 600 | Loss: 1.30812 | Correct: 391/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 700 | Loss: 1.33481 | Correct: 385/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 800 | Loss: 1.33173 | Correct: 379/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 900 | Loss: 1.29236 | Correct: 389/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 1000 | Loss: 1.29854 | Correct: 386/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 1100 | Loss: 1.31871 | Correct: 393/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 1200 | Loss: 1.35102 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 1300 | Loss: 1.35510 | Correct: 379/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 1400 | Loss: 1.32237 | Correct: 396/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 1500 | Loss: 1.30940 | Correct: 386/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 1600 | Loss: 1.33044 | Correct: 388/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 1700 | Loss: 1.35833 | Correct: 366/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 1800 | Loss: 1.31958 | Correct: 385/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 1900 | Loss: 1.39751 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 2000 | Loss: 1.33022 | Correct: 389/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 2100 | Loss: 1.38166 | Correct: 369/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 2200 | Loss: 1.31918 | Correct: 396/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 2300 | Loss: 1.31462 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 2400 | Loss: 1.28593 | Correct: 388/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 2500 | Loss: 1.35529 | Correct: 392/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 2600 | Loss: 1.30545 | Correct: 390/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 2700 | Loss: 1.38369 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 2800 | Loss: 1.34478 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 2900 | Loss: 1.37534 | Correct: 381/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 3000 | Loss: 1.39452 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 3100 | Loss: 1.32624 | Correct: 387/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 3200 | Loss: 1.35517 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 3300 | Loss: 1.30619 | Correct: 387/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 3400 | Loss: 1.34258 | Correct: 386/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 3500 | Loss: 1.34832 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 3600 | Loss: 1.31312 | Correct: 394/512\n",
      "Estimator: 001 | Epoch: 018 | Batch: 3700 | Loss: 1.32031 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 000 | Loss: 1.30779 | Correct: 388/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 100 | Loss: 1.27283 | Correct: 388/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 200 | Loss: 1.46122 | Correct: 356/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 300 | Loss: 1.39322 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 400 | Loss: 1.25932 | Correct: 396/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 500 | Loss: 1.38988 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 600 | Loss: 1.31055 | Correct: 387/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 700 | Loss: 1.35829 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 800 | Loss: 1.27004 | Correct: 388/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 900 | Loss: 1.33136 | Correct: 389/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 1000 | Loss: 1.28628 | Correct: 393/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 1100 | Loss: 1.30911 | Correct: 393/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 1200 | Loss: 1.36007 | Correct: 378/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 1300 | Loss: 1.40655 | Correct: 377/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 1400 | Loss: 1.30893 | Correct: 391/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 1500 | Loss: 1.35769 | Correct: 382/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 1600 | Loss: 1.34824 | Correct: 388/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 1700 | Loss: 1.33643 | Correct: 385/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 1800 | Loss: 1.25809 | Correct: 394/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 1900 | Loss: 1.33082 | Correct: 376/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 2000 | Loss: 1.30776 | Correct: 389/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 2100 | Loss: 1.31332 | Correct: 387/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 2200 | Loss: 1.35832 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 2300 | Loss: 1.36309 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 2400 | Loss: 1.34696 | Correct: 385/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 2500 | Loss: 1.42443 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 2600 | Loss: 1.33305 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 2700 | Loss: 1.32752 | Correct: 386/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 2800 | Loss: 1.30511 | Correct: 391/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 2900 | Loss: 1.34238 | Correct: 387/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 3000 | Loss: 1.41662 | Correct: 373/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 3100 | Loss: 1.36030 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 3200 | Loss: 1.30665 | Correct: 397/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 3300 | Loss: 1.33116 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 3400 | Loss: 1.41531 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 3500 | Loss: 1.34584 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 3600 | Loss: 1.37190 | Correct: 376/512\n",
      "Estimator: 002 | Epoch: 018 | Batch: 3700 | Loss: 1.38293 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 000 | Loss: 1.34460 | Correct: 395/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 100 | Loss: 1.28295 | Correct: 391/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 200 | Loss: 1.30250 | Correct: 393/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 300 | Loss: 1.29814 | Correct: 390/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 400 | Loss: 1.39166 | Correct: 367/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 500 | Loss: 1.35105 | Correct: 381/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 600 | Loss: 1.38771 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 700 | Loss: 1.26622 | Correct: 385/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 800 | Loss: 1.44351 | Correct: 373/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 900 | Loss: 1.38294 | Correct: 368/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 1000 | Loss: 1.28087 | Correct: 403/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 1100 | Loss: 1.41968 | Correct: 360/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 1200 | Loss: 1.35877 | Correct: 380/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 1300 | Loss: 1.31748 | Correct: 392/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 1400 | Loss: 1.31358 | Correct: 387/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 1500 | Loss: 1.37961 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 1600 | Loss: 1.34398 | Correct: 379/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 1700 | Loss: 1.30862 | Correct: 380/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 1800 | Loss: 1.36969 | Correct: 381/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 1900 | Loss: 1.33919 | Correct: 378/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 2000 | Loss: 1.34508 | Correct: 391/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 2100 | Loss: 1.27904 | Correct: 391/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 2200 | Loss: 1.29105 | Correct: 400/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 2300 | Loss: 1.30610 | Correct: 389/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 2400 | Loss: 1.31188 | Correct: 389/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 2500 | Loss: 1.34024 | Correct: 375/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 2600 | Loss: 1.29116 | Correct: 396/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 2700 | Loss: 1.40774 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 2800 | Loss: 1.28881 | Correct: 397/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 2900 | Loss: 1.30142 | Correct: 396/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 3000 | Loss: 1.39057 | Correct: 383/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 3100 | Loss: 1.43669 | Correct: 356/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 3200 | Loss: 1.41965 | Correct: 356/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 3300 | Loss: 1.32469 | Correct: 383/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 3400 | Loss: 1.41726 | Correct: 362/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 3500 | Loss: 1.31319 | Correct: 384/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 3600 | Loss: 1.25680 | Correct: 399/512\n",
      "Estimator: 003 | Epoch: 018 | Batch: 3700 | Loss: 1.39345 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 000 | Loss: 1.26073 | Correct: 397/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 100 | Loss: 1.34538 | Correct: 374/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 200 | Loss: 1.31167 | Correct: 392/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 300 | Loss: 1.36937 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 400 | Loss: 1.32375 | Correct: 383/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 500 | Loss: 1.31639 | Correct: 390/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 600 | Loss: 1.28416 | Correct: 387/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 700 | Loss: 1.32948 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 800 | Loss: 1.36568 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 900 | Loss: 1.37099 | Correct: 371/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 1000 | Loss: 1.37352 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 1100 | Loss: 1.35995 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 1200 | Loss: 1.29644 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 1300 | Loss: 1.35478 | Correct: 397/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 1400 | Loss: 1.33886 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 1500 | Loss: 1.35603 | Correct: 385/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 1600 | Loss: 1.33036 | Correct: 384/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 1700 | Loss: 1.33651 | Correct: 394/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 1800 | Loss: 1.32135 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 1900 | Loss: 1.30796 | Correct: 389/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 2000 | Loss: 1.36394 | Correct: 388/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 2100 | Loss: 1.33858 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 2200 | Loss: 1.26455 | Correct: 406/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 2300 | Loss: 1.41047 | Correct: 369/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 2400 | Loss: 1.34322 | Correct: 371/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 2500 | Loss: 1.30717 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 2600 | Loss: 1.35570 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 2700 | Loss: 1.35091 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 2800 | Loss: 1.42154 | Correct: 363/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 2900 | Loss: 1.33794 | Correct: 388/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 3000 | Loss: 1.33710 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 3100 | Loss: 1.30570 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 3200 | Loss: 1.34628 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 3300 | Loss: 1.29393 | Correct: 388/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 3400 | Loss: 1.30878 | Correct: 388/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 3500 | Loss: 1.40577 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 3600 | Loss: 1.33404 | Correct: 391/512\n",
      "Estimator: 004 | Epoch: 018 | Batch: 3700 | Loss: 1.39605 | Correct: 376/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 05:28:48,051 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 05:28:48,307 - INFO: Epoch: 018 | Validation Acc: 82.755 % | Historical Best: 82.755 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 019 | Batch: 000 | Loss: 1.29456 | Correct: 395/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 100 | Loss: 1.27116 | Correct: 389/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 200 | Loss: 1.38865 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 300 | Loss: 1.30256 | Correct: 389/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 400 | Loss: 1.40639 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 500 | Loss: 1.37225 | Correct: 374/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 600 | Loss: 1.30800 | Correct: 393/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 700 | Loss: 1.36777 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 800 | Loss: 1.34004 | Correct: 382/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 900 | Loss: 1.34960 | Correct: 386/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 1000 | Loss: 1.28487 | Correct: 386/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 1100 | Loss: 1.36817 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 1200 | Loss: 1.35599 | Correct: 384/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 1300 | Loss: 1.32562 | Correct: 385/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 1400 | Loss: 1.33958 | Correct: 370/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 1500 | Loss: 1.34321 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 1600 | Loss: 1.31991 | Correct: 390/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 1700 | Loss: 1.32685 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 1800 | Loss: 1.36858 | Correct: 383/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 1900 | Loss: 1.32886 | Correct: 401/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 2000 | Loss: 1.33267 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 2100 | Loss: 1.38454 | Correct: 380/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 2200 | Loss: 1.35787 | Correct: 385/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 2300 | Loss: 1.34873 | Correct: 392/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 2400 | Loss: 1.37680 | Correct: 383/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 2500 | Loss: 1.31716 | Correct: 390/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 2600 | Loss: 1.28255 | Correct: 396/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 2700 | Loss: 1.30926 | Correct: 394/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 2800 | Loss: 1.37618 | Correct: 381/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 2900 | Loss: 1.37156 | Correct: 377/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 3000 | Loss: 1.32449 | Correct: 399/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 3100 | Loss: 1.32479 | Correct: 382/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 3200 | Loss: 1.30253 | Correct: 387/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 3300 | Loss: 1.38197 | Correct: 378/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 3400 | Loss: 1.37333 | Correct: 376/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 3500 | Loss: 1.29876 | Correct: 395/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 3600 | Loss: 1.30211 | Correct: 393/512\n",
      "Estimator: 000 | Epoch: 019 | Batch: 3700 | Loss: 1.31312 | Correct: 387/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 000 | Loss: 1.34280 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 100 | Loss: 1.37132 | Correct: 375/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 200 | Loss: 1.39878 | Correct: 383/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 300 | Loss: 1.31996 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 400 | Loss: 1.33371 | Correct: 393/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 500 | Loss: 1.35096 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 600 | Loss: 1.33301 | Correct: 383/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 700 | Loss: 1.32939 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 800 | Loss: 1.35961 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 900 | Loss: 1.40970 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 1000 | Loss: 1.40929 | Correct: 365/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 1100 | Loss: 1.38672 | Correct: 376/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 1200 | Loss: 1.39035 | Correct: 370/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 1300 | Loss: 1.29443 | Correct: 392/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 1400 | Loss: 1.32043 | Correct: 394/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 1500 | Loss: 1.27840 | Correct: 397/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 1600 | Loss: 1.27018 | Correct: 394/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 1700 | Loss: 1.36122 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 1800 | Loss: 1.31629 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 1900 | Loss: 1.34127 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 2000 | Loss: 1.30192 | Correct: 384/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 2100 | Loss: 1.32142 | Correct: 389/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 2200 | Loss: 1.43273 | Correct: 367/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 2300 | Loss: 1.33436 | Correct: 385/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 2400 | Loss: 1.34771 | Correct: 382/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 2500 | Loss: 1.38224 | Correct: 372/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 2600 | Loss: 1.37121 | Correct: 377/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 2700 | Loss: 1.33028 | Correct: 371/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 2800 | Loss: 1.33103 | Correct: 389/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 2900 | Loss: 1.32221 | Correct: 387/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 3000 | Loss: 1.36617 | Correct: 380/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 3100 | Loss: 1.34405 | Correct: 373/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 3200 | Loss: 1.35728 | Correct: 386/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 3300 | Loss: 1.40544 | Correct: 354/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 3400 | Loss: 1.42513 | Correct: 364/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 3500 | Loss: 1.35844 | Correct: 375/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 3600 | Loss: 1.36363 | Correct: 379/512\n",
      "Estimator: 001 | Epoch: 019 | Batch: 3700 | Loss: 1.29739 | Correct: 388/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 000 | Loss: 1.32201 | Correct: 376/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 100 | Loss: 1.30542 | Correct: 390/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 200 | Loss: 1.29043 | Correct: 388/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 300 | Loss: 1.36502 | Correct: 385/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 400 | Loss: 1.33495 | Correct: 393/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 500 | Loss: 1.32453 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 600 | Loss: 1.29552 | Correct: 390/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 700 | Loss: 1.34370 | Correct: 383/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 800 | Loss: 1.32058 | Correct: 377/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 900 | Loss: 1.36808 | Correct: 370/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 1000 | Loss: 1.33125 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 1100 | Loss: 1.31395 | Correct: 388/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 1200 | Loss: 1.26329 | Correct: 392/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 1300 | Loss: 1.26415 | Correct: 396/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 1400 | Loss: 1.38177 | Correct: 370/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 1500 | Loss: 1.28697 | Correct: 400/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 1600 | Loss: 1.38713 | Correct: 376/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 1700 | Loss: 1.22276 | Correct: 408/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 1800 | Loss: 1.29242 | Correct: 395/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 1900 | Loss: 1.32994 | Correct: 375/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 2000 | Loss: 1.44726 | Correct: 357/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 2100 | Loss: 1.32051 | Correct: 391/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 2200 | Loss: 1.29171 | Correct: 392/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 2300 | Loss: 1.39052 | Correct: 370/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 2400 | Loss: 1.33570 | Correct: 379/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 2500 | Loss: 1.36873 | Correct: 378/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 2600 | Loss: 1.26128 | Correct: 403/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 2700 | Loss: 1.30212 | Correct: 384/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 2800 | Loss: 1.35619 | Correct: 376/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 2900 | Loss: 1.32812 | Correct: 378/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 3000 | Loss: 1.37798 | Correct: 380/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 3100 | Loss: 1.40164 | Correct: 372/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 3200 | Loss: 1.32015 | Correct: 381/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 3300 | Loss: 1.33445 | Correct: 387/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 3400 | Loss: 1.30530 | Correct: 390/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 3500 | Loss: 1.33309 | Correct: 374/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 3600 | Loss: 1.28409 | Correct: 387/512\n",
      "Estimator: 002 | Epoch: 019 | Batch: 3700 | Loss: 1.33980 | Correct: 389/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 000 | Loss: 1.34545 | Correct: 387/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 100 | Loss: 1.32982 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 200 | Loss: 1.24246 | Correct: 401/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 300 | Loss: 1.39573 | Correct: 368/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 400 | Loss: 1.35331 | Correct: 389/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 500 | Loss: 1.32447 | Correct: 387/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 600 | Loss: 1.34642 | Correct: 389/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 700 | Loss: 1.25641 | Correct: 397/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 800 | Loss: 1.30407 | Correct: 387/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 900 | Loss: 1.39265 | Correct: 379/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 1000 | Loss: 1.34673 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 1100 | Loss: 1.28920 | Correct: 390/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 1200 | Loss: 1.30450 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 1300 | Loss: 1.29827 | Correct: 389/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 1400 | Loss: 1.31977 | Correct: 386/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 1500 | Loss: 1.36142 | Correct: 377/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 1600 | Loss: 1.35393 | Correct: 381/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 1700 | Loss: 1.39709 | Correct: 372/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 1800 | Loss: 1.33681 | Correct: 379/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 1900 | Loss: 1.30340 | Correct: 391/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 2000 | Loss: 1.34622 | Correct: 381/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 2100 | Loss: 1.32106 | Correct: 383/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 2200 | Loss: 1.36206 | Correct: 382/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 2300 | Loss: 1.31547 | Correct: 380/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 2400 | Loss: 1.35697 | Correct: 379/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 2500 | Loss: 1.27037 | Correct: 395/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 2600 | Loss: 1.27572 | Correct: 394/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 2700 | Loss: 1.36056 | Correct: 383/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 2800 | Loss: 1.37793 | Correct: 379/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 2900 | Loss: 1.38278 | Correct: 374/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 3000 | Loss: 1.36525 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 3100 | Loss: 1.36206 | Correct: 386/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 3200 | Loss: 1.35879 | Correct: 379/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 3300 | Loss: 1.34175 | Correct: 384/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 3400 | Loss: 1.36434 | Correct: 371/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 3500 | Loss: 1.41323 | Correct: 363/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 3600 | Loss: 1.33224 | Correct: 381/512\n",
      "Estimator: 003 | Epoch: 019 | Batch: 3700 | Loss: 1.37606 | Correct: 373/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 000 | Loss: 1.40775 | Correct: 364/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 100 | Loss: 1.31900 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 200 | Loss: 1.34758 | Correct: 387/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 300 | Loss: 1.37831 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 400 | Loss: 1.27656 | Correct: 396/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 500 | Loss: 1.37057 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 600 | Loss: 1.40571 | Correct: 365/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 700 | Loss: 1.31306 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 800 | Loss: 1.25729 | Correct: 391/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 900 | Loss: 1.36630 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 1000 | Loss: 1.23626 | Correct: 408/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 1100 | Loss: 1.33359 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 1200 | Loss: 1.26854 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 1300 | Loss: 1.36082 | Correct: 382/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 1400 | Loss: 1.37545 | Correct: 384/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 1500 | Loss: 1.37009 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 1600 | Loss: 1.32238 | Correct: 385/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 1700 | Loss: 1.33127 | Correct: 375/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 1800 | Loss: 1.32822 | Correct: 392/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 1900 | Loss: 1.31406 | Correct: 392/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 2000 | Loss: 1.34791 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 2100 | Loss: 1.32087 | Correct: 386/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 2200 | Loss: 1.31695 | Correct: 397/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 2300 | Loss: 1.36550 | Correct: 366/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 2400 | Loss: 1.31274 | Correct: 392/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 2500 | Loss: 1.34983 | Correct: 377/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 2600 | Loss: 1.41398 | Correct: 367/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 2700 | Loss: 1.37741 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 2800 | Loss: 1.34145 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 2900 | Loss: 1.39512 | Correct: 362/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 3000 | Loss: 1.32132 | Correct: 387/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 3100 | Loss: 1.34335 | Correct: 385/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 3200 | Loss: 1.35148 | Correct: 381/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 3300 | Loss: 1.28237 | Correct: 393/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 3400 | Loss: 1.33380 | Correct: 379/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 3500 | Loss: 1.36695 | Correct: 380/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 3600 | Loss: 1.30390 | Correct: 395/512\n",
      "Estimator: 004 | Epoch: 019 | Batch: 3700 | Loss: 1.33240 | Correct: 380/512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 05:31:50,918 - INFO: Saving the model to `./VotingClassifier_Classifier_5_ckpt.pth`\n",
      "2023-03-17 05:31:51,136 - INFO: Epoch: 019 | Validation Acc: 83.044 % | Historical Best: 83.044 %\n"
     ]
    }
   ],
   "source": [
    "from torchensemble import VotingClassifier  # voting is a classic ensemble strategy\n",
    "from torchensemble.utils.logging import set_logger\n",
    "\n",
    "logger = set_logger('log')\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimator=Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim),               # here is your deep learning model\n",
    "    n_estimators=estimators ,                       # number of base estimators\n",
    "    cuda=True,\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing = 0.1)   \n",
    "ensemble.set_criterion(criterion)\n",
    "\n",
    "ensemble.set_optimizer(\n",
    "    \"AdamW\",                                 # type of parameter optimizer\n",
    "    lr=learning_rate,                       # learning rate of parameter optimizer\n",
    ")\n",
    "\n",
    "ensemble.fit(\n",
    "    train_loader,\n",
    "    epochs=num_epoch,                          # number of training epochs\n",
    "    test_loader = val_loader,\n",
    "    save_dir = './'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f32146",
   "metadata": {
    "id": "pwWH1KIqzxEr",
    "papermill": {
     "duration": 0.211988,
     "end_time": "2023-03-17T05:31:51.574457",
     "exception": false,
     "start_time": "2023-03-17T05:31:51.362469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5e5d49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T05:31:52.017590Z",
     "iopub.status.busy": "2023-03-17T05:31:52.017248Z",
     "iopub.status.idle": "2023-03-17T05:31:52.702894Z",
     "shell.execute_reply": "2023-03-17T05:31:52.701707Z"
    },
    "id": "ab33MxosWLmG",
    "outputId": "0d5e2cc6-46f3-41b9-ea09-79fdf660898f",
    "papermill": {
     "duration": 0.904587,
     "end_time": "2023-03-17T05:31:52.705459",
     "exception": false,
     "start_time": "2023-03-17T05:31:51.800872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_set, val_set\n",
    "del train_loader, val_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdb3bfd",
   "metadata": {
    "id": "1Hi7jTn3PX-m",
    "papermill": {
     "duration": 0.223213,
     "end_time": "2023-03-17T05:31:53.245223",
     "exception": false,
     "start_time": "2023-03-17T05:31:53.022010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing\n",
    "Create a testing dataset, and load model from the saved checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dcdae1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T05:31:53.697336Z",
     "iopub.status.busy": "2023-03-17T05:31:53.696905Z",
     "iopub.status.idle": "2023-03-17T05:32:01.391013Z",
     "shell.execute_reply": "2023-03-17T05:32:01.387803Z"
    },
    "id": "VOG1Ou0PGrhc",
    "outputId": "3373d328-bb42-48ec-92f2-e2e935c3344c",
    "papermill": {
     "duration": 7.920497,
     "end_time": "2023-03-17T05:32:01.393065",
     "exception": false,
     "start_time": "2023-03-17T05:31:53.472568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] - # phone classes: 41, number of utterances for test: 857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "857it [00:07, 111.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] test set\n",
      "torch.Size([527364, 975])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "test_X = preprocess_data(split='test', feat_dir='/kaggle/input/ml2023spring-hw2/libriphone/feat', phone_path='/kaggle/input/ml2023spring-hw2/libriphone', concat_nframes=concat_nframes)\n",
    "test_set = LibriDataset(test_X, None)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67291256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T05:32:01.826957Z",
     "iopub.status.busy": "2023-03-17T05:32:01.825894Z",
     "iopub.status.idle": "2023-03-17T05:32:02.051898Z",
     "shell.execute_reply": "2023-03-17T05:32:02.050945Z"
    },
    "id": "ay0Fu8Ovkdad",
    "outputId": "fe130106-a997-4985-fc4b-5102414afe31",
    "papermill": {
     "duration": 0.445279,
     "end_time": "2023-03-17T05:32:02.054388",
     "exception": false,
     "start_time": "2023-03-17T05:32:01.609109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "from torchensemble.utils import io\n",
    "test_ensemble = VotingClassifier(\n",
    "    estimator=Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim),               # here is your deep learning model\n",
    "    n_estimators=estimators,                        # number of base estimators\n",
    "    cuda=True,\n",
    ")\n",
    "io.load(test_ensemble,'./')  # reload\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e85dfd3",
   "metadata": {
    "id": "zp-DV1p4r7Nz",
    "papermill": {
     "duration": 0.213074,
     "end_time": "2023-03-17T05:32:02.485588",
     "exception": false,
     "start_time": "2023-03-17T05:32:02.272514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Make prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe946371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T05:32:02.961258Z",
     "iopub.status.busy": "2023-03-17T05:32:02.960870Z",
     "iopub.status.idle": "2023-03-17T05:32:11.154280Z",
     "shell.execute_reply": "2023-03-17T05:32:11.153116Z"
    },
    "id": "84HU5GGjPqR0",
    "outputId": "b49ffee0-1785-419d-e56c-0ddd734b2c99",
    "papermill": {
     "duration": 8.410073,
     "end_time": "2023-03-17T05:32:11.156749",
     "exception": false,
     "start_time": "2023-03-17T05:32:02.746676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1031/1031 [00:08<00:00, 126.01it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pred = np.array([], dtype=np.int32)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(test_loader)):\n",
    "        features = batch\n",
    "        features = features.to(device)\n",
    "        \n",
    "        outputs = test_ensemble.predict(features)\n",
    "\n",
    "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
    "        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dfa0fd",
   "metadata": {
    "id": "wyZqy40Prz0v",
    "papermill": {
     "duration": 0.21995,
     "end_time": "2023-03-17T05:32:11.600525",
     "exception": false,
     "start_time": "2023-03-17T05:32:11.380575",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Write prediction to a CSV file.\n",
    "\n",
    "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe72dc2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-17T05:32:12.058124Z",
     "iopub.status.busy": "2023-03-17T05:32:12.057102Z",
     "iopub.status.idle": "2023-03-17T05:32:12.464309Z",
     "shell.execute_reply": "2023-03-17T05:32:12.463266Z"
    },
    "id": "GuljYSPHcZir",
    "papermill": {
     "duration": 0.644195,
     "end_time": "2023-03-17T05:32:12.466793",
     "exception": false,
     "start_time": "2023-03-17T05:32:11.822598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('prediction.csv', 'w') as f:\n",
    "    f.write('Id,Class\\n')\n",
    "    for i, y in enumerate(pred):\n",
    "        f.write('{},{}\\n'.format(i, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3772.106832,
   "end_time": "2023-03-17T05:32:14.019075",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-17T04:29:21.912243",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
